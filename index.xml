<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Michael Pilosov | Academic Website on Michael Pilosov | Academic Website</title>
    <link>https://www.michaelpilosov.com/</link>
    <description>Recent content in Michael Pilosov | Academic Website on Michael Pilosov | Academic Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Michael Pilosov</copyright>
    <lastBuildDate>Mon, 01 Jan 2018 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Overview</title>
      <link>https://www.michaelpilosov.com/wid/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resources</title>
      <link>https://www.michaelpilosov.com/wid/resources/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 -0600</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/resources/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent Galleries</title>
      <link>https://www.michaelpilosov.com/wid/posts/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 -0600</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/posts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>BET Development</title>
      <link>https://www.michaelpilosov.com/slides/dev/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.michaelpilosov.com/slides/dev/</guid>
      <description>

&lt;h1 id=&#34;bet-development&#34;&gt;BET Development&lt;/h1&gt;

&lt;p&gt;[Butler, Estep, Tavener] Method&lt;/p&gt;

&lt;p&gt;+ Mattis, Graham, Walsh, Pilosov&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/UT-CHG/BET&#34; target=&#34;_blank&#34;&gt;github.com/UT-CHG/BET&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Purpose: Implement the novel method developed by the aforementioned authors&lt;/li&gt;
&lt;li&gt;GNU General Public License&lt;/li&gt;
&lt;li&gt;First released 2014&lt;/li&gt;
&lt;li&gt;Python 2.7, upgraded to 3.6&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;About/Motivation&lt;/li&gt;
&lt;li&gt;Git-Based Workflow&lt;/li&gt;
&lt;li&gt;Contribution, Communication&lt;/li&gt;
&lt;li&gt;Testing, Coverage, Versioning&lt;/li&gt;
&lt;li&gt;Pull Requests&lt;/li&gt;
&lt;li&gt;Continuous Integration&lt;/li&gt;
&lt;li&gt;Documentation&lt;/li&gt;
&lt;li&gt;Publishing, Releases, Licenses&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;about-motivation&#34;&gt;About/Motivation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Reproduce results in research&lt;/li&gt;
&lt;li&gt;Demonstrate utility of approach&lt;/li&gt;
&lt;li&gt;Upgrading

&lt;ul&gt;
&lt;li&gt;Python 2.7 will be deprecated by 2020&lt;/li&gt;
&lt;li&gt;New features in ConsistentBayes repo&lt;/li&gt;
&lt;li&gt;Desire to unify frameworks&lt;/li&gt;
&lt;li&gt;Repository needed some love&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;git-based-workflow&#34;&gt;Git-Based Workflow&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Fork project&lt;/li&gt;
&lt;li&gt;Clone your fork&lt;/li&gt;
&lt;li&gt;Create branch for new feature(s)&lt;/li&gt;
&lt;li&gt;Checkout branch, make changes&lt;/li&gt;
&lt;li&gt;Commit files with informative messages&lt;/li&gt;
&lt;li&gt;Push branch back to your remote fork&lt;/li&gt;
&lt;li&gt;Use GitHub to start Pull-Request&lt;/li&gt;
&lt;li&gt;Communicate (if needed) until PR is merged (or not)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;contribution-communication&#34;&gt;Contribution, Communication&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Make sure your contribution would be welcome

&lt;ul&gt;
&lt;li&gt;Consider starting a new &amp;ldquo;Issue&amp;rdquo; on GitHub to ask&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Read the existing documentation (&lt;code&gt;README&lt;/code&gt;, &lt;code&gt;CONTRIBUTE&lt;/code&gt;, etc)

&lt;ul&gt;
&lt;li&gt;Ensure you understand the necessary requirements&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;unit-testing-coverage-versioning&#34;&gt;Unit-Testing, Coverage, Versioning&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nose&lt;/code&gt; is a Python package/framework for unit testing&lt;/li&gt;
&lt;li&gt;&lt;code&gt;codecov&lt;/code&gt; works in conjuction

&lt;ul&gt;
&lt;li&gt;checks which lines of code your test called&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;setup.py&lt;/code&gt; contains versioning information

&lt;ul&gt;
&lt;li&gt;Major/Minor releases depend on extent of changes&lt;/li&gt;
&lt;li&gt;The third number in &lt;code&gt;v1.2.3&lt;/code&gt; is for incremental changes, such as bug-fixes, typos, patches, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;nosetests&#34;&gt;Nosetests&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;One-to-one file structure

&lt;ul&gt;
&lt;li&gt;one test (class) for each sub-module method&lt;/li&gt;
&lt;li&gt;multiple &amp;ldquo;tests&amp;rdquo; within each&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Class consists of several methods

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;setup&lt;/code&gt; and &lt;code&gt;teardown&lt;/code&gt; required&lt;/li&gt;
&lt;li&gt;test for each function within module&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Each test should anticipate mixtures of arguments that could be passed to each function&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;nosetest-example&#34;&gt;Nosetest Example&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from unnecessary_math import multiply
 
def test_numbers_3_4():
    assert multiply(3,4) == 12 
 
def test_strings_a_3():
    assert multiply(&#39;a&#39;,3) == &#39;aaa&#39; 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;nosetests -v test_um_nose.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;small&gt; &lt;a href=&#34;http://pythontesting.net/framework/nose/nose-introduction/&#34; target=&#34;_blank&#34;&gt;Source&lt;/a&gt; &lt;/small&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;pull-requests&#34;&gt;Pull Requests&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://help.github.com/assets/images/help/pull_requests/pull-request-review-edit-branch.png&#34; alt=&#34;github-pr&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://help.github.com/assets/images/help/pull_requests/pull-request-start-review-button.png&#34; alt=&#34;github-pr&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://help.github.com/assets/images/help/pull_requests/pullrequest-send.png&#34; alt=&#34;github-pr&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;continuous-integration&#34;&gt;Continuous Integration&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;If enabled, remote server then

&lt;ul&gt;
&lt;li&gt;Carries out instructions on UNIX image&lt;/li&gt;
&lt;li&gt;Communicates with GitHub about test status&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Ensures consistency of installation&lt;/li&gt;
&lt;li&gt;Someone has to pay for the computer&lt;/li&gt;
&lt;li&gt;Can run local versions&lt;/li&gt;
&lt;li&gt;Most &amp;ldquo;real&amp;rdquo; projects include CI

&lt;ul&gt;
&lt;li&gt;Travis, Shippable, etc.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;continuous-integration-1&#34;&gt;Continuous Integration&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Travis runs when you submit a PR to check that everything works&lt;/li&gt;
&lt;li&gt;GitHub checks for ability to merge automatically&lt;/li&gt;
&lt;li&gt;Passing does not ensure a PR is merged

&lt;ul&gt;
&lt;li&gt;Ultimiately up to the admininstrators of the repo&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Helpful for contributors to debug before admins take a look

&lt;ul&gt;
&lt;li&gt;If checks do not pass, adding commits to your branch will automatically trigger new CI builds, updates to the PR&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;

&lt;p&gt;BET is &lt;em&gt;auto-documented&lt;/em&gt; using a tool called &lt;a href=&#34;http://www.sphinx-doc.org/en/master/&#34; target=&#34;_blank&#34;&gt;Sphinx&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;r&amp;quot;&amp;quot;&amp;quot;
This is a description of the method.
All sorts of formatting options are understood by Sphinx.
(kind of something to learn on its own, but usually you
can make sense of syntax by looking at existing ones)
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Comments that are formatted inside blocks are converted into web-page documentation&lt;/li&gt;
&lt;li&gt;Updating docs through command-line&lt;/li&gt;
&lt;li&gt;GitHub pages used to host the resulting output&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;licensing&#34;&gt;Licensing&lt;/h2&gt;

&lt;p&gt;Many open-source models to choose from.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GNU GPL&lt;/li&gt;
&lt;li&gt;BSD&lt;/li&gt;
&lt;li&gt;MIT&lt;/li&gt;
&lt;li&gt;Creative Commons&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/licensing-a-repository/&#34; target=&#34;_blank&#34;&gt;Github: Choosing a License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.github.com/articles/adding-a-license-to-a-repository/&#34; target=&#34;_blank&#34;&gt;Github: Adding a License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;publishing&#34;&gt;Publishing&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;GitHub (Microsoft)&lt;/li&gt;
&lt;li&gt;GitLab (VC-funded, Private)&lt;/li&gt;
&lt;li&gt;Bitbucket (Atlassian)&lt;/li&gt;
&lt;li&gt;Anaconda (Community)&lt;/li&gt;
&lt;li&gt;PyPi (Community)&lt;/li&gt;
&lt;li&gt;(Suggested) Website&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;what-i-did&#34;&gt;What I Did&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Most of what was written about here&lt;/li&gt;
&lt;li&gt;Intent was to upgrade to Python 3.6&lt;/li&gt;
&lt;li&gt;Used a tool called &lt;code&gt;2to3&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Takes care of most major changes&lt;/li&gt;
&lt;li&gt;Two weeks fixing tests&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Once tests fixed, worked on upgrading dependencies&lt;/li&gt;
&lt;li&gt;Updated examples, copyrights, comments, styling&lt;/li&gt;
&lt;li&gt;Preparing for release &lt;code&gt;2.1.0&lt;/code&gt;, PR ready to be merged&lt;/li&gt;
&lt;li&gt;Version &lt;code&gt;3.0.0&lt;/code&gt; will incorporate &lt;code&gt;cbayes&lt;/code&gt; features&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.michaelpilosov.com/&#34;&gt;Homepage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.michaelpilosov.com/slides/&#34;&gt;Slideshows&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/UT-CHG/BET&#34; target=&#34;_blank&#34;&gt;BET&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slide Decks</title>
      <link>https://www.michaelpilosov.com/slides/</link>
      <pubDate>Wed, 06 Feb 2019 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/slides/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;These slideshows are created as single markdown files using &lt;a href=&#34;https://github.com/hakimel/reveal.js&#34; target=&#34;_blank&#34;&gt;Reveal.js&lt;/a&gt; implemented into the &lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34;&gt;Academic Theme for Hugo&lt;/a&gt;, which was used as the template for this website.&lt;/p&gt;

&lt;p&gt;The slideshows will open in a new tab (with any browser, including mobile ones). You can use the arrow keys to move through slides.
If you are presenting using a laptop/desktop whose screen is extended to a monitor/projection, pressing the &lt;code&gt;S&lt;/code&gt; key will enable a talk-timer in a separate browser window.&lt;/p&gt;

&lt;p&gt;This presentation interface will be familiar to anyone who has used one of the leading presentation software tools, complete with a preview of the next slide and speaker notes.&lt;/p&gt;

&lt;h1 id=&#34;slideshows&#34;&gt;Slideshows&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.michaelpilosov.com/slides/website/&#34; target=&#34;_blank&#34; &gt;Introduction To Web Development&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Talk given on Wednesday Feb 6, 2019 as part of the Student-Led Seminar Series at the University of Colorado Denver: Department of Mathematical and Statistical Studies.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://www.michaelpilosov.com/slides/dev/&#34; target=&#34;_blank&#34; &gt;Development of the BET Python Package&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Presentation given Friday Feb 8, 2019 as part of the Uncertainty Quantification Research Group weekly meetings at the University of Colorado Denver: Department of Mathematical and Statistical Sciences.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>GitHub Activity</title>
      <link>https://www.michaelpilosov.com/activity/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/activity/</guid>
      <description>&lt;p&gt;Here is a summary of my activity on Github from my legacy username.&lt;/p&gt;


&lt;script
  src=&#34;https://cdn.rawgit.com/IonicaBizau/github-calendar/gh-pages/dist/github-calendar.min.js&#34;
&gt;
&lt;/script&gt;





&lt;div class=&#34;calendar&#34;&gt;
    
    Loading the data just for you.
&lt;/div&gt;

&lt;script&gt;
    new GitHubCalendar(&#34;.calendar&#34;, &#34;mpilosov&#34;);
&lt;/script&gt;


&lt;p&gt;For activity on my other profile, please visit &lt;a href=&#34;https://www.mathematicalmichael.com/activity&#34; target=&#34;_blank&#34;&gt;my other website&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Jupyterhub Configuration</title>
      <link>https://www.michaelpilosov.com/devlog/jupyterhub/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/jupyterhub/</guid>
      <description>

&lt;h1 id=&#34;jan-1-2019&#34;&gt;Jan 1, 2019&lt;/h1&gt;

&lt;h2 id=&#34;status-report&#34;&gt;Status Report&lt;/h2&gt;

&lt;p&gt;Okay so where are we at?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Spawner&lt;/code&gt; needs to be sussed out. Right now I really like DockerSpawner, and it seems to persist storage.

&lt;ul&gt;
&lt;li&gt;Each student gets a user account but it&amp;rsquo;s only used for authenetication right now. Can&amp;rsquo;t figure out volume-mapping.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;With &lt;code&gt;dockerspawner.DockerSpawner&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each time someone is logged in, a container is either loaded up or built from &lt;code&gt;jupyterlab_img&lt;/code&gt; container. These are very flexible, many stacks available.&lt;/li&gt;
&lt;li&gt;In this set-up, each student gets a container, which is a full-fledged linux machine. Since Docker is managing these alongside Dockerhub in the network, communication between containers is not possible right now. &lt;em&gt;should be&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;One hour of inactivity results in shutdown of container thanks to a python script from jupyter.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What we want: &lt;code&gt;dockerspawner.SystemUserSpawner&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;with maps to home directories that exist on the &lt;code&gt;jupyterhub&lt;/code&gt; container.&lt;/li&gt;
&lt;li&gt;this way a teacher opens the docker container with the &amp;ldquo;hub&amp;rdquo; and all the students are there.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What we have now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;each student has a container with their name on it. each is its own linux machine&lt;/li&gt;
&lt;li&gt;to get into their linux machines, run &lt;code&gt;docker exec -ti jupyter-{surname} /bin/bash&lt;/code&gt;, do your thing, &lt;code&gt;Ctrl-D&lt;/code&gt; to exit.&lt;/li&gt;
&lt;li&gt;The script that gets installed in the hub container stops idle single-user servers (&lt;em&gt;I think this means it shuts down the containers that are inactive&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;The containers are spun up based on a jupyterlab image.

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;What happens when we update this? Perhaps to include files for every student?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternatively, you have all of them learn to manage push/pull from a class repository&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It appears that to do this, we &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner/issues/172&#34; target=&#34;_blank&#34;&gt;sub-class the Spawner&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    from dockerspawner import DockerSpawner
    class MyDockerSpawner(DockerSpawner):
        team_map = {
            &#39;user1&#39;: &#39;team1&#39;,
            &#39;user2&#39;: &#39;team1&#39;,
            &#39;user3&#39;: &#39;team2&#39;,
        }

        def start(self):
            team = self.team_map[self.user.name]
            # add team volume to volumes
            self.volumes[&#39;jupyterhub-team-{}&#39;.format(team)] = {
                &#39;bind&#39;: &#39;/home/shared/{}&#39;.format(team),
                &#39;mode&#39;: &#39;rw&#39;,  # or ro for read-only
            }

    c.JupyterHub.spawner_class = MyDockerSpawner
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;new-server&#34;&gt;New Server&lt;/h2&gt;

&lt;p&gt;As root:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot;
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce

sudo groupadd docker
sudo usermod -aG docker $USER
# also add any users you want to be running docker. 
# I added `michael` on my machine. will have to log out/in to refresh group membership. 

sudo apt-get install -y docker-compose
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As user &lt;code&gt;michael&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd repos/
git clone git clone https://github.com/mathematicalmichael/hubsetup.git
cd hubsetup/

# make sure you clean up images/volumes/containers. I didn&#39;t have much there from before, did have hello-world.

docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This came up, may be a problem?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WARNING: The COMPOSE_PROJECT_NAME variable is not set. Defaulting to a blank string.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But it kept going&amp;hellip;&lt;/p&gt;

&lt;p&gt;but then.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR: Service &#39;jupyterlab&#39; failed to build: failed to register layer: Error processing tar file(exit status 1): write /opt/conda/lib/python3.6/site-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so: no space left on device
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I went ahead and deleted a couple GB of space by removing unused conda environments and Lucas&amp;rsquo; user account.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose up 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fairly sure this will fail because of a mis-specified IP address.
Should also enable security since now I have them on this server.&lt;/p&gt;

&lt;p&gt;the SSL is messing with me since I already have it set up on the server.&lt;/p&gt;

&lt;p&gt;trying to launch jupyterhub with dockerspawner with jupyterhub local install.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export DOCKER_JUPYTER_IMAGE=jupyter/datascience-notebook:7254cdcfa22b&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Okay well the hub worked and spawner did not.&lt;/p&gt;

&lt;p&gt;I dove into making a custom spawner (may be necessary?), but it was a rabbit hole.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note from 1/8/19:&lt;/em&gt; The image needs to be available on the machine. It is separate from the hub, so just make sure the names line up correctly by checking &lt;code&gt;docker images&lt;/code&gt; against the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-2-3-2019&#34;&gt;Jan 2-3, 2019&lt;/h1&gt;

&lt;p&gt;See &lt;a href=&#34;https://www.michaelpilosov.com/devlog/proxy&#34;&gt;proxy&lt;/a&gt; page.&lt;/p&gt;

&lt;h2 id=&#34;useful-reading&#34;&gt;Useful Reading&lt;/h2&gt;

&lt;p&gt;Here is something interesting for version-controlling notebooks.
&lt;a href=&#34;https://github.com/mwouts/jupytext&#34; target=&#34;_blank&#34;&gt;https://github.com/mwouts/jupytext&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is an introduction to the notebook format.
&lt;a href=&#34;https://nbformat.readthedocs.io/en/latest/format_description.html&#34; target=&#34;_blank&#34;&gt;https://nbformat.readthedocs.io/en/latest/format_description.html&lt;/a&gt;
&lt;em&gt;TODO:&lt;/em&gt; You should turn this into a write-up.&lt;/p&gt;

&lt;p&gt;The basic examples in here are actually a great demo of publishing LaTeX documents right from Jupyter.
&lt;a href=&#34;https://github.com/jupyter/nbconvert-examples&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/nbconvert-examples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nice article
&lt;a href=&#34;https://blog.dominodatalab.com/data-science-vs-engineering-tension-points/&#34; target=&#34;_blank&#34;&gt;https://blog.dominodatalab.com/data-science-vs-engineering-tension-points/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might be how to set up binderhub on your own &amp;ndash; minikube
&lt;a href=&#34;https://github.com/jupyterhub/binderhub/blob/master/CONTRIBUTING.md&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/binderhub/blob/master/CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Other Projects for sharing results:
&lt;a href=&#34;https://github.com/minrk/thebelab&#34; target=&#34;_blank&#34;&gt;https://github.com/minrk/thebelab&lt;/a&gt;
&lt;a href=&#34;https://github.com/QuantStack/voila&#34; target=&#34;_blank&#34;&gt;https://github.com/QuantStack/voila&lt;/a&gt;
Write about them in a new section summarizing sharing results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jupyter/dashboards&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/dashboards&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Adding extra libraries to the jupyter-stacks image
&lt;a href=&#34;https://github.com/binder-examples/jupyter-stacks&#34; target=&#34;_blank&#34;&gt;https://github.com/binder-examples/jupyter-stacks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Allowing students to get latest files without knowing git
&lt;a href=&#34;https://github.com/jupyterhub/nbgitpuller&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/nbgitpuller&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When a link is clicked, we try to make opinionated intelligent guesses on how to do a merge automatically, without making the user do a conflict resolution. nbgitpuller is designed to be used by folks who do not know that git is being used underneath, and are only pulling content one way from a source and modifying it - not pushing it back. So we have made the following opinionated decisions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If content has changed in both places, prefer local changes over remote changes.&lt;/li&gt;
&lt;li&gt;If a file was deleted locally but present in the remote, remote file is restored to local repository. This allows users to get a &amp;lsquo;fresh copy&amp;rsquo; of a file by just deleting the file locally &amp;amp; clicking the link again.&lt;/li&gt;
&lt;li&gt;If a file exists locally but is untracked by git (maybe someone uploaded it manually), then rename the file, and pull in remote copy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hippylib-Hub, example to follow.
&lt;a href=&#34;https://github.com/g2s3-2018/hippylib-hub&#34; target=&#34;_blank&#34;&gt;https://github.com/g2s3-2018/hippylib-hub&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;dockerspawner&#34;&gt;Dockerspawner&lt;/h2&gt;

&lt;p&gt;Want:
    - Dockerspawner is nice (can restart hub without issues).
    - Although, restarting if all-in-one isn&amp;rsquo;t that bad, either. Temporary inconvenience.&lt;/p&gt;

&lt;p&gt;Add this to installations!!! It&amp;rsquo;s amazing.
&lt;a href=&#34;https://github.com/yuvipanda/nbresuse&#34; target=&#34;_blank&#34;&gt;https://github.com/yuvipanda/nbresuse&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might be a good thing to test on our server.
&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/&#34; target=&#34;_blank&#34;&gt;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;USEFUL: in Vim:
&lt;code&gt;r:! openssl rand -hex 32&lt;/code&gt; will paste a token into a file like &lt;code&gt;config.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;proxy:
    secretToken: xxxx
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;file-storage&#34;&gt;File Storage&lt;/h2&gt;

&lt;p&gt;Wow I can&amp;rsquo;t believe this exists.
&lt;a href=&#34;https://www.katacoda.com/&#34; target=&#34;_blank&#34;&gt;https://www.katacoda.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a good file-storage solution
&lt;a href=&#34;https://www.youtube.com/watch?v=hqE5c5pyfrk&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/watch?v=hqE5c5pyfrk&lt;/a&gt;
&lt;a href=&#34;https://storageos.com/developers/&#34; target=&#34;_blank&#34;&gt;https://storageos.com/developers/&lt;/a&gt;
another alternative, which appears to be a bit more complicated to set-up (though helm-chart should be available by now), but is open-source and from redhat: &lt;a href=&#34;https://www.youtube.com/watch?v=Fgpr2lMnBVY&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/watch?v=Fgpr2lMnBVY&lt;/a&gt; [16:30]&lt;/p&gt;

&lt;h2 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;

&lt;p&gt;Kubernetes 101 introduction
&lt;a href=&#34;https://medium.com/google-cloud/kubernetes-101-pods-nodes-containers-and-clusters-c1509e409e16&#34; target=&#34;_blank&#34;&gt;https://medium.com/google-cloud/kubernetes-101-pods-nodes-containers-and-clusters-c1509e409e16&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The monitoring of my memory usage led me to discover that repeated execution of plotting cells led to memory usage going through the roof. The solution was to add this cell-magic to the top of any plotting-cell: &lt;code&gt;%reset -f out&lt;/code&gt;. What this does is purge the output of the cell&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-4-5-2019&#34;&gt;Jan 4-5, 2019&lt;/h1&gt;

&lt;p&gt;Tried and failed to get Traefik working. See &lt;a href=&#34;https://www.michaelpilosov.com/devlog/proxy&#34;&gt;proxy&lt;/a&gt; notes. Took some time to relax.&lt;/p&gt;

&lt;p&gt;Note&lt;/p&gt;

&lt;p&gt;If you base a Dockerfile on this image:&lt;/p&gt;

&lt;p&gt;FROM juptyerhub/jupyterhub-onbuild:0.6
&amp;hellip;
then your jupyterhub_config.py adjacent to your Dockerfile will be loaded into the image and used by JupyterHub.&lt;/p&gt;

&lt;h2 id=&#34;file-permissions&#34;&gt;File permissions&lt;/h2&gt;

&lt;p&gt;Correct permissions for exposed shared directories require
&lt;code&gt;chmod -R 777&lt;/code&gt; for the folder at the top&lt;/p&gt;

&lt;p&gt;What this means:&lt;/p&gt;

&lt;p&gt;Permissions:
1 – can execute
2 – can write
4 – can read&lt;/p&gt;

&lt;p&gt;The octal number is the sum of those free permissions, i.e.
3 (1+2) – can execute and write
6 (2+4) – can write and read&lt;/p&gt;

&lt;p&gt;Position of the digit in value:
1 – what owner can
2 – what users in the file group(class) can
3 – what users &lt;em&gt;not&lt;/em&gt; in the file group(class) can&lt;/p&gt;

&lt;p&gt;So the third is what we care about since no we don&amp;rsquo;t want to create users on the machine running docker.&lt;/p&gt;

&lt;h2 id=&#34;database&#34;&gt;Database&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyterhub.readthedocs.io/en/stable/reference/database.html&#34; target=&#34;_blank&#34;&gt;https://jupyterhub.readthedocs.io/en/stable/reference/database.html&lt;/a&gt;
It comes pre-packaged with one, but it is recommended to use something else for production, which we will do!&lt;/p&gt;

&lt;p&gt;Hash authentication&amp;hellip; Very nice
&lt;a href=&#34;https://github.com/thedataincubator/jupyterhub-hashauthenticator&#34; target=&#34;_blank&#34;&gt;https://github.com/thedataincubator/jupyterhub-hashauthenticator&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can generate a good &lt;code&gt;secret key&lt;/code&gt; with &lt;code&gt;openssl rand -hex 32&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.authenticator_class = &#39;hashauthenticator.HashAuthenticator&#39;
c.HashAuthenticator.secret_key = &#39;my secret key&#39;  # Defaults to &#39;&#39;
c.HashAuthenticator.password_length = 10          # Defaults to 6
c.HashAuthenticator.show_logins = True            # Optional, defaults to False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the &lt;code&gt;show_logins&lt;/code&gt; option is set to &lt;code&gt;True&lt;/code&gt;, a CSV file containing login names and passwords will be served (to admins only) at &lt;code&gt;/hub/login_list&lt;/code&gt;. &lt;em&gt;Do we want this?&lt;/em&gt; Maybe for analytics? If possible.&lt;/p&gt;

&lt;p&gt;To figure out my password, I used
&lt;code&gt;hashauthpw --length 10 mathematicalmichael [secret key]&lt;/code&gt; on any computer that has run &lt;code&gt;pip install jupyterhub-hashauthenticator&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;multiple-spawners&#34;&gt;Multiple Spawners&lt;/h2&gt;

&lt;p&gt;multiple spawners! definitely my favorite way to go. Says this will allow them to choose upon login.
If so&amp;hellip; amazing.&lt;/p&gt;

&lt;p&gt;[multiple spawners issue on github][&lt;a href=&#34;https://github.com/jupyterhub/dockerspawner/issues/236]:&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/dockerspawner/issues/236]:&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dockerspawner import SystemUserSpawner

class MultiDockerImageSpawner(SystemUserSpawner):
    images = {
        &#39;SciPy&#39;: &#39;jupyter/scipy-notebook:0f73f7488fa0&#39;,
        &#39;Tensorflow&#39;: &#39;jupyter/tensorflow-notebook:59904dd7776a&#39;,
        &#39;R&#39;: &#39;jupyter/r-notebook:59904dd7776a&#39;,
    }
    def _options_form_default(self):
        outval = &amp;quot;&amp;quot;&amp;quot;
        &amp;lt;label for=&amp;quot;image&amp;quot;&amp;gt;Docker Image&amp;lt;/label&amp;gt;
        &amp;lt;select name=&amp;quot;image&amp;quot;&amp;gt;
        &amp;quot;&amp;quot;&amp;quot;
        for name, image in self.images.items():
            outval += &amp;quot;&amp;lt;option value=\&amp;quot;%s\&amp;quot;&amp;gt;%s (%s)&amp;lt;/option&amp;gt;&amp;quot; % (name, name, image)

        outval += &amp;quot;&amp;quot;&amp;quot;
        &amp;lt;/select&amp;gt;
        &amp;quot;&amp;quot;&amp;quot;
        return outval

    def options_from_form(self, formdata):
        options = {}
        options[&#39;image&#39;] = formdata.get(&#39;image&#39;, [&#39;SciPy&#39;])[0]
        self.image = self.images[options[&#39;image&#39;]]
        return options
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Everything is now up and running! New images can be added with total ease, the hub restart only has minimal disruption.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A note on startup files:&lt;/em&gt;
&amp;gt; IPython startup files, placed in ~/.ipython/profile_default/startup will be executed. These can be Python scripts (.py) or IPython scripts (.ipy with %magic commands). Notebooks aren&amp;rsquo;t supported as startup files, but if it really needs to be a notebook, you can use %run /path/to/notebook.ipynb in a .ipy startup file.&lt;/p&gt;

&lt;p&gt;This means that for testing, we can create an image with a file that gets run at startup, set it as the temporary default, and launch servers.&lt;/p&gt;

&lt;p&gt;I GOT RSTUDIO WORKING.
Okay, so just, build any image you want, and reference it in the spawner.
If you can execute the following and see the same output, you&amp;rsquo;ll have something working properly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mpilosov@math-ws-204:~/Packages/deploy/singleuser$ docker run --rm -ti rstudio_test
Executing the command: jupyter notebook
[I 22:39:24.130 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret
[I 22:39:24.745 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.7/site-packages/jupyterlab
[I 22:39:24.745 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab
[I 22:39:24.748 NotebookApp] Serving notebooks from local directory: /home/jovyan
[I 22:39:24.748 NotebookApp] The Jupyter Notebook is running at:
[I 22:39:24.748 NotebookApp] http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
[I 22:39:24.749 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 22:39:24.749 NotebookApp]

    Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
^C[I 22:39:36.445 NotebookApp] interrupted
Serving notebooks from local directory: /home/jovyan
0 active kernels
The Jupyter Notebook is running at:
http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
Shutdown this notebook server (y/[n])? ^C[C 22:39:37.364 NotebookApp] received signal 2, stopping
[I 22:39:37.366 NotebookApp] Shutting down 0 kernels
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-6-7-2019&#34;&gt;Jan 6-7, 2019&lt;/h1&gt;

&lt;h2 id=&#34;math-hub&#34;&gt;Math-hub&lt;/h2&gt;

&lt;p&gt;everything is up and running on math-hub,
100 notebooks idle take up 8gb of ram.&lt;/p&gt;

&lt;p&gt;I managed to mount volumes easily, but if you create a new volume with docker, use &lt;code&gt;docker inspect&lt;/code&gt; to find out where it is and change the permissions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pilosovm@math-hub:~/repos/deploy$ docker inspect rw_shared_volume
[
    {
        &amp;quot;CreatedAt&amp;quot;: &amp;quot;2019-01-04T17:57:04-07:00&amp;quot;,
        &amp;quot;Driver&amp;quot;: &amp;quot;local&amp;quot;,
        &amp;quot;Labels&amp;quot;: {},
        &amp;quot;Mountpoint&amp;quot;: &amp;quot;/var/lib/docker/volumes/rw_shared_volume/_data&amp;quot;,
        &amp;quot;Name&amp;quot;: &amp;quot;rw_shared_volume&amp;quot;,
        &amp;quot;Options&amp;quot;: {},
        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;
    }
]
pilosovm@math-hub:~/repos/deploy$ sudo chmod 777 /var/lib/docker/volumes/rw_shared_volume/_data
[sudo] password for pilosovm:
pilosovm@math-hub:~/repos/deploy$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;startup scripts: bootstrap scripts &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/tree/master/examples/bootstrap-script&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/jupyterhub/tree/master/examples/bootstrap-script&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-8-2019&#34;&gt;Jan 8, 2019&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.paraview.org/web/&#34; target=&#34;_blank&#34;&gt;https://www.paraview.org/web/&lt;/a&gt;
Paraview in-browser is now a thing&amp;hellip; Can we somehow create a container that includes the ability to launch this application?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html&#34; target=&#34;_blank&#34;&gt;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html&lt;/a&gt;
Jupyter Docker-Stacks&lt;/p&gt;

&lt;h2 id=&#34;python-2&#34;&gt;Python 2&lt;/h2&gt;

&lt;p&gt;Adding Python 2:
dd a Python 2.x environment
Python 2.x was removed from all images on August 10th, 2017, starting in tag cc9feab481f7. You can add a Python 2.x environment by defining your own Dockerfile inheriting from one of the images like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Choose your desired base image
FROM jupyter/scipy-notebook:latest

# Create a Python 2.x environment using conda including at least the ipython kernel
# and the kernda utility. Add any additional packages you want available for use
# in a Python 2 notebook to the first line here (e.g., pandas, matplotlib, etc.)
RUN conda create --quiet --yes -p $CONDA_DIR/envs/python2 python=2.7 ipython ipykernel kernda numpy pandas matplotlib ipywidgets yaml &amp;amp;&amp;amp; \
    conda clean -tipsy

USER root

# Create a global kernelspec in the image and modify it so that it properly activates
# the python2 conda environment.
RUN $CONDA_DIR/envs/python2/bin/python -m ipykernel install &amp;amp;&amp;amp; \
$CONDA_DIR/envs/python2/bin/kernda -o -y /usr/local/share/jupyter/kernels/python2/kernel.json

USER $NB_USER
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mixed-authentication&#34;&gt;Mixed Authentication&lt;/h2&gt;

&lt;p&gt;The main &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/wiki/Authenticators&#34; target=&#34;_blank&#34;&gt;authentication page&lt;/a&gt; on the Jupyterhub wiki is pretty useful but also kind of incomplete.&lt;/p&gt;

&lt;p&gt;Right now I am creating users based on the folders in &lt;code&gt;/home/math&lt;/code&gt;, authenticating with &lt;code&gt;HashAuthenticator&lt;/code&gt;, but &lt;a href=&#34;https://github.com/compmodels/jupyterhub/blob/master/docker_oauth.py&#34; target=&#34;_blank&#34;&gt;this example&lt;/a&gt; demonstrates how to mix Authentication methods.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;TO DO&lt;/em&gt;
Try &lt;a href=&#34;https://github.com/jupyterhub/oauthenticator#google-setup&#34; target=&#34;_blank&#34;&gt;google authentication&lt;/a&gt; on your own website.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-8-10-2019&#34;&gt;Jan 8-10, 2019&lt;/h1&gt;

&lt;h2 id=&#34;final-challenges&#34;&gt;Final Challenges&lt;/h2&gt;

&lt;p&gt;Proxy stress, user testing, configuration, security.&lt;/p&gt;

&lt;p&gt;I spoke with Audrey about setting up a hub.
She wants very clear set of instructions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-11-2019&#34;&gt;Jan 11, 2019&lt;/h1&gt;

&lt;h2 id=&#34;finishing-touches&#34;&gt;Finishing Touches&lt;/h2&gt;

&lt;p&gt;Need to write up an entire summary.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s what needs to happen:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Project Name (minimal changes)&lt;/li&gt;
&lt;li&gt;Document Process on Hub using newest version of repo.&lt;/li&gt;
&lt;li&gt;Nginx / Letsencrypt Instructions&lt;/li&gt;
&lt;li&gt;Re-do with math.computer on a new Droplet, screen cap?&lt;/li&gt;
&lt;li&gt;Wrap procedure into bash script?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Changes for a user to make to set up a new hub:
- touch &lt;code&gt;secrets/postgres.env&lt;/code&gt; and &lt;code&gt;touch userlist&lt;/code&gt;
- rename project folder &lt;em&gt;before&lt;/em&gt; running anything else.
- change &lt;code&gt;.env&lt;/code&gt; to reflect project name, include the port in there (no changes should be necessary to any other files)
- (optional) tweak limits in &lt;code&gt;jupyterhub_config.py&lt;/code&gt;
- (goal: no secrets, auth, etc). try to edit &lt;code&gt;makefile&lt;/code&gt; so that it takes care of all of that stuff. (or wrap into a &lt;code&gt;first_run.sh&lt;/code&gt; script).
- get password the first time? hashauth&amp;hellip; (or automate it so that it&amp;rsquo;s printed to a file)?&lt;/p&gt;

&lt;h2 id=&#34;customizing-spawning-options&#34;&gt;Customizing Spawning Options&lt;/h2&gt;

&lt;p&gt;Based on users&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dockerspawner import DockerSpawner
class MyDockerSpawner(DockerSpawner):
    team_map = {
        &#39;username1&#39;: &#39;team-a&#39;,
        &#39;username2&#39;: &#39;team-b&#39;,
        &#39;username3&#39;: &#39;team-a&#39;,
    }

    def start(self):
        if self.user.name in self.team_map:
            team = self.team_map[self.user.name]
            # add team volume to volumes
            self.volumes[&#39;/directory/jupyterhub-team-{}&#39;.format(team)] = {
                &#39;bind&#39;: &#39;/home/jovyan/teamfolder&#39;,
                &#39;mode&#39;: &#39;rw&#39;,  # or ro for read-only
            }
        return super().start()

c.JupyterHub.spawner_class = MyDockerSpawner
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, with that, refer to &lt;code&gt;jupyterhub_config.py&lt;/code&gt; for instances of &lt;code&gt;DockerSpawner&lt;/code&gt; and the children of that subclass. You can modify these properties (such as &lt;code&gt;image&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mathematicalmichael@math-hub:~$ docker images
REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
math-user                       latest              64698da59274        3 hours ago         11.5GB
math                            latest              7368bc798b20        4 hours ago         1.05GB
postgres                        9.5                 fc003c9dded6        29 hours ago        227MB
jupyter/datascience-notebook    latest              18c805bb3afb        3 days ago          6.32GB
jupyterhub/jupyterhub-onbuild   0.9.4               9ca16c1a77c3        3 months ago        812MB
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, my Disk-Usage on Digital Ocean reads 15GB. This tells me that &lt;code&gt;math-user&lt;/code&gt; includes the size &lt;code&gt;jupyter/datascience-notebook&lt;/code&gt;, since the sum of these two alone would exceed 15GB. &amp;lsquo;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Jan 15&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; Copying over from walkthrough.&lt;/p&gt;

&lt;p&gt;We will use this guy&amp;rsquo;s &lt;a href=&#34;https://medium.com/@pentacent/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71&#34; target=&#34;_blank&#34;&gt;walkthrough&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -L https://raw.githubusercontent.com/wmnnd/nginx-certbot/master/init-letsencrypt.sh &amp;gt; init-letsencrypt.sh
sed &#39;s/example.com/mathfight.club/g&#39; init-letsencrypt.sh &amp;gt; letsencrypt.sh
mv letsencrypt.sh init-letsencrypt.sh
chmod +x init-letsencrypt.sh
sudo ./init-letsencrypt.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Had to edit some lines, ran out of requests for letsencrypt.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Early Exploration with Docker &amp; Kubernetes</title>
      <link>https://www.michaelpilosov.com/devlog/docker/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/docker/</guid>
      <description>

&lt;p&gt;Dec 22, 2018
Today I began to structure and fill in the basic information for the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker&#34;&gt;Open Science/Docker&lt;/a&gt; Documentation.&lt;/p&gt;

&lt;p&gt;12/24/2019 - 01/01/2019&lt;/p&gt;

&lt;p&gt;Today I started by watching a video to be aware of the problems I might face going forward with JupyterHub.
I watched someone from Berkeley describe how they&amp;rsquo;ve scaled to thousands of users across many professors and managed to not grow their IT team while doing so.&lt;/p&gt;

&lt;p&gt;I will start by using this space here to take notes on the following video(s):&lt;/p&gt;

&lt;h2 id=&#34;deploying-jupyter-notebooks-for-students-and-researchers-pydata-2016&#34;&gt;Deploying Jupyter Notebooks for Students and Researchers (PyData 2016)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/gSVvxOchT8Y&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;managing-a-1000-student-jupyterhub-without-losing-your-sanity-jupytercon-2018&#34;&gt;Managing a 1000+ Student JupyterHub without Losing your Sanity (JupyterCon 2018)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/ivswAxysfTk&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Here are the stated goals in the video:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[7:30] Infrastructure Shouldn&amp;rsquo;t Bottleneck

&lt;ul&gt;
&lt;li&gt;Instructors should be able to install packages as needed&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[8:00] Anyone can Deploy

&lt;ul&gt;
&lt;li&gt;Treat Admins as Equal (grad students, teachers, etc)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[9:00] Automate Workflows

&lt;ul&gt;
&lt;li&gt;Avoid manual processes. No one-off scripts to bootstrap solutions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[9:30] Reduce Human Maintenance

&lt;ul&gt;
&lt;li&gt;Build on top of tools that already exist&lt;/li&gt;
&lt;li&gt;Let academic edit Dockerfile directly on Github, issue pull-request.&lt;/li&gt;
&lt;li&gt;Travis Process builds image, and if successful, requests to merge&lt;/li&gt;
&lt;li&gt;Rather than CLI, hit a couple buttons to set off other Travis Processes to update Helm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[13:55]: Reproducibility

&lt;ul&gt;
&lt;li&gt;Tag versions, everything.&lt;/li&gt;
&lt;li&gt;The release cycles of the core infrastructure components do not align with each other.&lt;/li&gt;
&lt;li&gt;In pip file, in Dockerfile, all of it.&lt;/li&gt;
&lt;li&gt;Get git hashes for latest commits.&lt;/li&gt;
&lt;li&gt;Tag Docker images with the hashes of the repositories that generated them&lt;/li&gt;
&lt;li&gt;This makes it much easier to re-deploy!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[15:30] Horror Story of Hub failing during Finals week because a Cloud bill was unpaid (grant ran out)

&lt;ul&gt;
&lt;li&gt;All the versioning helped saved them&lt;/li&gt;
&lt;li&gt;Despite coming up on different nodes, the same hub came out of it.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[17:00] Observability

&lt;ul&gt;
&lt;li&gt;Monitoring (container provider may have analytics)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;This may be less of a problem for us if we deploy on our own servers.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Figure out needs of students to figure out how many nodes.&lt;/li&gt;
&lt;li&gt;After observing, they noticed most students used under 1GB, allowing them to double capacity per node. Students that went above were writing runaway processes anyway.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[19:30] Incident Reporting

&lt;ul&gt;
&lt;li&gt;any time something goes down, write a report.&lt;/li&gt;
&lt;li&gt;[Incident Reports at Berkeley][github.com/data-8/infrastructure]&lt;/li&gt;
&lt;li&gt;Improves deployment.&lt;/li&gt;
&lt;li&gt;Event summary, timeline, conclusion, and action items.&lt;/li&gt;
&lt;li&gt;Reports are &amp;ldquo;blameless&amp;rdquo; to encourage transparency with relevant details&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[21:30] Generalization

&lt;ul&gt;
&lt;li&gt;Be a good open-source citizen&lt;/li&gt;
&lt;li&gt;This means digging into problems and reporting bugs&lt;/li&gt;
&lt;li&gt;Not every problem is your fault. Sometimes an upstream thing breaks it, and if you report it, you may save other people time/effort.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t rely on forks and custom patches. Contribute. Think about reproducible deployment scenarios.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[24:30] Contact Information (encouraged)

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;mailto:rylo@berkeley.edu&#34; target=&#34;_blank&#34;&gt;Ryan Lovett&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;mailto:yuvipanda@berkeley.edu&#34; target=&#34;_blank&#34;&gt;Yuvi Panda&lt;/a&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;scaling-jupyterhub-to-many-users-pydata-tel-aviv-2018&#34;&gt;Scaling JupyterHub to many users (PyData Tel-Aviv 2018)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/QN8T9zdnyLc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;jupyterhub-and-jupyterlab-perfect-together-pydata-2018&#34;&gt;&amp;ldquo;JupyterHub and JupyterLab: Perfect Together (PyData 2018)&amp;rdquo;&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/AXCo39qMn1E&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;jupyterhub-with-kubernetes&#34;&gt;JupyterHub with Kubernetes:&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/uiLUmuecU7I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;log&#34;&gt;Log&lt;/h2&gt;

&lt;p&gt;A lot of solutions exist for using docker to handle the file storage and user authentication.&lt;/p&gt;

&lt;p&gt;Here is the solution that I think will work best for workshops:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://opendreamkit.org/2018/10/17/jupyterhub-docker/&#34; target=&#34;_blank&#34;&gt;Open DreamKit&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[11:37 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;Okay, can&amp;rsquo;t confirm until I try it, but I am reasonably certain that while this set-up is useful in many contexts.
It doesn&amp;rsquo;t address the teacher/student/group collab management that we quite wanted (and that I focused on getting working first and have done already).
​&lt;/p&gt;

&lt;p&gt;[11:39 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;The way the build works here with data management is actually much &amp;ldquo;slimmer&amp;rdquo; in fact, and I think there&amp;rsquo;s a use for it for us for sure&amp;hellip; but I suspect it doesn&amp;rsquo;t allow two users to share data, or a super-user to poke around in files.
​&lt;/p&gt;

&lt;p&gt;[11:41 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;But it would allow for secure authentication for like, a workshop, just using people&amp;rsquo;s github accounts, and data-persistence and management would be more ideal in that sense since you can turn on permanence for each user, destroy it when the workshop is over as superuser (but without ever being able to poke around in their files, which is a nice security feature for the user I suppose&amp;hellip;).&lt;/p&gt;

&lt;p&gt;[11:52 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;In short, what we want instead is for docker to launch up a virtual LINUX machine, where all memory persists within the container.
It&amp;rsquo;s as if you set up a &amp;ldquo;new computer&amp;rdquo; for each class/workshop. Each class gets its own port.
Importantly, this makes &amp;ldquo;management&amp;rdquo; very familiar, identical to what you already know how to do, rather than having to &amp;ldquo;learn docker&amp;rdquo; to manage student&amp;rsquo;s work.
also, updating things can be done this way without re-building images through docker. which is really nice for on-the-fly changes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What&amp;rsquo;s the downside you ask?&lt;/em&gt;
It&amp;rsquo;s definitely less memory efficient, but it&amp;rsquo;s not a problem at all. we&amp;rsquo;re talking like&amp;hellip; cheap laptop levels of storage, nothing major.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[12:20 AM]
Finished watching the first video and going throught he tutorial above for the most part.
I still think the Linux within each container is the simplest option for someone to manage on their own.
it is definitely the most familiar environment.&lt;/p&gt;

&lt;p&gt;To start, let me &lt;code&gt;ssh&lt;/code&gt; into my workstation and see if I can revive the docker container from the summer workshop. I will log my commands here!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# start the server
docker run -td -p 80:8000 --name=labhub mathematicalmichael/labhub-test

# check that it is up
docker ps

# look for ip under process associated with your machine. look for 
# inet addr: &amp;lt;XXX.XXX.XXX.XXX&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we connect to auraria-anywhere via Cisco AnyConnect and attempt to connect to &lt;XXX.XXX.XXX.XXX&gt;:8000 via our browser.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;This site can&amp;rsquo;t be reached&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Debug mode:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker logs labhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;showed me that&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Creating 3 new users...
Created user0 with password Breckenridge0_g2s3
Created user1 with password Breckenridge1_g2s3
Created user2 with password Breckenridge2_g2s3
*** Running /etc/rc.local...
*** Booting runit daemon...
*** Runit started as PID 66
*** Running jupyterhub --Spawner.cmd=&#39;jupyter-labhub&#39; --no-ssl...
*** jupyterhub --Spawner.cmd=&#39;jupyter-labhub&#39; --no-ssl exited with status 127.
*** Shutting down runit daemon (PID 66)...
*** Killing all processes...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So that tells me I messed up the .Dockerfile.
It might be instructive to just learn from what they did. I don&amp;rsquo;t really need their libraries (which is what I believe was causing the build to fail before).&lt;/p&gt;

&lt;p&gt;** It will definitely be better to start with a fresh Linux image and go from there, since we want to build on top of the newest release anyway, and make sure we understand how its done, keep images/layers light. **&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;https://github.com/g2s3-2018/hippylib-hub&#34; target=&#34;_blank&#34;&gt;MUQ-Hippylib&lt;/a&gt; (see &lt;a href=&#34;https://bitbucket.org/mituq/&#34; target=&#34;_blank&#34;&gt;muq&lt;/a&gt; for more info)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM quay.io/fenicsproject/stable:2017.2.0.r3
MAINTAINER U. Villa

USER root

RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -yy pwgen npm nodejs-legacy python3-pip libgeos-dev&amp;amp;&amp;amp; \
    npm install -g configurable-http-proxy &amp;amp;&amp;amp; \
    pip3 install jupyterhub==0.8.1 &amp;amp;&amp;amp; \
    pip3 install ipython[notebook]==6.2.1 h5py pandas &amp;amp;&amp;amp; \
    pip install --user https://github.com/matplotlib/basemap/archive/master.zip

RUN apt-get clean &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

#RUN mkdir /etc/certs
#RUN touch /etc/certs/ssl.key
#RUN touch /etc/certs/ssl.crt
#RUN openssl req -x509 -nodes -days 730 -newkey rsa:2048 \
#                 -subj &amp;quot;/C=XY/ST=XYZ/L=XYZ/O=XYZ/CN=example.com&amp;quot; \
#                 -keyout /etc/certs/ssl.key -out /etc/certs/ssl.crt

USER fenics

# Install MUQ
RUN cd /home/fenics &amp;amp;&amp;amp; \
    mkdir Installations; mkdir Installations/MUQ_INSTALL &amp;amp;&amp;amp; \
    git clone --depth 1 https://bitbucket.org/mituq/muq2.git &amp;amp;&amp;amp; \
    cd muq2/; mkdir build; cd build;  \
    cmake -DCMAKE_INSTALL_PREFIX=/home/fenics/Installations/MUQ_INSTALL -DMUQ_USE_PYTHON=ON ../ &amp;amp;&amp;amp; \
    make install

# Install hIPPYlib
RUN cd /home/fenics/Installations &amp;amp;&amp;amp; \
    git clone https://github.com/hippylib/hippylib.git &amp;amp;&amp;amp; \
    chmod -R o+rx hippylib

# Copy the notebooks
RUN cd /home/fenics/Installations &amp;amp;&amp;amp; \
    git clone https://github.com/g2s3-2018/labs.git

COPY python3_config.json /usr/local/share/jupyter/kernels/python3/kernel.json
ENV LD_LIBRARY_PATH /home/fenics/Installations/MUQ_INSTALL/lib:/home/fenics/Installations/MUQ_INSTALL/muq_external/lib
ENV PYTHONPATH /home/fenics/Installations/MUQ_INSTALL/lib:/home/fenics/Installations/hippylib

USER root

COPY jupyterhub_config.py /home/fenics/jupyterhub_config.py
COPY make-users-std-password.sh /etc/my_init.d/make-users-std-password.sh
RUN chmod +x /etc/my_init.d/make-users-std-password.sh
RUN rm /etc/my_init.d/set-home-permissions.sh
COPY update_lab.sh /home/fenics/update_lab.sh
RUN chmod +x /home/fenics/update_lab.sh
RUN mkdir -p /home/fenics/.jupyter
COPY jupyter_notebook_config.py /home/fenics/.jupyter/jupyter_notebook_config.py


ENV NUMBER_OF_USERS 60
WORKDIR /home/fenics/
ENTRYPOINT [&amp;quot;/sbin/my_init&amp;quot;,&amp;quot;--&amp;quot;]
CMD [&amp;quot;jupyterhub&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So it appears that we&amp;rsquo;re starting with a root image from the Fenics Project.
&lt;a href=&#34;https://quay.io/repository/fenicsproject/stable?tag=latest&amp;amp;tab=tags&#34; target=&#34;_blank&#34;&gt;Quay.io&lt;/a&gt; has a summary of security vulnerabilities for each repository tag.&lt;/p&gt;

&lt;p&gt;The one used by Dr. Umberto Villa had 3 High-Risk Vulnerabilities and 151 fixable. More modern ones such as &lt;code&gt;2018.1.0.r3&lt;/code&gt; have only 57 Medium-Risk ones and 25 fixable.&lt;/p&gt;

&lt;p&gt;This is a considerable advantage and thus I believe the correct place to start from. It is also evident that the developers have been working on reducing image sizes, with a clear downward-trend each time a new one comes up.
The latest does also seem to be built on top of the Ubuntu 18.04, which is exactly what we wanted!!!&lt;/p&gt;

&lt;p&gt;Wonderful.&lt;/p&gt;

&lt;p&gt;Okay, but before I go on building my customized version[^builderrors], I want to remember how to get the &lt;code&gt;hippylib-muq&lt;/code&gt; one working. I have the Dockerhub image from &lt;code&gt;mparno/hippylib-muq&lt;/code&gt; and can run it (create an instance) with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -td -p 80:8000 --name=labhub mparno/muq-hippylib
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So this creates an instance that will map to port 80 (default address when you land on an IP, something we should map with sub-domains later on to have &lt;code&gt;classhub.math.ucdenver.edu&lt;/code&gt; rather than ports to memorize).
This &amp;ldquo;instance&amp;rdquo; (container) is now created and the ports mapped, so now we have to start it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker start labhub

# now can go to base IP address and log in! 

# later on... stop it.
docker stop labhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alright, that&amp;rsquo;s fine and well. We have a baseline set of instructions to go off now, and can learn from.
 However, seeing as quite a lot is happening in those instructions, and no SSL security has been established, I would like to perhaps instead start with Dockerfiles from the Jupyter Project. Moreover, these will be newer versions and should come with Lab enabled already since it is finally in a stable release.&lt;/p&gt;

&lt;p&gt;[^builderrors] I remember that some updates to MUQ&amp;hellip; likely because of a lack of pinning to specific releases, caused build errors when I tried to start up my labhub. Though it might have been the initial commands, based on the readout above.&lt;/p&gt;

&lt;p&gt;SO we&amp;rsquo;ll have to do two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Get Hub/Lab up and running with a single user based on the instructions from Project Jupyter.&lt;/li&gt;
&lt;li&gt;Use this on top of the Fenics build to get &lt;code&gt;import dolfin&lt;/code&gt; working inside of the Hub.&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; The ease of sharing memory for class-uses is actually a BRAND NEW effort from Jupyter (a week old?). &lt;a href=&#34;https://github.com/jupyterhub/hubshare&#34; target=&#34;_blank&#34;&gt;See here&lt;/a&gt;, which should remove the need for the solution we&amp;rsquo;re building, allow for much better and more lightweight scalability.&lt;/p&gt;

&lt;p&gt;I just came across &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner&#34; target=&#34;_blank&#34;&gt;dockerspawner&lt;/a&gt;
which can be enabled with the following in &lt;code&gt;jupyterhub_config.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.spawner_class = &#39;dockerspawner.DockerSpawner&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More appropriate for the use case we have is &lt;code&gt;SystemUserSpawner&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you want to spawn notebook servers for users that correspond to system users, you can use the SystemUserSpawner instead. Add the following to your jupyterhub_config.py:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c.JupyterHub.spawner_class = &#39;dockerspawner.SystemUserSpawner&#39;&lt;/code&gt;
The SystemUserSpawner will also need to know where the user home directories are on the host. By default, it expects them to be in &lt;code&gt;/home/&amp;lt;username&amp;gt;&lt;/code&gt;, but if you want to change this, you&amp;rsquo;ll need to further modify the &lt;code&gt;jupyterhub_config.py&lt;/code&gt;. For example, the following will look for a user&amp;rsquo;s home directory on the host system at &lt;code&gt;/volumes/user/&amp;lt;username&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.SystemUserSpawner.host_homedir_format_string = &#39;/volumes/user/{username}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a full example of how SystemUserSpawner is used, see the &lt;a href=&#34;https://github.com/jhamrick/compmodels-jupyterhub&#34; target=&#34;_blank&#34;&gt;compmodels-jupyterhub&lt;/a&gt; (warning: old) repository (this additionally runs the JupyterHub server within a docker container, and authenticates users using GitHub OAuth).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;I believe the correct entry-point for us will actually be &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, at Project Jupyter&amp;rsquo;s Deploy-Docker repository.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;jupyterhub-deploy-docker&lt;/code&gt; provides a reference deployment of JupyterHub, a multi-user Jupyter Notebook environment, on a single host using Docker.
This deployment is NOT intended for a production environment. It is a reference implementation that does not meet traditional requirements in terms of availability nor scalability.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker/raw/master/internal/jupyterhub-docker.png&#34; alt=&#34;schematic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Okay, so this is actually a great solution, but it&amp;rsquo;s the same thing more/less as the &amp;ldquo;french&amp;rdquo; solution, with the encryption being handled directly by Jupyterhub.&lt;/p&gt;

&lt;p&gt;Since we want to be building Linux images and then running a Hub on each one, we basically just need to paste installation instructions into the Dockerfile.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c conda-forge jupyterhub
conda install jupyterlab
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;docker-jupyter-stacks&#34;&gt;Docker Jupyter Stacks&lt;/h1&gt;

&lt;p&gt;However, I then came across &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;Jupyter Docker Stacks&lt;/a&gt;, which appear to be a number of recipes I can start with.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s go ahead and try this on the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Example 2: This command pulls the jupyter/datascience-notebook image tagged 3772fffc4aa4 from Docker Hub if it is not already present on the local host.
It then starts an ephemeral container running a Jupyter Notebook server and exposes the server on host port 10000. The command mounts the current working directory on the host as /home/jovyan/work in the container. The server logs appear in the terminal. Visiting http://&lt;hostname&gt;:10000/?token=&lt;token&gt; in a browser loads JupyterLab, where hostname is the name of the computer running docker and token is the secret token printed in the console. Docker destroys the container after notebook server exit, but any files written to ~/work in the container remain intact on the host.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm -p 10000:8888 -e JUPYTER_ENABLE_LAB=yes -v &amp;quot;$PWD&amp;quot;:/home/jovyan/work jupyter/datascience-notebook:3772fffc4aa4
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;My workstation was unable to find the image locally so it began to pull it from docker-cloud. &lt;em&gt;This took a moment.&lt;/em&gt; Appears to be several gb large.&lt;/p&gt;

&lt;p&gt;Okay, well I managed to connect to it by visiting &lt;code&gt;&amp;lt;IP&amp;gt;:10000/?token=XXXX...XXXX&lt;/code&gt;, where I grabbed the token from the output of the terminal window.&lt;/p&gt;

&lt;p&gt;This is great functionality, but it&amp;rsquo;s not the hub we&amp;rsquo;re looking for. That said, the &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;included dockerfiles&lt;/a&gt; are very instructive.&lt;/p&gt;

&lt;p&gt;Here is the dependency list. Each one is a root image of the next.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;base-notebook&lt;/code&gt; &amp;gt; &lt;code&gt;minimal-notebook&lt;/code&gt; &amp;gt;  &lt;code&gt;scipy-notebook&lt;/code&gt; &amp;gt; &lt;code&gt;datascience-notebook&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The last install, the [&lt;code&gt;datascience-notebook&lt;/code&gt;][&lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/datascience-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/docker-stacks/blob/master/datascience-notebook/Dockerfile&lt;/a&gt;] includes R and Julia on top of Python. The heavy &lt;code&gt;HDF5&lt;/code&gt; dependency for Julia is not included if the build is in test-mode (see line 10 and 73).
It will also link the kernels together.
As tempting as it is to start here, I&amp;rsquo;d like to start earlier.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/scipy-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy-notebook&lt;/code&gt;&lt;/a&gt; features installs of widgets and more, and is the minimum requirement for most of what we need.&lt;/p&gt;

&lt;p&gt;Something I noticed was that it includes an old version of pip.
If you launch the container, it mounts whatever directory you were in when you executed the &lt;code&gt;docker run&lt;/code&gt; command to a &amp;ldquo;fake one&amp;rdquo; inside docker (so &lt;code&gt;pwd&lt;/code&gt; returns &lt;code&gt;/home/jovyan/work&lt;/code&gt;).
This is actually kind of nice. If volumes of students can be mounted by the professor to have a look around, that would be great. That would, of course, require learning some docker.
Students can even install additional libraries as needed, but they will disappear next time they connect (though the files stick around!).&lt;/p&gt;

&lt;p&gt;What we need to do (I think), is merge this Dockerfile with the JupyterHub deployments. I think this just comes down to configuring the authenticator correctly (and referencing Umberto&amp;rsquo;s file above).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/base-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;base-notebook&lt;/code&gt;&lt;/a&gt;, since it seems that &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/scipy-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy-notebook&lt;/code&gt;&lt;/a&gt; just adds bells and whistles (widgets already is calling jupyterlab extension manager).
And yes, it appears hub is installed!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.

# Ubuntu 18.04 (bionic) from 2018-05-26
# https://github.com/docker-library/official-images/commit/aac6a45b9eb2bffb8102353c350d341a410fb169
ARG BASE_CONTAINER=ubuntu:bionic-20180526@sha256:c8c275751219dadad8fa56b3ac41ca6cb22219ff117ca98fe82b42f24e1ba64e
FROM $BASE_CONTAINER

LABEL maintainer=&amp;quot;Jupyter Project &amp;lt;jupyter@googlegroups.com&amp;gt;&amp;quot;
ARG NB_USER=&amp;quot;jovyan&amp;quot;
ARG NB_UID=&amp;quot;1000&amp;quot;
ARG NB_GID=&amp;quot;100&amp;quot;

USER root

# Install all OS dependencies for notebook server that starts but lacks all
# features (e.g., download as all possible file formats)
ENV DEBIAN_FRONTEND noninteractive
RUN apt-get update &amp;amp;&amp;amp; apt-get -yq dist-upgrade \
 &amp;amp;&amp;amp; apt-get install -yq --no-install-recommends \
    wget \
    bzip2 \
    ca-certificates \
    sudo \
    locales \
    fonts-liberation \
 &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

RUN echo &amp;quot;en_US.UTF-8 UTF-8&amp;quot; &amp;gt; /etc/locale.gen &amp;amp;&amp;amp; \
    locale-gen

# Configure environment
ENV CONDA_DIR=/opt/conda \
    SHELL=/bin/bash \
    NB_USER=$NB_USER \
    NB_UID=$NB_UID \
    NB_GID=$NB_GID \
    LC_ALL=en_US.UTF-8 \
    LANG=en_US.UTF-8 \
    LANGUAGE=en_US.UTF-8
ENV PATH=$CONDA_DIR/bin:$PATH \
    HOME=/home/$NB_USER

ADD fix-permissions /usr/local/bin/fix-permissions
# Create jovyan user with UID=1000 and in the &#39;users&#39; group
# and make sure these dirs are writable by the `users` group.
RUN groupadd wheel -g 11 &amp;amp;&amp;amp; \
    echo &amp;quot;auth required pam_wheel.so use_uid&amp;quot; &amp;gt;&amp;gt; /etc/pam.d/su &amp;amp;&amp;amp; \
    useradd -m -s /bin/bash -N -u $NB_UID $NB_USER &amp;amp;&amp;amp; \
    mkdir -p $CONDA_DIR &amp;amp;&amp;amp; \
    chown $NB_USER:$NB_GID $CONDA_DIR &amp;amp;&amp;amp; \
    chmod g+w /etc/passwd &amp;amp;&amp;amp; \
    fix-permissions $HOME &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR

USER $NB_UID

# Setup work directory for backward-compatibility
RUN mkdir /home/$NB_USER/work &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install conda as jovyan and check the md5 sum provided on the download site
ENV MINICONDA_VERSION 4.5.11
RUN cd /tmp &amp;amp;&amp;amp; \
    wget --quiet https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \
    echo &amp;quot;e1045ee415162f944b6aebfe560b8fee *Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh&amp;quot; | md5sum -c - &amp;amp;&amp;amp; \
    /bin/bash Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p $CONDA_DIR &amp;amp;&amp;amp; \
    rm Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --prepend channels conda-forge &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --set auto_update_conda false &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --set show_channel_urls true &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda install --quiet --yes conda=&amp;quot;${MINICONDA_VERSION%.*}.*&amp;quot; &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda update --all --quiet --yes &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    rm -rf /home/$NB_USER/.cache/yarn &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install Tini
RUN conda install --quiet --yes &#39;tini=0.18.0&#39; &amp;amp;&amp;amp; \
    conda list tini | grep tini | tr -s &#39; &#39; | cut -d &#39; &#39; -f 1,2 &amp;gt;&amp;gt; $CONDA_DIR/conda-meta/pinned &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install Jupyter Notebook, Lab, and Hub
# Generate a notebook server config
# Cleanup temporary files
# Correct permissions
# Do all this in a single RUN command to avoid duplicating all of the
# files across image layers when the permissions change
RUN conda install --quiet --yes \
    &#39;notebook=5.7.2&#39; \
    &#39;jupyterhub=0.9.4&#39; \
    &#39;jupyterlab=0.35.4&#39; &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    jupyter labextension install @jupyterlab/hub-extension@^0.12.0 &amp;amp;&amp;amp; \
    npm cache clean --force &amp;amp;&amp;amp; \
    jupyter notebook --generate-config &amp;amp;&amp;amp; \
    rm -rf $CONDA_DIR/share/jupyter/lab/staging &amp;amp;&amp;amp; \
    rm -rf /home/$NB_USER/.cache/yarn &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

USER root

EXPOSE 8888
WORKDIR $HOME

# Configure container startup
ENTRYPOINT [&amp;quot;tini&amp;quot;, &amp;quot;-g&amp;quot;, &amp;quot;--&amp;quot;]
CMD [&amp;quot;start-notebook.sh&amp;quot;]

# Add local files as late as possible to avoid cache busting
COPY start.sh /usr/local/bin/
COPY start-notebook.sh /usr/local/bin/
COPY start-singleuser.sh /usr/local/bin/
COPY jupyter_notebook_config.py /etc/jupyter/
RUN fix-permissions /etc/jupyter/

# Switch back to jovyan to avoid accidental container runs as root
USER $NB_UID
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It seems that the implementation at the &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deploy-Docker&lt;/a&gt; repository actually handles multi-users, and you can CHOOSE ANY OF the aforementioned builds from &lt;a href=&#34;https://hub.docker.com/u/jupyter&#34; target=&#34;_blank&#34;&gt;Jupyter&amp;rsquo;s Page on Docker Cloud&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think I will try this approach. The key difference here is that users are isolated through where docker mounts their directories, not through permissions.&lt;/p&gt;

&lt;p&gt;So the idea is that you have a Linux machine running docker. All the students files are in some directory there. The Hub spawns up a Docker container on-demand for each student, mounting them appropriately. A teacher can access the files since they are simply the user that is using Docker. (anyone with sudo permissions on the UNIX machine? or just part of the correct usergroup? Joe can help there.) When the teachers log in, their accounts get mounted in a place they can see the whole class, but not other instructor&amp;rsquo;s classes!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Virtualization can be used to segment classes, or they can run together. It doesn&amp;rsquo;t matter. Port-forwarding with sub-addresses can be used to direct to the correct hub for login. One hub runs per class. One docker instance manages all the hubs.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m going to try it this way first, rather than the isolated UNIX-machine way.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;the-correct-way&#34;&gt;The &amp;ldquo;Correct Way&amp;rdquo;&lt;/h1&gt;

&lt;p&gt;We will be using &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;dockerspawner&lt;/code&gt;&lt;/a&gt;, and the directions in their &lt;code&gt;README&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Actually&amp;hellip;&lt;/em&gt;
It seems this is what the point of &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deploy Docker&lt;/a&gt; is. Slight modifications are made so that the &lt;code&gt;dockerspawner&lt;/code&gt; launches up our chosen base-image!&lt;/p&gt;

&lt;p&gt;Choose a pinned image on &lt;a href=&#34;https://hub.docker.com/u/jupyter&#34; target=&#34;_blank&#34;&gt;docker cloud&lt;/a&gt; based on the builds from the &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;stacks on github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since we really need all the stuff included in the  &lt;a href=&#34;https://hub.docker.com/r/jupyter/scipy-notebook/tags&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy&lt;/code&gt;&lt;/a&gt; stack, and these images are no smaller than 2GB, we might as well spring for the &lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/tags&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;datascience&lt;/code&gt;&lt;/a&gt; stack since they are the same size and include R and Julia, which our colleagues may appreciate.&lt;/p&gt;

&lt;p&gt;As of this writing, here is a recent tag: &lt;code&gt;7254cdcfa22b&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;when running, be aware that no sudo priviledges will be granted. &lt;code&gt;-e GRANT_SUDO=yes&lt;/code&gt; needs to be included upon docker run.&lt;/p&gt;

&lt;p&gt;So, following the Deploy-Docker Dockerfile, I can see that it is running relatively recent versions of &lt;code&gt;jupyterhub&lt;/code&gt; and &lt;code&gt;dockerspawner&lt;/code&gt;, despite many files being unchanged for years. That&amp;rsquo;s actually kind of promising for maintenance purposes.&lt;/p&gt;

&lt;p&gt;Starting from Zero&amp;hellip; SSH into my main machine. Move into a directory to perform the cloning. Needed to first run&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo apt install docker-compose&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/jupyterhub/jupyterhub-deploy-docker.git
cd jupyterhub-deploy-docker

mkdir -p secrets
cd secrets
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout mykey.key -out mycert.pem

# bad idea?
mv mycert.pem jupyterhub.crt 
mv mykey.key jupyterhub.key

cd ..
mv .env

# change line 19 to 
DOCKER_NOTEBOOK_IMAGE=jupyter/datascience-notebook:7254cdcfa22b

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;jupyterhub_config.py&lt;/code&gt; add the lines&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.DockerSpawner.environment = { &#39;JUPYTER_ENABLE_LAB&#39;: &#39;yes&#39; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we face the authentication problem. We did generate a self-signed cert (hopefully), but the IP address of my workstation is not public. For extra security, best to keep it this way.&lt;/p&gt;

&lt;p&gt;We want to change authentication to users&amp;hellip;
The problem is that I don&amp;rsquo;t want to be setting up github users accounts. Lines 56-57 in &lt;code&gt;juptyerhub_config.py&lt;/code&gt; are the problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.authenticator_class = &#39;oauthenticator.GitHubOAuthenticator&#39;
c.GitHubOAuthenticator.oauth_callback_url = os.environ[&#39;OAUTH_CALLBACK_URL&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;I think by commenting it out, PAMAuthenticator is default. Should be good enough?&lt;/em&gt;
Well now if we change this we will have to create user accounts to log in with.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create a userlist file in the root directory &lt;code&gt;vim userlist&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;michael admin
troy admin
varis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to actually create these users. Let&amp;rsquo;s see how this was done in &lt;code&gt;hippylib-hub&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

echo &amp;quot;Update Lab materials from GitHub&amp;quot;
cd /home/fenics/Installations/labs &amp;amp;&amp;amp; git pull

echo &amp;quot;Creating ${NUMBER_OF_USERS} new users...&amp;quot;
for ((i = 0; i &amp;lt; ${NUMBER_OF_USERS}; i++));
do
    password=&amp;quot;Breckenridge${i}_g2s3&amp;quot;
    useradd &amp;quot;user${i}&amp;quot; -m -s /bin/bash
    echo &amp;quot;user${i}:${password}&amp;quot; | chpasswd user${i}
    
    cp -rf /home/fenics/.jupyter /home/user${i}/.jupyter
    chown -R user${i} /home/user${i}/.jupyter
    chmod -R u+rX /home/user${i}/.jupyter
    
    cp -r /home/fenics/Installations/labs/Labs /home/user${i}/
    chown -R user${i} /home/user${i}/Labs
    chmod -R u+rX /home/user${i}/Labs
 
    echo &amp;quot;Created user${i} with password ${password}&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So we have to translate this into our &lt;code&gt;Dockerfile.jupyterhub&lt;/code&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.
ARG JUPYTERHUB_VERSION
FROM jupyterhub/jupyterhub-onbuild:$JUPYTERHUB_VERSION

# Install dockerspawner, oauth, postgres
RUN /opt/conda/bin/conda install -yq psycopg2=2.7 &amp;amp;&amp;amp; \
    /opt/conda/bin/conda clean -tipsy &amp;amp;&amp;amp; \
    /opt/conda/bin/pip install --no-cache-dir \
        oauthenticator==0.8.* \
        dockerspawner==0.9.*

# We make additions here.
RUN useradd michael -m -s /bin/bash
RUN echo &amp;quot;michael:test_password&amp;quot; | chpasswd michael
RUN echo &amp;quot;Created user Michael&amp;quot;

# Copy TLS certificate and key
ENV SSL_CERT /srv/jupyterhub/secrets/jupyterhub.crt
ENV SSL_KEY /srv/jupyterhub/secrets/jupyterhub.key
COPY ./secrets/*.crt $SSL_CERT
COPY ./secrets/*.key $SSL_KEY
RUN chmod 700 /srv/jupyterhub/secrets &amp;amp;&amp;amp; \
    chmod 600 /srv/jupyterhub/secrets/*

COPY ./userlist /srv/jupyterhub/userlist
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try it?? The instructions say all I need now is to run &lt;code&gt;make build&lt;/code&gt; in the root directory.&lt;/p&gt;

&lt;p&gt;Failed. Commenting out lines referencing GitHub in &lt;code&gt;Makefile&lt;/code&gt; (lines 23-24) and &lt;code&gt;secrets/oauth.env&lt;/code&gt; (line 48).&lt;/p&gt;

&lt;p&gt;I dont have any clue what is going on in the secrets files. Doing my best but unable to make it work.&lt;/p&gt;

&lt;p&gt;Okay let&amp;rsquo;s try this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -p 8000:8000 -d --name jupyterhub jupyterhub/jupyterhub jupyterhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My errors seem to be caused by outdated docker. Since I was running on 16.04, the apt repositories didn&amp;rsquo;t have newer versions, so I needed to manually add the updates:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot;
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;after setting
&lt;code&gt;ARG JUPYTERHUB_VERSION=0.90&lt;/code&gt; in the header, I was able to finally run &lt;code&gt;make build&lt;/code&gt; (but who knows how it will work).&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s no particular reason Hub has to run in a docker container. It can still spawn up new processes with docker.&lt;/p&gt;

&lt;p&gt;Once &lt;code&gt;make build&lt;/code&gt; finished, I had to run &lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker ps&lt;/code&gt; revealed two containers. One is a database of some sort (what was causing me trouble with installation earlier before I faked the files).&lt;/p&gt;

&lt;p&gt;Logs are showing me that my problem is indeed with &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt; &amp;hellip; and this part is certainly a bit above my paygrade.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker</title>
      <link>https://www.michaelpilosov.com/openscience/docker/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/docker/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#images&#34;&gt;Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#containers&#34;&gt;Containers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#comparison-to-virtual-machines&#34;&gt;Comparison to Virtual Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install&#34;&gt;Install&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#linux&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#macos&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#configure&#34;&gt;Configure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#permissions&#34;&gt;Permissions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#start-on-boot&#34;&gt;Start on boot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#re-route-ip&#34;&gt;Re-route IP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ip-forwarding&#34;&gt;IP Forwarding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limiting&#34;&gt;Limiting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#security&#34;&gt;Security&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#security-tips&#34;&gt;Security Tips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deployment&#34;&gt;Deployment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#making-docker-safe-for-production&#34;&gt;Making Docker Safe for Production&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#port-exposal&#34;&gt;Port-Exposal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more&#34;&gt;More&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#user-namespaces&#34;&gt;User Namespaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-security-roadmap&#34;&gt;The Security Roadmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#security-videos&#34;&gt;Security Videos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cheat-sheet&#34;&gt;Cheat Sheet&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#images-1&#34;&gt;Images&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-up&#34;&gt;Cleaning up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-save-image&#34;&gt;Load/Save image&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#layers&#34;&gt;Layers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#containers-1&#34;&gt;Containers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-1&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#starting-and-stopping&#34;&gt;Starting and Stopping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-1&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#import-export&#34;&gt;Import / Export&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#executing-commands&#34;&gt;Executing Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#container-import-export&#34;&gt;Container Import/Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#management&#34;&gt;Management&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cpu-constraints&#34;&gt;CPU Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#memory-constraints&#34;&gt;Memory Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#capabilities&#34;&gt;Capabilities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dockerfile&#34;&gt;Dockerfile&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#instructions&#34;&gt;Instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#networks&#34;&gt;Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-2&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-2&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connection&#34;&gt;Connection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#registries&#34;&gt;Registries&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#registries-v-repositories&#34;&gt;Registries v. Repositories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-local-registry&#34;&gt;Run local registry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#volumes&#34;&gt;Volumes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-3&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-3&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#useful-commands-tips&#34;&gt;Useful Commands/Tips&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#versions&#34;&gt;Versions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basics&#34;&gt;Basics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#get-ip-address&#34;&gt;Get IP Address&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#get-port-mapping&#34;&gt;Get Port Mapping&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#general&#34;&gt;General&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#find-containers-using-regular-expression&#34;&gt;Find containers using regular expression:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#get-environment-settings&#34;&gt;Get environment settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kill-running-containers&#34;&gt;Kill running containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-all-containers-force-running-or-stopped-containers&#34;&gt;Delete all containers (force!! running or stopped containers)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-old-containers&#34;&gt;Delete old containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-stopped-containers&#34;&gt;Delete stopped containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-containers-after-stopping&#34;&gt;Delete containers after stopping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-dangling-images&#34;&gt;Delete dangling images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-all-images&#34;&gt;Delete all images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-dangling-volumes&#34;&gt;Delete dangling volumes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#show-image-dependencies&#34;&gt;Show image dependencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#df&#34;&gt;df&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#heredoc-docker-container&#34;&gt;Heredoc Docker Container&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prune&#34;&gt;Prune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#last-ids&#34;&gt;Last Ids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#commit&#34;&gt;Commit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monitoring&#34;&gt;Monitoring&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#monitor-system-resource-utilization-for-running-containers&#34;&gt;Monitor system resource utilization for running containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#volumes-can-be-files&#34;&gt;Volumes can be files&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#efficiency&#34;&gt;Efficiency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#best-practices&#34;&gt;Best Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;From the &lt;a href=&#34;https://docs.docker.com/get-started/&#34; target=&#34;_blank&#34;&gt;Docker Documentation&lt;/a&gt;:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. &amp;gt; The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is.&lt;/p&gt;

&lt;p&gt;Containerization is increasingly popular because containers are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flexible: Even the most complex applications can be containerized.&lt;/li&gt;
&lt;li&gt;Lightweight: Containers leverage and share the host kernel.&lt;/li&gt;
&lt;li&gt;Interchangeable: You can deploy updates and upgrades on-the-fly.&lt;/li&gt;
&lt;li&gt;Portable: You can build locally, deploy to the cloud, and run anywhere.&lt;/li&gt;
&lt;li&gt;Scalable: You can increase and automatically distribute container replicas.&lt;/li&gt;
&lt;li&gt;Stackable: You can stack services vertically and on-the-fly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;images&#34;&gt;Images&lt;/h2&gt;

&lt;p&gt;An image is a collection of files (a package) that is executable.
It has &lt;strong&gt;all the files&lt;/strong&gt; necessary to run an application, from dependencies to configuration files.&lt;/p&gt;

&lt;p&gt;It is analogous to a &lt;code&gt;class&lt;/code&gt; from object-oriented programming.&lt;/p&gt;

&lt;h2 id=&#34;containers&#34;&gt;Containers&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;A &lt;strong&gt;container&lt;/strong&gt; is a runtime instance of an image,&amp;rdquo; or in other words, it is an instance of a class.
One image can be used to &amp;ldquo;spin up&amp;rdquo; many containers.
A container is what an image becomes (in the computer&amp;rsquo;s memory) when it is launched.
It is a user process with a state and need for access to resources.&lt;/p&gt;

&lt;p&gt;Docker being a &amp;ldquo;machine&amp;rdquo; of sorts, it has its own processes, which happen to be instances of images&amp;ndash;containers.&lt;/p&gt;

&lt;p&gt;Just as you would in Linux, you can see a list of your running containers by issuing &lt;code&gt;(sudo) docker ps&lt;/code&gt; (more on that soon).&lt;/p&gt;

&lt;h3 id=&#34;comparison-to-virtual-machines&#34;&gt;Comparison to Virtual Machines&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight.&lt;/p&gt;

&lt;p&gt;By contrast, a virtual machine (VM) runs a full-blown “guest” operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here is a Virtual Machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.docker.com/images/VM%402x.png&#34; alt=&#34;container-vm-comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And here is a Container:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.docker.com/images/Container%402x.png&#34; alt=&#34;container-vm-comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how Docker sits atop the Host Operating System &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:os-footnote&#34;&gt;&lt;a href=&#34;#fn:os-footnote&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and is performing the management role of resources among applications in place of a &amp;ldquo;hypervisor&amp;rdquo; from a Virtual Machine.&lt;/p&gt;

&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;

&lt;p&gt;Here is the &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Cheatsheet&lt;/a&gt; from which I will be pulling much of what is in this post.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;install&#34;&gt;Install&lt;/h1&gt;

&lt;h2 id=&#34;linux&#34;&gt;Linux&lt;/h2&gt;

&lt;p&gt;Quick and easy install script provided by Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -sSL https://get.docker.com/ | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;From the author of the cheatsheet:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re not willing to run a random shell script, please see the &lt;a href=&#34;https://docs.docker.com/engine/installation/linux/&#34; target=&#34;_blank&#34;&gt;installation&lt;/a&gt; instructions for your distribution.
If you are a complete Docker newbie, you should follow the &lt;a href=&#34;https://docs.docker.com/engine/getstarted/&#34; target=&#34;_blank&#34;&gt;series of tutorials&lt;/a&gt; now.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;macos&#34;&gt;macOS&lt;/h2&gt;

&lt;p&gt;Download and install &lt;a href=&#34;https://www.docker.com/community-edition&#34; target=&#34;_blank&#34;&gt;Docker Community Edition&lt;/a&gt;. if you have Homebrew-Cask, just type &lt;code&gt;brew cask install docker&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve installed Docker Community Edition, click the docker icon in Launchpad. Then start up a container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; You may have to restart your shell session (either by closing and re-launching a new one, or logging out of your remote server connection with &lt;code&gt;Ctrl-D&lt;/code&gt; and logging back in with &lt;code&gt;ssh&lt;/code&gt;). This is what I had to do.&lt;/p&gt;

&lt;p&gt;If successful, you should see a &amp;ldquo;Hello from Docker!&amp;rdquo; printout in your console.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;And that&amp;rsquo;s it, you have a running Docker container (this one comes with the install).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;However, we are not quite done yet. Let&amp;rsquo;s get to some configuration&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;windows&#34;&gt;Windows&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/&#34; target=&#34;_blank&#34;&gt;Go deal with it yourself&lt;/a&gt;. It&amp;rsquo;s similar to the Desktop-version available for Mac, but comes with &lt;strong&gt;all sorts of caveats you should read through first.&lt;/strong&gt;
It should be fairly straightforward for Windows 10 Users.
My suggestion is to simply go with Linux, since our focus is on using Docker for deploying to servers, which are unlikely to be running Windows for the use-cases we have in mind. That said, &lt;em&gt;should be doable, if you insist on it.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;configure&#34;&gt;Configure&lt;/h1&gt;

&lt;p&gt;One thing you may notice is that &lt;code&gt;docker&lt;/code&gt; commands require the use of &lt;code&gt;sudo&lt;/code&gt;, which we would like to avoid.
To avoid permission errors (and the use of sudo), add your user to the &lt;code&gt;docker&lt;/code&gt; group.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;Post-Installation Steps&lt;/a&gt; contains optional procedures for configuring Linux hosts to work better with Docker. &lt;em&gt;The following is taken from that source, and much more &lt;strong&gt;Troubleshooting Information can be found there&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;permissions&#34;&gt;Permissions&lt;/h2&gt;

&lt;p&gt;To create the docker group and add your user:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create the docker group.&lt;/li&gt;
&lt;li&gt;Add your user to the docker group.&lt;/li&gt;
&lt;li&gt;Log out and log back in so that your group membership is re-evaluated. Some caveats may apply. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:usergroup-caveats&#34;&gt;&lt;a href=&#34;#fn:usergroup-caveats&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo groupadd docker
sudo usermod -aG docker $USER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verify that you can run docker commands without sudo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you initially ran Docker CLI commands using sudo before adding your user to the docker group, you may see the following error, which indicates that your &lt;code&gt;~/.docker/&lt;/code&gt; directory was created with incorrect permissions due to the sudo commands.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WARNING: Error loading config file: /home/user/.docker/config.json 
- stat /home/user/.docker/config.json: permission denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To fix this problem, either remove the &lt;code&gt;~/.docker/ directory&lt;/code&gt; (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chown &amp;quot;$USER&amp;quot;:&amp;quot;$USER&amp;quot; /home/&amp;quot;$USER&amp;quot;/.docker -R
sudo chmod g+rwx &amp;quot;$HOME/.docker&amp;quot; -R
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;start-on-boot&#34;&gt;Start on boot&lt;/h2&gt;

&lt;p&gt;Sometimes you want Docker to be the main thing running on a server and thus started up on boot (for the occasional restart).
This feature may be desired for servers that host critical processes using Docker.
Most current Linux distributions (RHEL, CentOS, Fedora, Ubuntu 16.04 and higher) use &lt;code&gt;systemd&lt;/code&gt; to manage which services start when the system boots. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:linux-version&#34;&gt;&lt;a href=&#34;#fn:linux-version&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl enable docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To disable this behavior, use &lt;code&gt;disable&lt;/code&gt; instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl disable docker
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;re-route-ip&#34;&gt;Re-route IP&lt;/h2&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;By default, the Docker daemon listens for connections on a UNIX socket to accept requests from local clients.&lt;/p&gt;

&lt;p&gt;It is possible to allow Docker to accept requests from remote hosts by configuring it to listen on an IP address and port as well as the UNIX socket.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;For more detailed information on this configuration option take a look at “Bind Docker to another host/port or a unix socket” section of the &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/dockerd/&#34; target=&#34;_blank&#34;&gt;Docker CLI Reference article&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;&lt;strong&gt;Security Notice&lt;/strong&gt;: Before configuring Docker to accept connections from remote hosts it is critically important that you understand the security implications of opening docker to the network. If steps are not taken to secure the connection, it is possible for remote non-root users to gain root access on the host. For more information on how to use TLS certificates to secure this connection, check this article on how to protect the Docker daemon socket.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Configuring Docker to accept remote connections can be done with the &lt;code&gt;docker.service&lt;/code&gt; &lt;code&gt;systemd&lt;/code&gt; unit file for Linux distributions using &lt;code&gt;systemd&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Use the command &lt;code&gt;sudo systemctl edit docker.service&lt;/code&gt; to open an override file for &lt;code&gt;docker.service&lt;/code&gt; in a text editor.&lt;/p&gt;

&lt;p&gt;Add or modify the following lines, &lt;em&gt;substituting your own values.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H fd:// -H tcp://127.0.0.1:2375
Save the file.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reload the systemctl configuration and restart Docker.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl daemon-reload
sudo systemctl restart docker.service
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Check to see whether the change was honored by reviewing the output of &lt;code&gt;netstat&lt;/code&gt; to confirm &lt;code&gt;dockerd&lt;/code&gt; is listening on the configured port, which should look similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo netstat -lntp | grep dockerd
tcp        0      0 127.0.0.1:2375          0.0.0.0:*               LISTEN      3758/dockerd
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;To enable IPv6 on the Docker daemon, see &lt;a href=&#34;https://docs.docker.com/config/daemon/ipv6/&#34; target=&#34;_blank&#34;&gt;Enable IPv6 support&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;

&lt;p&gt;More troubleshooting information can be found in the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/#troubleshooting&#34; target=&#34;_blank&#34;&gt;Troubleshooting section&lt;/a&gt; of the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;Post-Install&lt;/a&gt; documentation page.&lt;/p&gt;

&lt;p&gt;Here we attempt to address just a couple of the most common things that we may have to do.&lt;/p&gt;

&lt;h3 id=&#34;ip-forwarding&#34;&gt;IP Forwarding&lt;/h3&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you manually configure your network using &lt;code&gt;systemd-network&lt;/code&gt; with &lt;code&gt;systemd&lt;/code&gt; &lt;strong&gt;version 219 or higher,&lt;/strong&gt; &lt;em&gt;Docker containers may not be able to access your network.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Beginning with &lt;code&gt;systemd&lt;/code&gt; &lt;strong&gt;version 220&lt;/strong&gt;, the forwarding setting for a given network (&lt;code&gt;net.ipv4.conf.&amp;lt;interface&amp;gt;.forwarding&lt;/code&gt;) defaults to &lt;code&gt;off&lt;/code&gt;.
This setting prevents IP forwarding.
It also conflicts with Docker’s behavior of enabling the &lt;code&gt;net.ipv4.conf.all.forwarding&lt;/code&gt; setting within containers.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;To work around this on RHEL, CentOS, or Fedora, edit the &lt;code&gt;&amp;lt;interface&amp;gt;.network&lt;/code&gt; file in &lt;code&gt;/usr/lib/systemd/network/&lt;/code&gt; on your Docker host (ex: &lt;code&gt;/usr/lib/systemd/network/80-container-host0.network&lt;/code&gt;) and add the following block within the &lt;code&gt;[Network]&lt;/code&gt; section.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Network]
...
IPForward=kernel
# OR
IPForward=true
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;This configuration allows IP forwarding from the container as expected.&lt;/p&gt;

&lt;h3 id=&#34;limiting&#34;&gt;Limiting&lt;/h3&gt;

&lt;p&gt;You may see&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WARNING: Your kernel does not support swap limit capabilities. Limitation discarded.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;This warning does not occur on RPM-based systems, which enable these capabilities by default.
If you don’t need these capabilities, you can ignore the warning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can enable these capabilities on Ubuntu or Debian by following these instructions.
Memory and swap accounting incur an overhead of about 1% of the total available memory and a 10% overall performance degradation, even if Docker is not running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Log into the Ubuntu or Debian host as a user with sudo privileges.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Edit the &lt;code&gt;/etc/default/grub&lt;/code&gt; file. Add or edit the &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt; line to add the following two key-value pairs:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;GRUB_CMDLINE_LINUX=&amp;quot;cgroup_enable=memory swapaccount=1&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Save and close the file.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Update GRUB.
&lt;code&gt;sudo update-grub&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If your GRUB configuration file has incorrect syntax, an error occurs. In this case, repeat steps 3 and 4.
 The changes take effect when the system is rebooted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;This is where security tips about Docker go. The Docker &lt;a href=&#34;https://docs.docker.com/engine/security/security/&#34; target=&#34;_blank&#34;&gt;security&lt;/a&gt; page goes into more detail.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First things first: &lt;strong&gt;Docker runs as root.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you are in the &lt;code&gt;docker&lt;/code&gt; group, you effectively &lt;a href=&#34;http://reventlov.com/advisories/using-the-docker-command-to-root-the-host&#34; target=&#34;_blank&#34;&gt;have root access&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;If you &lt;em&gt;expose the docker UNIX socket to a container&lt;/em&gt;, you are giving the container &lt;a href=&#34;https://www.lvh.io/posts/dont-expose-the-docker-socket-not-even-to-a-container.html&#34; target=&#34;_blank&#34;&gt;root access to the host&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Docker should not be your only defense. You should secure and harden it.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The security tips following are useful if you&amp;rsquo;ve already hardened containers in the past, but are &lt;strong&gt;not a substitute for understanding.&lt;/strong&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:security&#34;&gt;&lt;a href=&#34;#fn:security&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;security-tips&#34;&gt;Security Tips&lt;/h2&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;For greatest security, you want to run Docker inside a virtual machine.
(Source: Docker Security Team Lead  &lt;a href=&#34;http://www.slideshare.net/jpetazzo/linux-containers-lxc-docker-and-security&#34; target=&#34;_blank&#34;&gt;slides&lt;/a&gt; / &lt;a href=&#34;http://www.projectatomic.io/blog/2014/08/is-it-safe-a-look-at-docker-and-security-from-linuxcon/&#34; target=&#34;_blank&#34;&gt;notes&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Then, run with AppArmor / seccomp / SELinux / grsec etc to &lt;a href=&#34;http://linux-audit.com/docker-security-best-practices-for-your-vessel-and-containers/&#34; target=&#34;_blank&#34;&gt;limit the container permissions&lt;/a&gt;. See the &lt;a href=&#34;https://blog.docker.com/2016/02/docker-engine-1-10-security/&#34; target=&#34;_blank&#34;&gt;Docker 1.10 security features&lt;/a&gt; for more details.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Docker image ids are &lt;a href=&#34;https://medium.com/@quayio/your-docker-image-ids-are-secrets-and-its-time-you-treated-them-that-way-f55e9f14c1a4&#34; target=&#34;_blank&#34;&gt;sensitive information&lt;/a&gt; and should not be exposed to the outside world. Treat them like passwords.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;See the &lt;a href=&#34;https://github.com/konstruktoid/Docker/blob/master/Security/CheatSheet.adoc&#34; target=&#34;_blank&#34;&gt;Docker Security Cheat Sheet&lt;/a&gt; by &lt;a href=&#34;https://github.com/konstruktoid&#34; target=&#34;_blank&#34;&gt;Thomas Sjögren&lt;/a&gt;: some good stuff about container hardening in there.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Check out the &lt;strong&gt;&lt;a href=&#34;https://github.com/docker/docker-bench-security&#34; target=&#34;_blank&#34;&gt;docker bench security script&lt;/a&gt;&lt;/strong&gt; for a security benchmark.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Download the &lt;a href=&#34;https://blog.docker.com/2015/05/understanding-docker-security-and-best-practices/&#34; target=&#34;_blank&#34;&gt;white papers&lt;/a&gt; and subscribe to the &lt;a href=&#34;https://www.docker.com/docker-security&#34; target=&#34;_blank&#34;&gt;mailing lists&lt;/a&gt; (unfortunately Docker does not have a unique mailing list, only dev / user). To begin with, see this (foot)note from the cheatsheet &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:begin&#34;&gt;&lt;a href=&#34;#fn:begin&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;h3 id=&#34;making-docker-safe-for-production&#34;&gt;Making Docker Safe for Production&lt;/h3&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Since Docker 1.11, you can easily limit the number of active processes running inside a container to prevent fork bombs.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This requires a Linux kernel &amp;gt;= 4.3 with &lt;code&gt;CGROUP_PIDS=y&lt;/code&gt; to be in the kernel configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --pids-limit=64
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Also available since docker 1.11 is the ability to prevent processes from gaining new privileges.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This feature have been in the Linux kernel since version 3.5. You can read more about it in &lt;a href=&#34;http://www.projectatomic.io/blog/2016/03/no-new-privs-docker/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; blog post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --security-opt=no-new-privileges
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;From the &lt;a href=&#34;http://container-solutions.com/content/uploads/2015/06/15.06.15_DockerCheatSheet_A2.pdf&#34; target=&#34;_blank&#34;&gt;Docker Security Cheat Sheet&lt;/a&gt; (it&amp;rsquo;s in PDF which makes it hard to use, so copying below) by &lt;a href=&#34;(http://container-solutions.com/is-docker-safe-for-production/)&#34; target=&#34;_blank&#34;&gt;Container Solutions&lt;/a&gt; :&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Be aware that the following may affect the performance of your applications in unexpected ways if you are not sure what kinds of communications requirements you need.&lt;/p&gt;

&lt;p&gt;Proceed with caution. Reference the [presentation above][docker-production].&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Turn off interprocess communication with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker -d --icc=false --iptables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set the container to be read-only:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --read-only
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verify images with a hashsum:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set volumes to be read only:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -v $(pwd)/secrets:/secrets:ro debian
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Define and run a user in your Dockerfile so you don&amp;rsquo;t run as root inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN groupadd -r user &amp;amp;&amp;amp; useradd -r -g user user
USER user
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;port-exposal&#34;&gt;Port-Exposal&lt;/h2&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Exposing incoming ports through the host container is &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#expose-incoming-ports&#34; target=&#34;_blank&#34;&gt;fiddly but doable&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This is done by mapping the container port to the host port (only using localhost interface) using &lt;code&gt;-p&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -p 127.0.0.1:$HOSTPORT:$CONTAINERPORT --name CONTAINER -t someimage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can tell Docker that the container listens on the specified network ports at runtime by using &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#expose&#34; target=&#34;_blank&#34;&gt;EXPOSE&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPOSE &amp;lt;CONTAINERPORT&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that EXPOSE does not expose the port itself &amp;ndash; only &lt;code&gt;-p&lt;/code&gt; will do that. To expose the container&amp;rsquo;s port on your localhost&amp;rsquo;s port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -t nat -A DOCKER -p tcp --dport &amp;lt;LOCALHOSTPORT&amp;gt; -j DNAT --to-destination &amp;lt;CONTAINERIP&amp;gt;:&amp;lt;PORT&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;re running Docker in Virtualbox, you then need to forward the port there as well, using &lt;a href=&#34;https://docs.vagrantup.com/v2/networking/forwarded_ports.html&#34; target=&#34;_blank&#34;&gt;forwarded_port&lt;/a&gt;. Define a range of ports in your Vagrantfile like this so you can dynamically map them:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  ...

  (49000..49900).each do |port|
    config.vm.network :forwarded_port, :host =&amp;gt; port, :guest =&amp;gt; port
  end

  ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you forget what you mapped the port to on the host container, use &lt;code&gt;docker port&lt;/code&gt; to show it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker port CONTAINER $CONTAINERPORT
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;more&#34;&gt;More&lt;/h2&gt;

&lt;h3 id=&#34;user-namespaces&#34;&gt;User Namespaces&lt;/h3&gt;

&lt;p&gt;There&amp;rsquo;s also work on &lt;a href=&#34;https://s3hh.wordpress.com/2013/07/19/creating-and-using-containers-without-privilege/&#34; target=&#34;_blank&#34;&gt;user namespaces&lt;/a&gt; &amp;ndash; it is in 1.10 but is not enabled by default.&lt;/p&gt;

&lt;p&gt;To enable user namespaces (&amp;ldquo;remap the userns&amp;rdquo;) in Ubuntu 15.10, &lt;a href=&#34;https://raesene.github.io/blog/2016/02/04/Docker-User-Namespaces/&#34; target=&#34;_blank&#34;&gt;follow the blog example&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;the-security-roadmap&#34;&gt;The Security Roadmap&lt;/h3&gt;

&lt;p&gt;The Docker roadmap talks about &lt;a href=&#34;https://github.com/docker/docker/blob/master/ROADMAP.md#11-security&#34; target=&#34;_blank&#34;&gt;seccomp support&lt;/a&gt;.
There is an AppArmor policy generator called &lt;a href=&#34;https://github.com/jfrazelle/bane&#34; target=&#34;_blank&#34;&gt;bane&lt;/a&gt;, and they&amp;rsquo;re working on &lt;a href=&#34;https://github.com/docker/docker/issues/17142&#34; target=&#34;_blank&#34;&gt;security profiles&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;security-videos&#34;&gt;Security Videos&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/04LOuMgNj9U&#34; target=&#34;_blank&#34;&gt;Using Docker Safely&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/KmxOXmPhZbk&#34; target=&#34;_blank&#34;&gt;Securing your applications using Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/a9lE9Urr6AQ&#34; target=&#34;_blank&#34;&gt;Container security: Do containers actually contain?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=iN6QbszB1R8&#34; target=&#34;_blank&#34;&gt;Linux Containers: Future or Fantasy?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;cheat-sheet&#34;&gt;Cheat Sheet&lt;/h1&gt;

&lt;p&gt;The following is full &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Cheat Sheet&lt;/a&gt; mentioned earlier, and presented here for convenience. Feel free to use the table of contents on the right sidebar (or duplicated below for mobile users) to more easily navigate this page than on the Github Gist &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:gist&#34;&gt;&lt;a href=&#34;#fn:gist&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;images-1&#34;&gt;Images&lt;/h2&gt;

&lt;p&gt;Images are just &lt;a href=&#34;https://docs.docker.com/engine/understanding-docker/#how-does-a-docker-image-work&#34; target=&#34;_blank&#34;&gt;templates for docker containers&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/images&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker images&lt;/code&gt;&lt;/a&gt; shows all images.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/import&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker import&lt;/code&gt;&lt;/a&gt; creates an image from a tarball.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/build&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker build&lt;/code&gt;&lt;/a&gt; creates image from Dockerfile.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/commit&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker commit&lt;/code&gt;&lt;/a&gt; creates image from a container, pausing it temporarily if it is running.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rmi&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rmi&lt;/code&gt;&lt;/a&gt; removes an image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/load&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker load&lt;/code&gt;&lt;/a&gt; loads an image from a tar archive as STDIN, including images and tags (as of 0.7).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/save&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker save&lt;/code&gt;&lt;/a&gt; saves an image to a tar archive stream to STDOUT with all parent layers, tags &amp;amp; versions (as of 0.7).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/history&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker history&lt;/code&gt;&lt;/a&gt; shows history of image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/tag&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker tag&lt;/code&gt;&lt;/a&gt; tags an image to a name (local or registry).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cleaning-up&#34;&gt;Cleaning up&lt;/h3&gt;

&lt;p&gt;While you can use the &lt;code&gt;docker rmi&lt;/code&gt; command to remove specific images, there&amp;rsquo;s a tool called &lt;a href=&#34;https://github.com/spotify/docker-gc&#34; target=&#34;_blank&#34;&gt;docker-gc&lt;/a&gt; that will safely clean up images that are no longer used by any containers.&lt;/p&gt;

&lt;h3 id=&#34;load-save-image&#34;&gt;Load/Save image&lt;/h3&gt;

&lt;p&gt;Load an image from file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker load &amp;lt; my_image.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save an existing image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker save my_image:my_tag | gzip &amp;gt; my_image.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;layers&#34;&gt;Layers&lt;/h2&gt;

&lt;p&gt;The versioned filesystem in Docker is based on layers. They&amp;rsquo;re like &lt;a href=&#34;https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/&#34; target=&#34;_blank&#34;&gt;git commits or changesets for filesystems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Eventually you&amp;rsquo;ll want to make changes to an existing image, and will find yourself manipulating the &lt;code&gt;Dockerfile&lt;/code&gt; that defines the build and configuration of the image.
You can think of this as mimicking the keystrokes a user would have to enter in order to set up each application on a fresh computer.&lt;/p&gt;

&lt;p&gt;Pretty much every image we&amp;rsquo;ll be interested in will have it&amp;rsquo;s origin in some version of a Linux distribution on top of which a number of commands are run to define the files necessary for the use-case.&lt;/p&gt;

&lt;p&gt;Since each &amp;ldquo;version&amp;rdquo; of an image is an entire filesystem, building one version of an image based on a previous one can lead to lots of unnecessary files being tracked.&lt;/p&gt;

&lt;p&gt;As stated in the &lt;a href=&#34;#dockerfile&#34;&gt;Dockerfile section&lt;/a&gt;, the command &lt;code&gt;RUN&lt;/code&gt; executes any commands in a &lt;em&gt;new layer&lt;/em&gt; &lt;strong&gt;on top&lt;/strong&gt; of the current image, and commits the results.&lt;/p&gt;

&lt;p&gt;This &amp;ldquo;on top&amp;rdquo; part is especially important to understand, and several things can be done to keep subsequent changes to an image relatively &amp;ldquo;lightweight.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;For example, make sure to &lt;a href=&#34;#efficiency&#34;&gt;clean up&lt;/a&gt; the &lt;code&gt;APT&lt;/code&gt; repositories.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;containers-1&#34;&gt;Containers&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://etherealmind.com/basics-docker-containers-hypervisors-coreos/&#34; target=&#34;_blank&#34;&gt;Your basic isolated Docker process&lt;/a&gt;. Containers are to Virtual Machines as threads are to processes. Or you can think of them as chroots on steroids.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle-1&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/create&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker create&lt;/code&gt;&lt;/a&gt; creates a container but does not start it.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rename/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rename&lt;/code&gt;&lt;/a&gt; allows the container to be renamed.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker run&lt;/code&gt;&lt;/a&gt; creates and starts a container in one operation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rm&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rm&lt;/code&gt;&lt;/a&gt; deletes a container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/update/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker update&lt;/code&gt;&lt;/a&gt; updates a container&amp;rsquo;s resource limits.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Normally if you run a container without options it will start and stop immediately, if you want keep it running you can use the command, &lt;code&gt;docker run -td container_id&lt;/code&gt; this will use the option &lt;code&gt;-t&lt;/code&gt; that will allocate a pseudo-TTY session and &lt;code&gt;-d&lt;/code&gt; that will detach automatically the container (run container in background and print container ID).&lt;/p&gt;

&lt;p&gt;If you want a transient container, &lt;code&gt;docker run --rm&lt;/code&gt; will remove the container after it stops.&lt;/p&gt;

&lt;p&gt;If you want to map a directory on the host to a docker container, &lt;code&gt;docker run -v $HOSTDIR:$DOCKERDIR&lt;/code&gt;. Also see &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet/#volumes&#34; target=&#34;_blank&#34;&gt;Volumes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you want to remove also the volumes associated with the container, the deletion of the container must include the &lt;code&gt;-v&lt;/code&gt; switch like in &lt;code&gt;docker rm -v&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s also a &lt;a href=&#34;https://docs.docker.com/engine/admin/logging/overview/&#34; target=&#34;_blank&#34;&gt;logging driver&lt;/a&gt; available for individual containers in docker 1.10. To run docker with a custom log driver (i.e., to syslog), use &lt;code&gt;docker run --log-driver=syslog&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Another useful option is &lt;code&gt;docker run --name yourname docker_image&lt;/code&gt; because when you specify the &lt;code&gt;--name&lt;/code&gt; inside the run command this will allow you to start and stop a container by calling it with the name the you specified when you created it.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;starting-and-stopping&#34;&gt;Starting and Stopping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/start&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker start&lt;/code&gt;&lt;/a&gt; starts a container so it is running.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stop&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker stop&lt;/code&gt;&lt;/a&gt; stops a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/restart&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker restart&lt;/code&gt;&lt;/a&gt; stops and starts a container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/pause/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker pause&lt;/code&gt;&lt;/a&gt; pauses a running container, &amp;ldquo;freezing&amp;rdquo; it in place.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/unpause/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker unpause&lt;/code&gt;&lt;/a&gt; will unpause a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/wait&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker wait&lt;/code&gt;&lt;/a&gt; blocks until running container stops.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/kill&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker kill&lt;/code&gt;&lt;/a&gt; sends a SIGKILL to a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/attach&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker attach&lt;/code&gt;&lt;/a&gt; will connect to a running container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you want to integrate a container with a &lt;a href=&#34;https://docs.docker.com/engine/admin/host_integration/&#34; target=&#34;_blank&#34;&gt;host process manager&lt;/a&gt;, start the daemon with &lt;code&gt;-r=false&lt;/code&gt; then use &lt;code&gt;docker start -a&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you want to expose container ports through the host, see the &lt;a href=&#34;#exposing-ports&#34;&gt;exposing ports&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;Restart policies on crashed docker instances are &lt;a href=&#34;http://container42.com/2014/09/30/docker-restart-policies/&#34; target=&#34;_blank&#34;&gt;covered here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;info-1&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/ps&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker ps&lt;/code&gt;&lt;/a&gt; shows running containers.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/logs&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker logs&lt;/code&gt;&lt;/a&gt; gets logs from container.  (You can use a custom log driver, but logs is only available for &lt;code&gt;json-file&lt;/code&gt; and &lt;code&gt;journald&lt;/code&gt; in 1.10).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/inspect&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker inspect&lt;/code&gt;&lt;/a&gt; looks at all the info on a container (including IP address).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/events&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker events&lt;/code&gt;&lt;/a&gt; gets events from container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/port&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker port&lt;/code&gt;&lt;/a&gt; shows public facing port of container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/top&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker top&lt;/code&gt;&lt;/a&gt; shows running processes in container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stats&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker stats&lt;/code&gt;&lt;/a&gt; shows containers&amp;rsquo; resource usage statistics.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/diff&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker diff&lt;/code&gt;&lt;/a&gt; shows changed files in the container&amp;rsquo;s FS.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;docker ps -a&lt;/code&gt; shows running and stopped containers.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker stats --all&lt;/code&gt; shows a running list of containers.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;import-export&#34;&gt;Import / Export&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/cp&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker cp&lt;/code&gt;&lt;/a&gt; copies files or folders between a container and the local filesystem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/export&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker export&lt;/code&gt;&lt;/a&gt; turns container filesystem into tarball archive stream to STDOUT.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;executing-commands&#34;&gt;Executing Commands&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/exec&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker exec&lt;/code&gt;&lt;/a&gt; to execute a command in container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To enter a running container, attach a new shell process to a running container called foo, use: &lt;code&gt;docker exec -it foo /bin/bash&lt;/code&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;container-import-export&#34;&gt;Container Import/Export&lt;/h3&gt;

&lt;p&gt;Import a container as an image from file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat my_container.tar.gz | docker import - my_image:my_tag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Export an existing container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker export my_container | gzip &amp;gt; my_container.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;The difference between &lt;em&gt;loading a saved image&lt;/em&gt; and importing an exported &lt;em&gt;container as an image&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Loading an image using the &lt;code&gt;load&lt;/code&gt; command creates a new image including its history.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Importing a container as an image using the &lt;code&gt;import&lt;/code&gt; command creates a new image, &lt;strong&gt;excluding the history,&lt;/strong&gt; which results in a &lt;em&gt;smaller image size compared to loading an image&lt;/em&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;management&#34;&gt;Management&lt;/h2&gt;

&lt;h3 id=&#34;cpu-constraints&#34;&gt;CPU Constraints&lt;/h3&gt;

&lt;p&gt;You can limit CPU, either using a percentage of all CPUs, or by using specific cores.&lt;/p&gt;

&lt;p&gt;For example, you can tell the &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/cpu-share-constraint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cpu-shares&lt;/code&gt;&lt;/a&gt; setting.  The setting is a bit strange &amp;ndash; 1024 means 100% of the CPU, so if you want the container to take 50% of all CPU cores, you should specify 512.  See &lt;a href=&#34;https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu&#34; target=&#34;_blank&#34;&gt;https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu&lt;/a&gt; for more:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti -c 512 agileek/cpuset-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also only use some CPU cores using &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/cpuset-constraint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cpuset-cpus&lt;/code&gt;&lt;/a&gt;.  See &lt;a href=&#34;https://agileek.github.io/docker/2014/08/06/docker-cpuset/&#34; target=&#34;_blank&#34;&gt;https://agileek.github.io/docker/2014/08/06/docker-cpuset/&lt;/a&gt; for details and some nice videos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti --cpuset-cpus=0,4,6 agileek/cpuset-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that Docker can still &lt;strong&gt;see&lt;/strong&gt; all of the CPUs inside the container &amp;ndash; it just isn&amp;rsquo;t using all of them.  See &lt;a href=&#34;https://github.com/docker/docker/issues/20770&#34; target=&#34;_blank&#34;&gt;https://github.com/docker/docker/issues/20770&lt;/a&gt; for more details.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;memory-constraints&#34;&gt;Memory Constraints&lt;/h3&gt;

&lt;p&gt;You can also set &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/user-memory-constraints&#34; target=&#34;_blank&#34;&gt;memory constraints&lt;/a&gt; on Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it -m 300M ubuntu:14.04 /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;capabilities&#34;&gt;Capabilities&lt;/h3&gt;

&lt;p&gt;Linux capabilities can be set by using &lt;code&gt;cap-add&lt;/code&gt; and &lt;code&gt;cap-drop&lt;/code&gt;.  See &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34; target=&#34;_blank&#34;&gt;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;This should be used for greater security.&lt;/p&gt;

&lt;/div&gt;

To mount a FUSE based filesystem, you need to combine both &amp;ndash;cap-add and &amp;ndash;device:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give access to a single device:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it --device=/dev/ttyUSB0 debian bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give access to all devices:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb debian bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;more info about privileged containers &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;dockerfile&#34;&gt;Dockerfile&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34;&gt;The configuration file&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sets up a Docker container when you run &lt;code&gt;docker build&lt;/code&gt; on it. Vastly preferable to &lt;code&gt;docker commit&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here are some common text editors and their syntax highlighting modules you could use to create Dockerfiles:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://packagecontrol.io/packages/Dockerfile%20Syntax%20Highlighting&#34; target=&#34;_blank&#34;&gt;Sublime Text 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://atom.io/packages/language-docker&#34; target=&#34;_blank&#34;&gt;Atom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ekalinin/Dockerfile.vim&#34; target=&#34;_blank&#34;&gt;Vim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spotify/dockerfile-mode&#34; target=&#34;_blank&#34;&gt;Emacs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Also see &lt;a href=&#34;https://domeide.github.io/&#34; target=&#34;_blank&#34;&gt;Docker meets the IDE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;instructions&#34;&gt;Instructions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#dockerignore-file&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;.dockerignore&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#from&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;FROM&lt;/code&gt;&lt;/a&gt; Sets the Base Image for subsequent instructions.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#maintainer-deprecated&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;MAINTAINER&lt;/code&gt; (deprecated - use LABEL instead)&lt;/a&gt; Set the Author field of the generated images.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#run&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;RUN&lt;/code&gt;&lt;/a&gt; execute any commands in a new layer on top of the current image and commit the results.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#cmd&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;CMD&lt;/code&gt;&lt;/a&gt; provide defaults for an executing container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#expose&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;EXPOSE&lt;/code&gt;&lt;/a&gt; informs Docker that the container listens on the specified network ports at runtime.  NOTE: does not actually make ports accessible.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#env&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ENV&lt;/code&gt;&lt;/a&gt; sets environment variable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#add&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ADD&lt;/code&gt;&lt;/a&gt; copies new files, directories or remote file to container.  Invalidates caches. Avoid &lt;code&gt;ADD&lt;/code&gt; and use &lt;code&gt;COPY&lt;/code&gt; instead.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#copy&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;COPY&lt;/code&gt;&lt;/a&gt; copies new files or directories to container.  Note that this only copies as root, so you have to chown manually regardless of your USER / WORKDIR setting.  See &lt;a href=&#34;https://github.com/moby/moby/issues/30110&#34; target=&#34;_blank&#34;&gt;https://github.com/moby/moby/issues/30110&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#entrypoint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ENTRYPOINT&lt;/code&gt;&lt;/a&gt; configures a container that will run as an executable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#volume&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;VOLUME&lt;/code&gt;&lt;/a&gt; creates a mount point for externally mounted volumes or other containers.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#user&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;USER&lt;/code&gt;&lt;/a&gt; sets the user name for following RUN / CMD / ENTRYPOINT commands.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#workdir&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;WORKDIR&lt;/code&gt;&lt;/a&gt; sets the working directory.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#arg&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ARG&lt;/code&gt;&lt;/a&gt; defines a build-time variable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#onbuild&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ONBUILD&lt;/code&gt;&lt;/a&gt; adds a trigger instruction when the image is used as the base for another build.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#stopsignal&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;STOPSIGNAL&lt;/code&gt;&lt;/a&gt; sets the system call signal that will be sent to the container to exit.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/labels-custom-metadata/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;LABEL&lt;/code&gt;&lt;/a&gt; apply key/value metadata to your images, containers, or daemons.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://flux7.com/blogs/docker/docker-tutorial-series-part-3-automation-is-the-word-using-dockerfile/&#34; target=&#34;_blank&#34;&gt;Flux7&amp;rsquo;s Dockerfile Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#dockerfile-examples&#34; target=&#34;_blank&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/&#34; target=&#34;_blank&#34;&gt;Best practices for writing Dockerfiles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://crosbymichael.com/&#34; target=&#34;_blank&#34;&gt;Michael Crosby&lt;/a&gt; has some more &lt;a href=&#34;http://crosbymichael.com/dockerfile-best-practices.html&#34; target=&#34;_blank&#34;&gt;Dockerfiles best practices&lt;/a&gt; / &lt;a href=&#34;http://crosbymichael.com/dockerfile-best-practices-take-2.html&#34; target=&#34;_blank&#34;&gt;take 2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://jonathan.bergknoff.com/journal/building-good-docker-images&#34; target=&#34;_blank&#34;&gt;Building Good Docker Images&lt;/a&gt; / &lt;a href=&#34;http://jonathan.bergknoff.com/journal/building-better-docker-images&#34; target=&#34;_blank&#34;&gt;Building Better Docker Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://speakerdeck.com/garethr/managing-container-configuration-with-metadata&#34; target=&#34;_blank&#34;&gt;Managing Container Configuration with Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rock-it.pl/how-to-write-excellent-dockerfiles/&#34; target=&#34;_blank&#34;&gt;How to write excellent Dockerfiles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;networks&#34;&gt;Networks&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker has a &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/&#34; target=&#34;_blank&#34;&gt;networks&lt;/a&gt; feature.
Not much is known about it, so this is a good place to expand the cheat sheet.
There is a note saying that it&amp;rsquo;s a good way to configure docker containers to talk to each other without using ports.
See &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/work-with-networks/&#34; target=&#34;_blank&#34;&gt;working with networks&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;lifecycle-2&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_create/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network create&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_rm/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network rm&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info-2&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_ls/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network ls&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_inspect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network inspect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;connection&#34;&gt;Connection&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_connect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network connect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_disconnect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network disconnect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can specify a &lt;a href=&#34;https://blog.jessfraz.com/post/ips-for-all-the-things/&#34; target=&#34;_blank&#34;&gt;specific IP address for a container&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# create a new bridge network with your subnet and gateway for your ip block
$ docker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic

# run a nginx container with a specific ip in that block
$ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx

# curl the ip from any other place (assuming this is a public ip block duh)
$ curl 203.0.113.2
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;registries&#34;&gt;Registries&lt;/h2&gt;

&lt;h3 id=&#34;registries-v-repositories&#34;&gt;Registries v. Repositories&lt;/h3&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;A repository is a &lt;em&gt;hosted&lt;/em&gt; collection of tagged images that together create the file system for a container.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;A registry is a &lt;em&gt;host&lt;/em&gt; &amp;ndash; a server that stores repositories and provides an HTTP API for &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockerrepos/&#34; target=&#34;_blank&#34;&gt;managing the uploading and downloading of repositories&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Docker.com hosts its own &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;index&lt;/a&gt; to a central registry which contains a large number of repositories.&lt;/p&gt;

&lt;p&gt;Having said that, the central docker registry &lt;a href=&#34;https://titanous.com/posts/docker-insecurity&#34; target=&#34;_blank&#34;&gt;does not do a good job of verifying images&lt;/a&gt; and should be avoided if you&amp;rsquo;re worried about security.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/login&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker login&lt;/code&gt;&lt;/a&gt; to login to a registry.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/logout&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker logout&lt;/code&gt;&lt;/a&gt; to logout from a registry.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/search&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker search&lt;/code&gt;&lt;/a&gt; searches registry for image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/pull&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker pull&lt;/code&gt;&lt;/a&gt; pulls an image from registry to local machine.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/push&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker push&lt;/code&gt;&lt;/a&gt; pushes an image to the registry from local machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;run-local-registry&#34;&gt;Run local registry&lt;/h3&gt;

&lt;p&gt;You can run a local registry by using the &lt;a href=&#34;https://github.com/docker/distribution&#34; target=&#34;_blank&#34;&gt;docker distribution&lt;/a&gt; project and looking at the &lt;a href=&#34;https://github.com/docker/docker.github.io/blob/master/registry/deploying.md&#34; target=&#34;_blank&#34;&gt;local deploy&lt;/a&gt; instructions.&lt;/p&gt;

&lt;p&gt;Also see the &lt;a href=&#34;https://groups.google.com/a/dockerproject.org/forum/#!forum/distribution&#34; target=&#34;_blank&#34;&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;p&gt;Links are how Docker containers talk to each other &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/&#34; target=&#34;_blank&#34;&gt;through TCP/IP ports&lt;/a&gt;. &lt;a href=&#34;https://docs.docker.com/engine/examples/running_redis_service/&#34; target=&#34;_blank&#34;&gt;Linking into Redis&lt;/a&gt; and &lt;a href=&#34;https://blogs.atlassian.com/2013/11/docker-all-the-things-at-atlassian-automation-and-wiring/&#34; target=&#34;_blank&#34;&gt;Atlassian&lt;/a&gt; show worked examples. You can also resolve &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/#/updating-the-etchosts-file&#34; target=&#34;_blank&#34;&gt;links by hostname&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This has been deprected to some extent by &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/#user-defined-networks&#34; target=&#34;_blank&#34;&gt;user-defined networks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;NOTE: If you want containers to ONLY communicate with each other through links, start the docker daemon with &lt;code&gt;-icc=false&lt;/code&gt; to disable inter process communication.&lt;/p&gt;

&lt;p&gt;If you have a container with the name CONTAINER (specified by &lt;code&gt;docker run --name CONTAINER&lt;/code&gt;) and in the Dockerfile, it has an exposed port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPOSE 1337
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then if we create another container called LINKED like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d --link CONTAINER:ALIAS --name LINKED user/wordpress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the exposed ports and aliases of CONTAINER will show up in LINKED with the following environment variables:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ALIAS_PORT_1337_TCP_PORT
$ALIAS_PORT_1337_TCP_ADDR
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can connect to it that way.&lt;/p&gt;

&lt;p&gt;To delete links, use &lt;code&gt;docker rm --link&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Generally, linking between docker services is a subset of &amp;ldquo;service discovery&amp;rdquo;, a big problem if you&amp;rsquo;re planning to use Docker at scale in production.  Please read &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/the-docker-ecosystem-service-discovery-and-distributed-configuration-stores&#34; target=&#34;_blank&#34;&gt;The Docker Ecosystem: Service Discovery and Distributed Configuration Stores&lt;/a&gt; for more info.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;volumes&#34;&gt;Volumes&lt;/h2&gt;

&lt;p&gt;Docker volumes are &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/&#34; target=&#34;_blank&#34;&gt;free-floating filesystems&lt;/a&gt;. They don&amp;rsquo;t have to be connected to a particular container. You should use volumes mounted from &lt;a href=&#34;https://medium.com/@ramangupta/why-docker-data-containers-are-good-589b3c6c749e&#34; target=&#34;_blank&#34;&gt;data-only containers&lt;/a&gt; for portability.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle-3&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_create/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume create&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_rm/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume rm&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info-3&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_ls/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume ls&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_inspect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume inspect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Volumes are useful in situations where you can&amp;rsquo;t use links (which are TCP/IP only). For instance, if you need to have two docker instances communicate by leaving stuff on the filesystem.&lt;/p&gt;

&lt;p&gt;You can mount them in several docker containers at once, using &lt;code&gt;docker run --volumes-from&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Because volumes are isolated filesystems, they are often used to store state from computations between transient containers. That is, you can have a stateless and transient container run from a recipe, blow it away, and then have a second instance of the transient container pick up from where the last one left off.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&#34;http://crosbymichael.com/advanced-docker-volumes.html&#34; target=&#34;_blank&#34;&gt;advanced volumes&lt;/a&gt; for more details. Container42 is &lt;a href=&#34;http://container42.com/2014/11/03/docker-indepth-volumes/&#34; target=&#34;_blank&#34;&gt;also helpful&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/#mount-a-host-directory-as-a-data-volume&#34; target=&#34;_blank&#34;&gt;map MacOS host directories as docker volumes&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -v /Users/wsargent/myapp/src:/src
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use remote NFS volumes if you&amp;rsquo;re &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-shared-storage-volume-as-a-data-volume&#34; target=&#34;_blank&#34;&gt;feeling brave&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You may also consider running data-only containers as described &lt;a href=&#34;http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; to provide some data portability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#volumes-can-be-files&#34;&gt;Be aware that you can mount files as volumes.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;useful-commands-tips&#34;&gt;Useful Commands/Tips&lt;/h1&gt;

&lt;p&gt;Sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://sssslide.com/speakerdeck.com/bmorearty/15-docker-tips-in-5-minutes&#34; target=&#34;_blank&#34;&gt;15 Docker Tips in 5 minutes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codefresh.io/blog/everyday-hacks-docker/&#34; target=&#34;_blank&#34;&gt;CodeFresh Everyday Hacks Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;versions&#34;&gt;Versions&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;It is very important that you always know the current version of Docker you are currently running on at any point in time.&lt;/em&gt;
This is very helpful because you get to know what features are compatible with what you have running.
This is also important because you know what containers to run from the docker store when you are trying to get template containers.
That said let see how to know what version of docker we have running currently&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/version/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker version&lt;/code&gt;&lt;/a&gt; checks what version of docker you have running&lt;/li&gt;
&lt;li&gt;Usage: &lt;code&gt;docker version [OPTIONS]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Get the server version&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker version --format &#39;{{.Server.Version}}&#39;

1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dump raw JSON data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker version --format &#39;{{json .}}&#39;

{&amp;quot;Client&amp;quot;:{&amp;quot;Version&amp;quot;:&amp;quot;1.8.0&amp;quot;,&amp;quot;ApiVersion&amp;quot;:&amp;quot;1.20&amp;quot;,&amp;quot;GitCommit&amp;quot;:&amp;quot;f5bae0a&amp;quot;,&amp;quot;GoVersion&amp;quot;:&amp;quot;go1.4.2&amp;quot;,&amp;quot;Os&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;Arch&amp;quot;:&amp;quot;am&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;basics&#34;&gt;Basics&lt;/h2&gt;

&lt;h3 id=&#34;get-ip-address&#34;&gt;Get IP Address&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker inspect $(dl) | grep -wm1 IPAddress | cut -d &#39;&amp;quot;&#39; -f 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or install &lt;a href=&#34;https://stedolan.github.io/jq/&#34; target=&#34;_blank&#34;&gt;jq&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker inspect $(dl) | jq -r &#39;.[0].NetworkSettings.IPAddress&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or using a &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/inspect&#34; target=&#34;_blank&#34;&gt;go template&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker inspect -f &#39;{{ .NetworkSettings.IPAddress }}&#39; &amp;lt;container_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or when building an image from Dockerfile, when you want to pass in a build argument:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_HOST_IP=`ifconfig | grep -E &amp;quot;([0-9]{1,3}\.){3}[0-9]{1,3}&amp;quot; | grep -v 127.0.0.1 | awk &#39;{ print $2 }&#39; | cut -f2 -d: | head -n1`
echo DOCKER_HOST_IP = $DOCKER_HOST_IP
docker build \
  --build-arg ARTIFACTORY_ADDRESS=$DOCKER_HOST_IP 
  -t sometag \
  some-directory/
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;get-port-mapping&#34;&gt;Get Port Mapping&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker inspect -f &#39;{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} -&amp;gt; {{(index $conf 0).HostPort}} {{end}}&#39; &amp;lt;containername&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;general&#34;&gt;General&lt;/h2&gt;

&lt;h3 id=&#34;find-containers-using-regular-expression&#34;&gt;Find containers using regular expression:&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for i in $(docker ps -a | grep &amp;quot;REGEXP_PATTERN&amp;quot; | cut -f1 -d&amp;quot; &amp;quot;); do echo $i; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-environment-settings&#34;&gt;Get environment settings&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm ubuntu env
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kill-running-containers&#34;&gt;Kill running containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker kill $(docker ps -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-all-containers-force-running-or-stopped-containers&#34;&gt;Delete all containers (force!! running or stopped containers)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rm -f $(docker ps -qa)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-old-containers&#34;&gt;Delete old containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a | grep &#39;weeks ago&#39; | awk &#39;{print $1}&#39; | xargs docker rm
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-stopped-containers&#34;&gt;Delete stopped containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rm -v $(docker ps -a -q -f status=exited)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-containers-after-stopping&#34;&gt;Delete containers after stopping&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker stop $(docker ps -aq) &amp;amp;&amp;amp; docker rm -v $(docker ps -aq)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-dangling-images&#34;&gt;Delete dangling images&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q -f dangling=true)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-all-images&#34;&gt;Delete all images&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-dangling-volumes&#34;&gt;Delete dangling volumes&lt;/h3&gt;

&lt;p&gt;As of Docker 1.9:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker volume rm $(docker volume ls -q -f dangling=true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In 1.9.0, the filter &lt;code&gt;dangling=false&lt;/code&gt; does &lt;em&gt;not&lt;/em&gt; work - it is ignored and will list all volumes.&lt;/p&gt;

&lt;h3 id=&#34;show-image-dependencies&#34;&gt;Show image dependencies&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker images -viz | dot -Tpng -o docker.png
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;df&#34;&gt;df&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker system df&lt;/code&gt; presents a summary of the space currently used by different docker objects.&lt;/p&gt;

&lt;h3 id=&#34;heredoc-docker-container&#34;&gt;Heredoc Docker Container&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker build -t htop - &amp;lt;&amp;lt; EOF
FROM alpine
RUN apk --no-cache add htop
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;prune&#34;&gt;Prune&lt;/h3&gt;

&lt;p&gt;The new &lt;a href=&#34;https://github.com/docker/docker/pull/26108&#34; target=&#34;_blank&#34;&gt;Data Management Commands&lt;/a&gt; have landed as of Docker 1.13:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;docker system prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker volume prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker network prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker container prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker image prune&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;last-ids&#34;&gt;Last Ids&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;alias dl=&#39;docker ps -l -q&#39;
docker run ubuntu echo hello world
docker commit $(dl) helloworld
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;commit&#34;&gt;Commit&lt;/h3&gt;

&lt;p&gt;with command (needs Dockerfile)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -run=&#39;{&amp;quot;Cmd&amp;quot;:[&amp;quot;postgres&amp;quot;, &amp;quot;-too -many -opts&amp;quot;]}&#39; $(dl) postgres
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;monitoring&#34;&gt;Monitoring&lt;/h2&gt;

&lt;h3 id=&#34;monitor-system-resource-utilization-for-running-containers&#34;&gt;Monitor system resource utilization for running containers&lt;/h3&gt;

&lt;p&gt;To check the CPU, memory, and network I/O usage of a single container, you can use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats &amp;lt;container&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by id:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats $(docker ps -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by name:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats $(docker ps --format &#39;{{.Names}}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a -f ancestor=ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove all untagged images&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images | grep “^” | awk &#39;{split($0,a,&amp;quot; &amp;quot;); print a[3]}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove container by a regular expression&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a | grep wildfly | awk &#39;{print $1}&#39; | xargs docker rm -f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove all exited containers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker rm -f $(docker ps -a | grep Exit | awk &#39;{ print $1 }&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;volumes-can-be-files&#34;&gt;Volumes can be files&lt;/h3&gt;

&lt;p&gt;Be aware that you can mount files as volumes. For example you can inject a configuration file like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# copy file from container
docker run --rm httpd cat /usr/local/apache2/conf/httpd.conf &amp;gt; httpd.conf

# edit file
vim httpd.conf

# start container with modified configuration
docker run --rm -ti -v &amp;quot;$PWD/httpd.conf:/usr/local/apache2/conf/httpd.conf:ro&amp;quot; -p &amp;quot;80:80&amp;quot; httpd
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;efficiency&#34;&gt;Efficiency&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cleaning &lt;code&gt;APT&lt;/code&gt; in a &lt;code&gt;RUN&lt;/code&gt; layer. &lt;em&gt;Note&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:clean&#34;&gt;&lt;a href=&#34;#fn:clean&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN {apt commands} \
&amp;amp;&amp;amp; apt-get clean \
&amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Flatten an image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ID=$(docker run -d image-name /bin/bash)
docker export $ID | docker import – flat-image-name
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For backup&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ID=$(docker run -d image-name /bin/bash)
(docker export $ID | gzip -c &amp;gt; image.tgz)
gzip -dc image.tgz | docker import - flat-image-name
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h2&gt;

&lt;p&gt;This is where general Docker best practices and war stories go:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gregoryszorc.com/blog/2014/10/16/the-rabbit-hole-of-using-docker-in-automated-tests/&#34; target=&#34;_blank&#34;&gt;The Rabbit Hole of Using Docker in Automated Tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/bridgetkromhout&#34; target=&#34;_blank&#34;&gt;Bridget Kromhout&lt;/a&gt; has a useful blog post on &lt;a href=&#34;http://sysadvent.blogspot.co.uk/2014/12/day-1-docker-in-production-reality-not.html&#34; target=&#34;_blank&#34;&gt;running Docker in production&lt;/a&gt; (2014) at Dramafever.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s also a best practices &lt;a href=&#34;http://developers.lyst.com/devops/2014/12/08/docker/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; (2014) from Lyst.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tersesystems.com/2013/11/20/building-a-development-environment-with-docker/&#34; target=&#34;_blank&#34;&gt;Building a Development Environment With Docker&lt;/a&gt; (2013)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://samsaffron.com/archive/2013/11/07/discourse-in-a-docker-container&#34; target=&#34;_blank&#34;&gt;Discourse in a Docker Container&lt;/a&gt; (2013)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:os-footnote&#34;&gt;In this tutorial, we will be using Linux since that is what almost every server runs, but as the principle of Docker is that it makes applications independent of platforms, everything herein should be applicable no matter what machine you are running.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:os-footnote&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:usergroup-caveats&#34;&gt;If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect. On a desktop Linux environment such as X Windows, log out of your session completely and then log back in.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:usergroup-caveats&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:linux-version&#34;&gt;Ubuntu 14.10 and below use &lt;code&gt;upstart&lt;/code&gt;. See the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;post-installation&lt;/a&gt; instructions for support.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:linux-version&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:security&#34;&gt;For an understanding of what containers leave exposed, you should read &lt;a href=&#34;https://www.nccgroup.trust/globalassets/our-research/us/whitepapers/2016/april/ncc_group_understanding_hardening_linux_containers-1-1.pdf&#34; target=&#34;_blank&#34;&gt;Understanding and Hardening Linux Containers&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/dyn___&#34; target=&#34;_blank&#34;&gt;Aaron Grattafiori&lt;/a&gt;. This is a complete and comprehensive guide to the issues involved with containers, with a plethora of links and footnotes leading on to yet more useful content.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:security&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:begin&#34;&gt;You should start off by using a kernel with unstable patches for &lt;code&gt;grsecurity / pax&lt;/code&gt; compiled in, such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Alpine_Linux&#34; target=&#34;_blank&#34;&gt;Alpine Linux&lt;/a&gt;. If you are using &lt;code&gt;grsecurity&lt;/code&gt; in production, you should spring for &lt;a href=&#34;https://grsecurity.net/business_support.php&#34; target=&#34;_blank&#34;&gt;commercial support&lt;/a&gt; for the &lt;a href=&#34;https://grsecurity.net/announce.php&#34; target=&#34;_blank&#34;&gt;stable patches&lt;/a&gt;, same as you would do for RedHat. It&amp;rsquo;s $200 a month, which is nothing to your devops budget.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:begin&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:gist&#34;&gt;The gist was scraped and mildly edited on &lt;em&gt;12/22/18&lt;/em&gt;, so it may behoove you to check the original source for any updates. If you find typos/corrections/updates that should be included below, please &lt;a href=&#34;https://www.michaelpilosov.com/#contact&#34;&gt;get in touch&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:gist&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:clean&#34;&gt;This should be done in the same layer as other apt commands. Otherwise, the previous layers still persist the original information and your images will still be fat.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:clean&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deploying a New Hub</title>
      <link>https://www.michaelpilosov.com/openscience/hubsetup/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/hubsetup/</guid>
      <description>

&lt;h1 id=&#34;adding-a-hub&#34;&gt;Adding a Hub&lt;/h1&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This document assumes that you have followed the walkthrough at least once before. You already have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Logged in with an account that has &lt;code&gt;sudo&lt;/code&gt; permissions&lt;/li&gt;
&lt;li&gt;Docker installed&lt;/li&gt;
&lt;li&gt;Proxy configured, secured with HTTPS&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This walk-through will guide you through the bare-minimal steps to set up a new hub.&lt;/p&gt;

&lt;h2 id=&#34;preliminaries&#34;&gt;Preliminaries&lt;/h2&gt;

&lt;p&gt;First, we need to decide on the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Name of new hub&lt;/li&gt;
&lt;li&gt;An available port for it to be hosted on&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will run the following commands to find out what is already in use:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker ps --format &amp;quot;table {{.Names}}\t{{.Status}}\t{{.Ports}}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will see the names and ports formatted printed out. Here is an example of what that might look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;NAMES                STATUS              PORTS
math8660-user-troy   Up 32 minutes       8888/tcp
math-user-michael    Up 3 days           8888/tcp
math8660             Up 3 days           0.0.0.0:8002-&amp;gt;8000/tcp
math8660-db          Up 3 days           5432/tcp
math                 Up 3 days           0.0.0.0:8000-&amp;gt;8000/tcp
math-db              Up 3 days           5432/tcp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we are seeing is a list of processes being run by Docker and their respective ports.
The ones that read &lt;code&gt;8888/tcp&lt;/code&gt; are on the local docker-network (these are the single-user notebook servers).
It is fine for these numbers to conflict since they are not ports open on the main server.
The databases on &lt;code&gt;5432&lt;/code&gt; are similarly of no concern to us.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;If the output of this command is blank (perhaps this is your first time), then &lt;em&gt;nothing is running&lt;/em&gt;, and so you can stick with the default name and port number in our deployment.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;We can also see that three hubs are live on this server, listening for connections on local ports &lt;code&gt;8000&lt;/code&gt; and &lt;code&gt;8001&lt;/code&gt; in addition to the two user containers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We simply need to choose any port other than &lt;code&gt;8000&lt;/code&gt; or &lt;code&gt;8002&lt;/code&gt;&lt;/strong&gt; (e.g. &lt;code&gt;8001&lt;/code&gt;, &lt;code&gt;8003&lt;/code&gt;, &lt;code&gt;8451&lt;/code&gt;, &lt;code&gt;8762&lt;/code&gt;, etc.).&lt;/p&gt;

&lt;p&gt;We also see that the two names in use are &lt;code&gt;math&lt;/code&gt; (default in our deployment) and &lt;code&gt;math8660&lt;/code&gt;, so we would have to choose a different name.
In our deployment, this name is ALSO where your hub will live (&lt;code&gt;example.com/math8660&lt;/code&gt; and &lt;code&gt;example.com/math&lt;/code&gt; are live in the above output).&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;The proxy configurations must direct traffic to these &amp;ldquo;locations&amp;rdquo; (&lt;code&gt;/math&lt;/code&gt; and &lt;code&gt;/math8660&lt;/code&gt;) for it to be publicly accessible. See the &lt;a href=&#34;./openscience/walkthrough#proxy&#34;&gt;Proxy section of the Walkthrough&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;em&gt;Before proceeding, let us get the necessary files.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Clone the repository from GitHub or copy an existing hub&amp;rsquo;s directory and rename the folder, or upload the files in any way you want.&lt;/p&gt;

&lt;p&gt;Rename it to something memorable (perhaps the name of your hub).
Here we choose &amp;ldquo;deploy&amp;rdquo; as our folder name.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/mathematicalmichael/jupyterhub-deploy-docker.git
mv jupyterhub-deploy-docker/ deploy/
cd deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last line brings us into the &lt;code&gt;deploy&lt;/code&gt; directory, where the instructions that follow pick up. They assume that you have cloned the repo.&lt;/p&gt;

&lt;h1 id=&#34;quick-install&#34;&gt;Quick Install&lt;/h1&gt;

&lt;p&gt;I have added a convenience script that allows for automatic creation of a hub. It creates one default &lt;code&gt;hub-admin&lt;/code&gt; user and prints the password as output when it completes the build process and the hub is live.
It will also print out the entry that needs to be added to &lt;code&gt;/etc/nginx/sites-enabled/hub.conf&lt;/code&gt; in order to add your hub.&lt;/p&gt;

&lt;h2 id=&#34;instructions&#34;&gt;Instructions&lt;/h2&gt;

&lt;p&gt;If you have no existing hub named &lt;code&gt;math&lt;/code&gt; and port &lt;code&gt;8000&lt;/code&gt; is available, then nothing needs to be edited. (If you need to reassign &lt;code&gt;HUB_NAME&lt;/code&gt; and &lt;code&gt;PORT_NUM&lt;/code&gt;, edit the first lines of &lt;code&gt;.env&lt;/code&gt;). Be aware of re-using old names from previous deployments&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:reuse&#34;&gt;&lt;a href=&#34;#fn:reuse&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Once you are ready, run:&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;This may take 10-15 minutes in total but will handle everything for you.&lt;/p&gt;

&lt;/div&gt;


&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;This script presumes this is your first run. It creates several files that are only required initially, and re-running it will delete any changes you made to &lt;code&gt;userlist&lt;/code&gt; unless you comment out the first line (which creates this file).&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;A dialogue will come across the screen tell you the password to get into the hub and what to add to the proxy configuration.
Once you log in, you can add users through the Admin panel.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;On the CU Denver campus, (or from behind any private network), you will likely encounter a warning in your browser that you must &lt;em&gt;Add an Exception&lt;/em&gt; to handle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.michaelpilosov.com/img/hub-error.png&#34; alt=&#34;hub-error&#34; /&gt;
Chrome, Firefox, Edge, etc. all have variations on the following dialogue windows that you must go through before seeing your hub:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.michaelpilosov.com/img/hub-error-confirm.png&#34; alt=&#34;hub-error-confirm&#34; /&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;However, to manage shared volumes for groups/teams, you must change &lt;code&gt;userlist&lt;/code&gt; accordingly.&lt;/p&gt;

&lt;h2 id=&#34;group-memberships&#34;&gt;Group Memberships&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;setup.sh&lt;/code&gt; script additionally creates one group (team) named &lt;code&gt;shared&lt;/code&gt; and associated volume, mounting it to &lt;code&gt;hub-admin&lt;/code&gt;&amp;rsquo;s working directory.
All shared (group) directories are prepended with &lt;code&gt;shared-&lt;/code&gt;, which is what &lt;code&gt;jupyterhub_config.py&lt;/code&gt; is expecting when it reads &lt;code&gt;userlist&lt;/code&gt; to determine group memberships.&lt;/p&gt;

&lt;p&gt;If you open up &lt;code&gt;userlist&lt;/code&gt; and add more users who belong to the &lt;code&gt;shared&lt;/code&gt; group, they will also see this folder and be able to read/write to it. You can add any phrase (groupname) to a user&amp;rsquo;s line, but be sure to create the volume and set its permissions before refreshing the hub (if you do not do this, Docker will create the volume automatically, but users will only be given read permissions by default).&lt;/p&gt;

&lt;p&gt;To create volumes for new groups and set the permissions, run the following command (which parses information to find where Docker has linked the new volume, and passes the directory to &lt;code&gt;chmod&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export SHARED_VOLUME_NAME=newGroupNameHere
docker volume create shared-$SHARED_VOLUME_NAME
sudo chmod 777 $(docker inspect shared-$SHARED_VOLUME_NAME | grep &amp;quot;Mountpoint&amp;quot; | awk &#39;{print $2}&#39; | sed &#39;s/&amp;quot;//g&#39; | sed &#39;s/,//g&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Be sure to change the above to reflect any group names you (or your students) choose, and run it for every new group name.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;An example &lt;code&gt;userlist&lt;/code&gt; might look like (group orders do not matter):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hub-admin shared admin 
mpilosov admin shared team-1
halljord team-1
tbutler admin team-1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;finding-out-passwords&#34;&gt;Finding out Passwords&lt;/h2&gt;

&lt;p&gt;After adding users/groups to &lt;code&gt;userlist&lt;/code&gt;, you will have to restart hub for changes to take effect.
This can be accomplished through the Control Panel by clicking &amp;ldquo;Shut Down Hub&amp;rdquo; and refreshing the page).&lt;/p&gt;

&lt;p&gt;Log in as &lt;code&gt;hub-admin&lt;/code&gt; and visit &lt;code&gt;/hub/login_list&lt;/code&gt; to see all users and passwords from &lt;code&gt;userlist&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Additionally, if you edit the last line of &lt;code&gt;.env&lt;/code&gt; and uncomment the last lines of &lt;code&gt;show_login.sh&lt;/code&gt;, you can see individual user passwords from the command-line by running &lt;code&gt;./show_login.sh&lt;/code&gt; from the root project directory (here, &lt;code&gt;/deploy&lt;/code&gt;).&lt;/p&gt;

&lt;h2 id=&#34;sharing-passwords&#34;&gt;Sharing Passwords&lt;/h2&gt;

&lt;p&gt;To share passwords across hubs, simply be sure that &lt;code&gt;secrets/oauth.env&lt;/code&gt; is the same. Copy it over from any existing hubs you desire.&lt;/p&gt;

&lt;h2 id=&#34;restarting-the-hub&#34;&gt;Restarting the Hub&lt;/h2&gt;

&lt;p&gt;You will need to run the following from the hub&amp;rsquo;s root directory for these changes (as well as those made to &lt;code&gt;userlist&lt;/code&gt;), to take effect:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose down
docker-compose build
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;These commands stop and destroy the containers running the hub and database, remove the existing image, re-build the Hub&amp;rsquo;s image and re-launch it (with no data loss, since volumes and networks are preserved).&lt;/p&gt;

&lt;/div&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;manual-install&#34;&gt;Manual Install&lt;/h1&gt;

&lt;p&gt;If you want to perform the steps carried out in &lt;code&gt;setup.sh&lt;/code&gt; yourself, you can follow these directions (or simply run the commands in that file one-by-one). This script is designed to save you time and effort.&lt;/p&gt;

&lt;h2 id=&#34;configure-settings&#34;&gt;Configure Settings&lt;/h2&gt;

&lt;p&gt;Now that we are in the &lt;code&gt;deploy&lt;/code&gt; directory (or whatever you named your hub):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir secrets
make secrets/postgres.env
make secrets/oauth.env
make userlist
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you copied an existing hub, be aware that your secret files will be shared between the two (same login credentials).&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;At the very least, remove &lt;code&gt;postgres.env&lt;/code&gt; and re-make the secret key there.
If you want &lt;em&gt;passwords to be shared&lt;/em&gt; for users across hubs, keep &lt;code&gt;oauth.env&lt;/code&gt; the same among the hubs. &lt;em&gt;Passwords are set during the build process.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;You will see some dialogue regarding how to add users to the hub initially.
We only need to be concerned with adding one administrative user at this time since we can add users later through the Hub&amp;rsquo;s interface.
Run the following command and edit the &lt;code&gt;userlist&lt;/code&gt; according to the prompt you just saw, which will show you how to format this file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim userlist
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, run &lt;code&gt;vim .env&lt;/code&gt; to change the name of your hub and the port to avoid conflicts with running Docker processes.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;The noteboook image that gets built by default is quite sizable.&lt;/p&gt;

&lt;p&gt;You may consider changing this in the &lt;code&gt;.env&lt;/code&gt; file (&lt;code&gt;$DOCKER_NOTEBOOK_IMAGE&lt;/code&gt;) if you&amp;rsquo;re just testing it out and want to make sure it works (perhaps to &lt;code&gt;jupyter/minimal-notebook&lt;/code&gt; or another &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;pre-built stack&lt;/a&gt; ).
But, the one we ship is &lt;em&gt;feature-rich&lt;/em&gt;. Consider it a &amp;ldquo;show off what this can do&amp;rdquo; example.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The notebook image that gets build starts off with &lt;code&gt;$DOCKER_NOTEBOOK_IMAGE&lt;/code&gt; and adds in some features.
To change the image, edit &lt;code&gt;singleuser/Dockerfile&lt;/code&gt; and delete as much as you would like.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;At any point you can re-build this image with &lt;code&gt;make notebook_image&lt;/code&gt; (which we will run in a moment in the next step).&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;build&#34;&gt;Build&lt;/h2&gt;

&lt;p&gt;We are now ready to build our hub! The last line also &lt;em&gt;runs&lt;/em&gt; it as a background process.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make build
make notebook_image
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that is all. Sit back and wait.
It will take a while.&lt;/p&gt;

&lt;p&gt;You might see a bunch of red messages like these fly by during the build process.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chgrp: changing group of &#39;/opt/conda/var/cache/fontconfig/0c78243b-3123-48a4-91b4-49cb45a27aaf-le64.cache-7&#39;: Operation not permitted
chgrp: changing group of &#39;/opt/conda/var/cache/fontconfig/2fd305a6-4303-4a09-8894-d1594f7ec636-le64.cache-7&#39;: Operation not permitted
.
.
.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As far as I can tell, this is not a problem and occurs somewhere outside of the instructions I have added on top of the pre-built images supplied by Jupyter.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;If successful, you should see green &lt;code&gt;done&lt;/code&gt; output at the very end.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;When you want to destroy the images that get built (&lt;code&gt;make build&lt;/code&gt; runs &lt;code&gt;docker-compose build&lt;/code&gt; with some other options to configure it properly), and the associated containers created from them, you can run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose down
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to clean up. Since data is external to the containers that host our application, you won&amp;rsquo;t lose any configurations at all.&lt;/p&gt;

&lt;h2 id=&#34;direct-traffic&#34;&gt;Direct Traffic&lt;/h2&gt;

&lt;p&gt;From the &lt;a href=&#34;./openscience/walkthrough&#34;&gt;walkthrough&lt;/a&gt;, you should have already configured the nginx proxy. Now all that is left is to tell our proxy the &amp;ldquo;location&amp;rdquo; of our hub so that it can become publicly accessible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo vim /etc/nginx/sites-enabled/hub.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You need to look for the &lt;code&gt;server&lt;/code&gt; object (if secured, on port &lt;code&gt;443&lt;/code&gt;) that matches the domain name that this hub will exist on, and add an entry inside of this server configuration. It will look like this (for the default hub that ships with the deployment, specified in &lt;code&gt;.env&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;location /math {
    proxy_pass http://127.0.0.1:8000;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    # websocket headers
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, when &lt;code&gt;example.com/math&lt;/code&gt; is hit, our proxy (nginx) will direct traffic to &lt;code&gt;localhost&lt;/code&gt; (&lt;code&gt;127.0.0.1&lt;/code&gt;). Specifically, to port &lt;code&gt;8000&lt;/code&gt;. Make sure that the entry you add matches the &lt;code&gt;.env&lt;/code&gt; file. Here, we show the default.&lt;/p&gt;

&lt;h2 id=&#34;acquire-credentials&#34;&gt;Acquire Credentials&lt;/h2&gt;

&lt;p&gt;To get your password, &lt;code&gt;vim Makefile&lt;/code&gt; and uncomment the following line (around 5): &lt;code&gt;include secrets/oauth.env&lt;/code&gt;
(Alternatively, you can just run &lt;code&gt;source secrets/oauth.env&lt;/code&gt; and skip editing the file).&lt;/p&gt;

&lt;p&gt;Once that is done, you can run &lt;code&gt;make login&lt;/code&gt; to find out the password for whatever user is specified in &lt;code&gt;.env&lt;/code&gt;.
&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Hopefully the user in &lt;code&gt;.env&lt;/code&gt; matches at least one of the admin users you put in &lt;code&gt;userlist&lt;/code&gt;, otherwise you would be querying passwords for non-existent users. If not, edit &lt;code&gt;.env&lt;/code&gt; and &lt;code&gt;userlist&lt;/code&gt; and run &lt;code&gt;docker-compose down; docker-compose up -d&lt;/code&gt; to re-build the images.&lt;/p&gt;

&lt;/div&gt;
&lt;/p&gt;

&lt;h2 id=&#34;test&#34;&gt;Test&lt;/h2&gt;

&lt;p&gt;You can now log in by visiting &lt;code&gt;example.com/math&lt;/code&gt; and ensure that everything is working as expected out of the box.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;[hub-admin]:&#34; alt=&#34;snapshot-of-login&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can add users through &lt;code&gt;Control Panel &amp;gt; Admin&lt;/code&gt;!
![snapshot-of-admin][hub-admin]&lt;/p&gt;

&lt;p&gt;Now that you have your password, log in to the hub. If you navigate to &lt;code&gt;/hub/login_list&lt;/code&gt; you will see passwords for everyone in &lt;code&gt;userlist&lt;/code&gt;. Since the connection is not yet secure, do not do this yet.&lt;/p&gt;

&lt;p&gt;You can bring up or take down your hub with
&lt;code&gt;docker-compose up -d&lt;/code&gt; and
&lt;code&gt;docker-compose down&lt;/code&gt;, but must run these in the same directory as the &lt;code&gt;docker-compose.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;management&#34;&gt;Management&lt;/h1&gt;

&lt;h2 id=&#34;adding-packages&#34;&gt;Adding Packages&lt;/h2&gt;

&lt;p&gt;Assuming you are ssh&amp;rsquo;ed into the server and inside the directory that has your hub, simply edit &lt;code&gt;singleuser/Dockerfile&lt;/code&gt; and use the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker&#34;&gt;Docker Reference&lt;/a&gt; on the next page to run commands.&lt;/p&gt;

&lt;h2 id=&#34;managing-users-work&#34;&gt;Managing Users/Work&lt;/h2&gt;

&lt;p&gt;When logged in to the hub, you can access &lt;code&gt;Control Panel &amp;gt; Admin&lt;/code&gt; to add users and access their servers.&lt;/p&gt;

&lt;p&gt;To disable the feature of Admins being able to log in as the students, set &lt;code&gt;c.JupyterHub.admin_access = False&lt;/code&gt; in &lt;code&gt;jupyterhub_config.py&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;group-sharing&#34;&gt;Group Sharing&lt;/h2&gt;

&lt;p&gt;Sharing files between groups is a feature I personally coded into the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file. Towards the top of the script, the file &lt;code&gt;userlist&lt;/code&gt; is opened (in the container&amp;hellip; so if you update it, you can run &lt;code&gt;docker restart hub-name&lt;/code&gt; since this configuration file only runs at hub startup). Better yet, do this from the Admin menu directly.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Each line in &lt;code&gt;userlist&lt;/code&gt; has the name of the student, followed by their group names, separated by spaces.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Instead of restarting through the docker command, you can &amp;ldquo;Power Down&amp;rdquo; the Hub from the Control Panel in JupyterHub. This has the effect of propagating changes to lists of users. Docker takes care of re-starting the hub automatically.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;If userlist is given the right permissions with &lt;code&gt;chown 777 userlist&lt;/code&gt;, and mounted inside the professor&amp;rsquo;s directory, it may be possible to manage group memberships  without ever logging into the math-hub server (except to update the single-user notebook image), editing the &lt;code&gt;userlist&lt;/code&gt; right from the web-interface, provided the group volume permissions have previously been set correctly.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;&lt;code&gt;jupyterhub_config.py&lt;/code&gt; will check the user&amp;rsquo;s groups and mount all appropriate volumes. A volume is created for the group if one does not exist.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;By default, when volumes are created, the permissions are not set in a way where users can write files.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;To fix this, you would find the shared group volume in question, use &lt;code&gt;docker inspect&lt;/code&gt; to find out where it is, and change the permissions with &lt;code&gt;chmod&lt;/code&gt;. Here is an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pilosovm@math-hub:~$ docker volume ls | grep &amp;quot;shared-*&amp;quot; | awk &#39;{print $2}&#39;
ro_shared_volume
rw_shared_volume
shared-broncos
shared-test-group
pilosovm@math-hub:~$
pilosovm@math-hub:~$ docker volume inspect shared-broncos | grep &amp;quot;Mountpoint&amp;quot;
        &amp;quot;Mountpoint&amp;quot;: &amp;quot;/var/lib/docker/volumes/shared-broncos/_data&amp;quot;,
pilosovm@math-hub:~$ chmod 777 /var/lib/docker/volumes/shared-broncos/_data
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;p&gt;In this manner, you can create new volumes (e.g. &lt;code&gt;docker volume create shared-groupname&lt;/code&gt;) and set the permissions as desired with &lt;code&gt;chmod&lt;/code&gt;, modifying &lt;code&gt;userlist&lt;/code&gt; to add &lt;code&gt;groupname&lt;/code&gt; to the appropriate users.&lt;/p&gt;

&lt;p&gt;Rinse, repeat.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;The architecture implemented here mounts volumes based on the words that follow the username in &lt;code&gt;userlist&lt;/code&gt; and prepends them with &lt;code&gt;shared&lt;/code&gt;. If you want to avoid naming conflicts, use group names such as &lt;code&gt;math8660-group1&lt;/code&gt;, &lt;code&gt;math8660-group2&lt;/code&gt;, etc., or something unique chosen by the group members). &lt;strong&gt;It is up to you to avoid naming conflicts across multiple hubs when sharing group volumes.&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;More customization is possible. For example, you can have multiple hubs set up on the same server (e.g. at &lt;code&gt;example.com/hub1/&lt;/code&gt; and &lt;code&gt;example.com/hub2/&lt;/code&gt;, etc.) but create one &lt;code&gt;shared-admin&lt;/code&gt; volume that every administrator has access to. To accomplish this, (&lt;em&gt;or to add any new group volume&lt;/em&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker volume create shared-admin
docker volume inspect shared-admin | grep &amp;quot;Mountpoint&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then use &lt;code&gt;chmod 777 PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; matches the path in the output of the last command. Now this volume is visible to anyone for whom it is mounted.&lt;/p&gt;

&lt;p&gt;However, in &lt;code&gt;jupyterhub_config.py&lt;/code&gt;, we have this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;33                 for i in range(1,len(parts)):
34                     group_id = parts.pop()
35                     if group_id != &#39;admin&#39;: # no need for an admin group.
36                         group_map[user_name].append(group_id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We purposefully disable this from happening by default. To enable it, simply change the logic here. Erase line 35, un-indent line 36, and the &lt;code&gt;shared-admin&lt;/code&gt; volume will be mounted for all admins of all hubs. Don&amp;rsquo;t forget to restart your hub for the changes to take effect.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:reuse&#34;&gt;The command &lt;code&gt;docker-compose down&lt;/code&gt; does not remove volumes created during the build process. If using a name of a hub that once existed, remove the old volumes with &lt;code&gt;docker volume rm&lt;/code&gt; (use &lt;code&gt;docker volume ls&lt;/code&gt; to list existing volumes and look for &lt;code&gt;-data&lt;/code&gt; endings).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:reuse&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>JupyterHub</title>
      <link>https://www.michaelpilosov.com/openscience/jupyterhub/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/jupyterhub/</guid>
      <description>

&lt;h1 id=&#34;the-end-user-experience&#34;&gt;The End-User Experience&lt;/h1&gt;

&lt;p&gt;You go to a web-address and are confronted with the Jupyterhub login portal.
Once you log in, you see a drop-down menu that allows you to choose what &amp;ldquo;stack&amp;rdquo; of software dependencies you would like to use.
After you make your selection, you are redirected to an in-browser interface where all your files are available.
Jupyter Notebooks, R Scripts, anything you want, can now be run directly through this interface.&lt;/p&gt;

&lt;p&gt;The work is performed &amp;ldquo;in the cloud.&amp;rdquo; What this means is that a connection is established between your browser window (the client) and a server (the host) elsewhere that is capable of performing the calculations you need.&lt;/p&gt;

&lt;h2 id=&#34;benefits&#34;&gt;Benefits&lt;/h2&gt;

&lt;p&gt;You do not have to worry about installing software dependencies, since the administrator has already loaded them into the environment that you selected.
The machine you are working on will not be doing anything except communicating commands to the host and displaying the result, which means your computer will run on less energy.&lt;/p&gt;

&lt;p&gt;Moreover, it means that since &lt;em&gt;all you need is a functional internet browser,&lt;/em&gt; you can do all of your scientific work with a budget laptop (or in a pinch, a phone/tablet).
For academic institutions, this means that entire laboratories of computers can be re-purposed for better uses, since students will not be limited by the technology they can afford.&lt;/p&gt;

&lt;p&gt;If you are an administrative user, you can add other users through a control-panel available through this interface, and even be able to see when these users are logged in.
If configured by the system administrator who set all this up, you may also be able to start an environment &lt;em&gt;as&lt;/em&gt; any of these users, and look around their folders/files, perhaps as a teacher helping de-bug some code during remotely-held office hours.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sounds neat, doesn&amp;rsquo;t it?&lt;/em&gt;
Especially for academics, this lowering of friction to programming is especially appealing.
The hardest parts of setting up a class with the resources they need to start learning how to code have all been abstracted away for both the students and teachers who serve as administrators.
All of this is already possible, and there are &lt;em&gt;a lot&lt;/em&gt; of ways to set this exact thing up, which makes navigating how to do so a little difficult.
We will discuss this later after building up the proper motivation.&lt;/p&gt;

&lt;h2 id=&#34;application-architecture&#34;&gt;Application Architecture&lt;/h2&gt;

&lt;p&gt;This separation of where work is performed and where its results are shown is actually essential to understanding how most modern  &amp;ldquo;applications&amp;rdquo; are built.
By not burdening end-users with installation dependencies that vary with the technology they own, application developers avoid worrying about cross-platform support.
Most applications are now simply re-skinned versions of a browser called Chromium&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:chrome&#34;&gt;&lt;a href=&#34;#fn:chrome&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, which direct you to the company&amp;rsquo;s servers where all the work is performed.&lt;/p&gt;

&lt;p&gt;In this spirit, the Jupyter Project has done the same thing for scientists and programmers.
The open-source community that powers most of the work done by Jupyter is largely concentrated at UC Berkeley, and the adoption of their work is spreading fast across the world.
However, due to the rapid pace of development, a cohesive narrative that explains how all the technologies developed by the Jupyter Project are connected is hard to come by.
We attempt to address this problem with this document, stepping through the layers of abstraction and building up a story that helps develop an understanding of how these underlying technologies interface and the many ways in which they can be configured&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:config&#34;&gt;&lt;a href=&#34;#fn:config&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h1 id=&#34;jupyterhub&#34;&gt;Jupyterhub&lt;/h1&gt;

&lt;p&gt;The management of users and the environments they are able to use is done through the interface known as Jupyterhub (the &amp;ldquo;Hub&amp;rdquo; for short).
The Hub controls who is allowed to access a notebook server through an &lt;em&gt;Authenticator&lt;/em&gt;.
This can be a username/password combination, or a one-click login through a third-party such as Github, Gitlab, Google, Azure, or your university&amp;rsquo;s login page.&lt;/p&gt;

&lt;p&gt;Jupyterhub passes information to an Authenticator, which returns a &amp;ldquo;successful&amp;rdquo; (or not) message to the Hub, which (if successful) then performs some action.
In the example above, the action is performed was to first display a drop-down menu that allows a user to select an environment.
(This can be bypassed if you want every end-user to have the same environment).
Jupyterhub then &amp;ldquo;spawns&amp;rdquo; a &amp;ldquo;single-user (notebook) server&amp;rdquo; to establish the connection between computational resources and the user-facing interface through the browser&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:server&#34;&gt;&lt;a href=&#34;#fn:server&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
The Hub launches such a server for each user that successfully logs in.&lt;/p&gt;

&lt;p&gt;Jupyterhub is thus made up of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An Authenticator (that lets people in or keeps them out),&lt;/li&gt;
&lt;li&gt;a Spawner (which defines individual environments),&lt;/li&gt;
&lt;li&gt;a Database (to store users), and&lt;/li&gt;
&lt;li&gt;a Server (to connect all of it).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker/raw/master/internal/jupyterhub-docker.png&#34; alt=&#34;schematic&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;notebook-server&#34;&gt;Notebook Server&lt;/h2&gt;

&lt;p&gt;At the heart of the system is the Jupyter Notebook (server).
The notebook server communicates with the relevant processes on the host machine to carry out the computations that you (the client) asked it to perform through your browser interface.
The machine running the notebook server has all the necessary dependencies to perform the work, and your end-user experienced is managed through the Jupyter notebook server.&lt;/p&gt;

&lt;p&gt;The native file-format for the interface the notebook server is the &amp;ldquo;interactive notebook&amp;rdquo; (which has the &lt;code&gt;.ipynb&lt;/code&gt; ending).
All that these notebooks are is a collection of key-value pairs (dictionaries, linked lists, many words exist), each of which corresponds to one &amp;ldquo;cell&amp;rdquo; in the notebook and carries input/output information along with formatting specifications.
Since it is best to see by example, here is an abstraction of what this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&amp;quot;cell_1&amp;quot;: {info} }
{&amp;quot;cell_2&amp;quot;: {info} }
{&amp;quot;cell_3&amp;quot;: {info} }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where each one of these &lt;code&gt;{info}&lt;/code&gt; elements corresponds to a dictionary itself, which might look something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&amp;quot;input&amp;quot;: &amp;lt;&amp;gt;, 
 &amp;quot;output&amp;quot;: &amp;lt;&amp;gt;,
 &amp;quot;execution_count&amp;quot;: &amp;lt;&amp;gt;, 
 &amp;quot;kernel&amp;quot;: &amp;lt;&amp;gt;, ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of this information is used to format an HTML page that is then rendered by a browser of your choice, since at this point it is simply a web page.&lt;/p&gt;

&lt;p&gt;Now, it is important to note at this time that if you are using a computer that has all the required software dependencies you need, then you can become the &amp;ldquo;host&amp;rdquo; yourself, and run the notebook server locally.
In the event that you do this, the website you visit to see the notebook server file-browsing interface and work with notebooks will look something like &lt;code&gt;http://localhost:8000&lt;/code&gt;, where &lt;code&gt;localhost&lt;/code&gt; is telling your browser that &amp;hellip; well, the host is &lt;em&gt;local&lt;/em&gt;, not somewhere &lt;em&gt;remote&lt;/em&gt;&amp;hellip;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:web&#34;&gt;&lt;a href=&#34;#fn:web&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.
The &lt;code&gt;:8000&lt;/code&gt; (the number can differ) is the &lt;em&gt;port&lt;/em&gt; that is being opened on the machine to allow for input/output connections, which is what is handled by the server.
&lt;em&gt;(Remember this&amp;hellip; it&amp;rsquo;ll come up later).&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;An Analogy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If the website is considered the &amp;ldquo;address&amp;rdquo; of the machine(s), the port is the &amp;ldquo;apartment number.&amp;rdquo;
Many &amp;ldquo;tenants&amp;rdquo; (applications) can &amp;ldquo;live&amp;rdquo; (be hosted) at the same &amp;ldquo;address&amp;rdquo; (website).
Some buildings choose to have a doorman, so you can ask for directions to the right place &lt;em&gt;by name&lt;/em&gt; instead of apartment number.
So if you do not see a port number (&lt;code&gt;:XXXX&lt;/code&gt;) anywhere in the browser address, you can assume that the configuration implemented has a &amp;ldquo;doorman&amp;rdquo; (proxy) directing traffic to the right places.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This about sums up what you need to know about the notebook server.
&lt;em&gt;Somewhere there exists a machine that can do what you want.
By running a notebook server on this machine, you can connect to it through a web-browser.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;spawning&#34;&gt;Spawning&lt;/h2&gt;

&lt;p&gt;There are many ways to start the (single-user) notebook servers.
They can be started as individual processes on the same machine that the Hub is running on, which is the default behavior, and the implementation used in &lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub&#34; target=&#34;_blank&#34;&gt;The Littlest Jupyterhub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, in the spirit of modularity, they can also be started on machines elsewhere in the world.
These machines may be set up with all the dependencies, waiting for authenticated connections from Hub, or they can be created (and destroyed) &lt;em&gt;on-demand.&lt;/em&gt;
They can be physical machines, or &amp;ldquo;virtual machines,&amp;rdquo; which (as the name suggests) are emulations of computers that run as processes on top of some existing architecture.&lt;/p&gt;

&lt;h3 id=&#34;containerization&#34;&gt;Containerization&lt;/h3&gt;

&lt;p&gt;Virtual machines allow for something called &amp;ldquo;containerization,&amp;rdquo; which isolated applications in (usually Linux) virtual environments that contain little else but the bare necessities for running a given application.&lt;/p&gt;

&lt;p&gt;To scale to millions of users, services exist that allow for the creation and destruction of virtual machines on-demand, with low latency, and pricing computed by the second.
Such services sit atop a software platform called Kubernetes, and require a decent amount of technical experience to configure.
Jupyterhub can be configured to &amp;ldquo;spawn&amp;rdquo; single-user notebook servers through such a service using an extension called &amp;ldquo;Kubespawner.&amp;rdquo;
However, we do not provide any more information about this herein because the wiki for Jupyterhub is written specifically for this implementation case.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We focus on a solution that is capable of scaling to hundreds of users and can be built with existing server resources that a department may have that are underutilized, but is a little more technically challenging to implement than &lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub&#34; target=&#34;_blank&#34;&gt;The Littlest Jupyterhub&lt;/a&gt;, which basically functions as a one-click install and provides its own set of configuration scripts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;docker&#34;&gt;Docker&lt;/h3&gt;

&lt;p&gt;A simpler solution though, can be achieved through &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker&#34;&gt;Docker&lt;/a&gt;, which (although it has a learning curve), is capable of scaling to very large workloads and can be configured to connect multiple servers and balance traffic amongst them.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We choose to run Jupyterhub within a Docker container, the Database in another container, and then spawn single-user notebook servers each in isolated containers as well.
The latter containers are ephemeral, which means that once a user shuts down their single-user server (or it is shut down due to inactivity after a predetermined amount of time), the container is destroyed.
Containerizing every aspect of this project allows for a really simple deployment scenario, which we walk through on the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/deploy&#34;&gt;Deployment&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can &amp;ldquo;containerize&amp;rdquo; the environments we want our users to experience in their single-user notebook servers through the use of a &amp;ldquo;Dockerfile,&amp;rdquo; which simply lists a set of instructions to configure a brand-new Ubuntu (Linux distribution) machine to handle all the dependencies.&lt;/p&gt;

&lt;p&gt;The single-user notebook servers can be launched from a choice of &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker/#images&#34;&gt;&amp;ldquo;images,&amp;rdquo;&lt;/a&gt; which define the containers that are created/destroyed on-demand.&lt;/p&gt;

&lt;p&gt;In this way, our applications are &amp;ldquo;stateless,&amp;rdquo; which means that all the information (files, data, configuration) is connected to the application virtually (Docker handles these connections through something called &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker#volumes&#34;&gt;&amp;ldquo;volumes&amp;rdquo;&lt;/a&gt;.
So, if properly configured, &lt;em&gt;a student can launch any environment they want and still see the same set of files.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;database&#34;&gt;Database&lt;/h2&gt;

&lt;p&gt;A basic SQL database comes prepackaged and configured with Jupyterhub, but for &amp;ldquo;production&amp;rdquo; purposes, the developers in the Jupyter Project advise using a more resilient database such as PostgresDB, which is the solution we implemented, following the &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deployment Example&lt;/a&gt; provided by Jupyter.&lt;/p&gt;

&lt;p&gt;This postgres database will exist inside its own container and be connected to an external volume (managed by Docker), so that we can create/destroy the Hub and not lose any of our user data.&lt;/p&gt;

&lt;h2 id=&#34;authenticator&#34;&gt;Authenticator&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/wiki/Authenticators&#34; target=&#34;_blank&#34;&gt;Wiki&lt;/a&gt; has a list of authenticator options.
The default behavior is to check the system users on the machine running Jupyterhub.
In the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file which is used to set up the Hub, a &lt;code&gt;whitelist&lt;/code&gt; and &lt;code&gt;admins&lt;/code&gt; attribute are defined to control who is allowed in.
If inside a container, this means that users must be created inside of there!
The nice thing about using an authentication service such as OAuth is that it simplifies the login entirely, since accounts exist on other platforms to verify users.
The downside is that you must own a &amp;ldquo;fully qualified domain name&amp;rdquo; in order to do this, which means you must own the website (can be as low as $2-10/year, available via &lt;a href=&#34;https://namecheap.com or similar provider&#34; target=&#34;_blank&#34;&gt;Namecheap&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;p&gt;As mentioned in the analogy in &lt;a href=&#34;./#notebook-server&#34;&gt;earlier sections&lt;/a&gt;, the &amp;ldquo;doorman&amp;rdquo; that directs traffic around is the component of this application known as the &amp;ldquo;proxy&amp;rdquo;, and is the last part left in securing and configuring your server.&lt;/p&gt;

&lt;h2 id=&#34;volumes&#34;&gt;Volumes&lt;/h2&gt;

&lt;p&gt;Files and folders, as mentioned, persist on the machine that is hosting the application, and can even be configured (e.g., with symbolic links), to connect to file-servers elsewhere.
My university, for example, has a system for all of us to be able to store files on a remote server, and we can &amp;ldquo;mount&amp;rdquo; these connections appropriately by configuring Jupyterhub so that students can more readily access such resources.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:chrome&#34;&gt;which serves as the backbone for Google Chrome.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:chrome&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:config&#34;&gt;We note that the reason that there are so many possible ways to set up such a system is because the developers ensured the modularity of all the application components. There is a lot of segmentation that allows for this technology to scale to thousands of users. The lessons learned by mobile developers about scaling in popularity have all been implemented here.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:config&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:server&#34;&gt;The distinction is made for (single-user) servers since Jupyterhub itself is a server communicating with other applications/servers.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:server&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:web&#34;&gt;I suppose this would be a good time to mention that any website you visit is simply an alias for an &amp;ldquo;address&amp;rdquo; to some other computer elsewhere in the world. The address system used on the internet is known as the &amp;ldquo;IP address&amp;rdquo;, so the &lt;code&gt;localhost&lt;/code&gt; is telling the browser to look for a connection on the same machine.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:web&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Open Science: Working towards reproducibility</title>
      <link>https://www.michaelpilosov.com/devlog/openscience/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/openscience/</guid>
      <description>

&lt;h1 id=&#34;jan-1-2019&#34;&gt;Jan 1, 2019&lt;/h1&gt;

&lt;p&gt;Today I split up the documentation here on devlog and began the write-ups for Jupyterhub.
I think I should segment out a section that goes through the entire process of deployment&lt;/p&gt;

&lt;p&gt;Notes:
- bash script to give you nice shortcuts
- SSH key generated ahead of time, ready to log in without passwords
- get Traefik proxy working
    - It seems extremely straightforward except that I do not know how to direct traffic to a folder. I suppose that since it is running port-mappings, I could have an nginx server&lt;/p&gt;

&lt;p&gt;This is helpful, but it&amp;rsquo;s not using docker.
&lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub/tree/master/tljh&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/the-littlest-jupyterhub/tree/master/tljh&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;okay the only thing I&amp;rsquo;ve managed to set up correctly is nginx outside of docker. This is annoying.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 3 * * 1 certbot renew --pre-hook &amp;quot;service nginx stop&amp;quot; --post-hook &amp;quot;service nginx start&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;crontab for renewals.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hub.conf&lt;/code&gt; inside of &lt;code&gt;/etc/nginx/sites-enabled&lt;/code&gt; (to be mounted)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# top-level http config for websocket headers
# If Upgrade is defined, Connection = upgrade
# If Upgrade is empty, Connection = close
map $http_upgrade $connection_upgrade {
    default upgrade;
    &#39;&#39;      close;
}

# HTTP server to redirect all 80 traffic to SSL/HTTPS
server {
    listen 80;
    server_name hub.consistentbayes.com;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

# HTTPS server to handle JupyterHub
server {
    listen 443;
    ssl on;

    server_name hub.consistentbayes.com;

    ssl_certificate /etc/letsencrypt/live/consistentbayes.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/consistentbayes.com/privkey.pem;

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_dhparam /etc/ssl/certs/dhparam.pem;
    ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&#39;;
    
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    # Managing literal requests to the JupyterHub front end
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;whereas the website looks like &lt;code&gt;/etc/nginxsites-enabled/consistentbayes.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    server_name consistentbayes.com;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

server {
    listen 443;
    ssl on;

    # INSERT OTHER SSL PARAMETERS HERE AS ABOVE
    ssl_certificate /etc/letsencrypt/live/consistentbayes.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/consistentbayes.com/privkey.pem;

    # Set the appropriate root directory
    root /var/www/consistentbayes.com/public_html;

    # Set URI handling
    location / {
        try_files $uri $uri/ =404;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Traefik Problems&lt;/em&gt;
&lt;code&gt;netstat -ltnp | grep -w &#39;:80&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So far this is the easiest I&amp;rsquo;ve had it configuring the set-up.. with nginx. Talk to Joe about getting Traefik to work.
&lt;a href=&#34;https://blog.raveland.org/post/traefik_le/&#34; target=&#34;_blank&#34;&gt;https://blog.raveland.org/post/traefik_le/&lt;/a&gt;
maybe that will help???
&lt;a href=&#34;https://www.bennadel.com/blog/3420-obtaining-a-wildcard-ssl-certificate-from-letsencrypt-using-the-dns-challenge.htm&#34; target=&#34;_blank&#34;&gt;https://www.bennadel.com/blog/3420-obtaining-a-wildcard-ssl-certificate-from-letsencrypt-using-the-dns-challenge.htm&lt;/a&gt;
or that&amp;hellip; (it is important to note that you need to follow instructions after feb 18 due to letsencrypt changing something major).&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-2-2019&#34;&gt;Jan 2, 2019&lt;/h1&gt;

&lt;p&gt;Spent day configuring proxy. Succeeded eventually on my domain, but not with a reverse proxy. Just a regular one&amp;hellip;&lt;/p&gt;

&lt;p&gt;Messed around with apache but couldn&amp;rsquo;t make it work.
&lt;a href=&#34;https://jupyterhub.readthedocs.io/en/latest/reference/config-proxy.html&#34; target=&#34;_blank&#34;&gt;Documentation on Jupyter&amp;rsquo;s website is god awful&lt;/a&gt;, there are numerous omissions and a typo in the configuration files (including ones from the &lt;a href=&#34;https://github.com/jupyterhub/oauthenticator/tree/master/examples/full&#34; target=&#34;_blank&#34;&gt;repository&lt;/a&gt; I got my original setup files), no context or setup instructions. They just assume you know what you are doing.&lt;/p&gt;

&lt;p&gt;I do not, though. So let&amp;rsquo;s go through it.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s what a reverse-proxy is doing.
It catches requests to a website and handles them.&lt;/p&gt;

&lt;p&gt;When you hit &lt;a href=&#34;consistentbayes.com&#34; target=&#34;_blank&#34;&gt;consistentbayes.com&lt;/a&gt;, it directs you to a folder with a bunch of files that make up my website. I had that working with Apache but couldn&amp;rsquo;t do what I wanted, which was direct traffic to &amp;ldquo;hub.consistentbayes.com&amp;rdquo; instead.&lt;/p&gt;

&lt;p&gt;I got the &amp;ldquo;hub&amp;rdquo; part set up by adding an &lt;code&gt;A Record&lt;/code&gt; into my DNS Control Panel (talk more about that later). Now the proxy just had to be able to handle and direct that request to a jupyterhub instance running in a docker container that was exposing itself on &lt;code&gt;http://127.0.0.1:8000&lt;/code&gt; (I&amp;rsquo;ll show config files later). The hub would be in a container that is just a Linux machine, with users and everything in there.&lt;/p&gt;

&lt;p&gt;If the container name is &amp;ldquo;nostalgic_colden&amp;rdquo; (TO DO: figure out how to name these)&amp;hellip; then running&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker exec -ti -u mpilosov nostalgic_colden /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will log you into the linux computer as &amp;ldquo;mpilosov&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The user accounts are handled at build-time, but can be managed within the computer just as you would on a linux machine (to log in as &lt;code&gt;root&lt;/code&gt;, omit &lt;code&gt;-u mpilosov&lt;/code&gt; above).&lt;/p&gt;

&lt;p&gt;So&amp;hellip; those accounts.
Github usernames. By far the best authentication method I found, but it relied on having a Fully Qualified Domain Name (website name, which the server at school would not let me do).
But&amp;hellip; we can loop the authenticator to whatever we want.&lt;/p&gt;

&lt;p&gt;Here are my nginx configurations:&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;/etc/nginx/sites-enabled/consistentbayes.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    server_name NO_HUB.DOMAIN.TLD;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

server {
    listen 443;
    ssl on;

    # INSERT OTHER SSL PARAMETERS HERE AS ABOVE
    # SSL cert may differ

    # Set the appropriate root directory
    root /var/www/html;

    # Set URI handling
    location / {
        try_files $uri $uri/ =404;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;/etc/nginx/sites-enabled/jupyterhub.conf&lt;/code&gt; (titles dont matter it seems).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# top-level http config for websocket headers
# If Upgrade is defined, Connection = upgrade
# If Upgrade is empty, Connection = close
map $http_upgrade $connection_upgrade {
    default upgrade;
    &#39;&#39;      close;
}

# HTTP server to redirect all 80 traffic to SSL/HTTPS
server {
    listen 80;
    server_name HUB.DOMAIN.TLD;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

# HTTPS server to handle JupyterHub
server {
    listen 443;
    ssl on;

    server_name HUB.DOMAIN.TLD;

    ssl_certificate /etc/letsencrypt/live/HUB.DOMAIN.TLD/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/HUB.DOMAIN.TLD/privkey.pem;

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_dhparam /etc/ssl/certs/dhparam.pem;
    ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&#39;;
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    # Managing literal requests to the JupyterHub front end
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Talk about how you had to generate letsencrypt scripts for nginx with &lt;code&gt;certbot&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install python-certbot
sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install python-certbot-nginx 
sudo certbot certonly
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I actually ran into trouble being unable to start nginx with the sites enabled. Kind of a catch-22. Removed letsencrypt files&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo certbot certonly --webroot -w /var/www/example -d example.com -d www.example.com -w /var/www/thing -d thing.is -d m.thing.is
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will obtain a single cert for example.com, www.example.com, thing.is, and m.thing.is; it will place files below /var/www/example to prove control of the first two domains, and under /var/www/thing for the second pair.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I dont quite want that. Let&amp;rsquo;s try the interactive.;&lt;/em&gt;
&lt;code&gt;sudo certbot certonly&lt;/code&gt;
Hit 1, enter website names (consistentbayes.com, www.consistentbayes.com),&lt;/p&gt;

&lt;p&gt;Then do the same again for the hub.consistentbayes.com&lt;/p&gt;

&lt;p&gt;And we&amp;rsquo;re golden. The files have been placed where nginx is expecting them to be. (e.g. &lt;code&gt;/etc/letsencrypt/live/hub.consistentbayes.com/fullchain.pem&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;And also you will need to issue the following command once.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl dhparam -out /etc/ssl/certs/dhparam.pem 4096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then go ahead and make the &lt;code&gt;Dockerfile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Designed to be run as
#
# docker run -it -p 8000:8000 jupyterhub/oauthenticator

FROM jupyterhub/jupyterhub

MAINTAINER Project Jupyter &amp;lt;ipython-dev@scipy.org&amp;gt;

# Install oauthenticator from git
RUN python3 -m pip install oauthenticator
RUN python3 -m pip install notebook&amp;gt;=4.0
# Create oauthenticator directory and put necessary files in it
RUN mkdir /srv/oauthenticator
WORKDIR /srv/oauthenticator
ENV OAUTHENTICATOR_DIR /srv/oauthenticator
ADD jupyterhub_config.py jupyterhub_config.py
ADD addusers.sh /srv/oauthenticator/addusers.sh
ADD userlist /srv/oauthenticator/userlist
ADD ssl /srv/oauthenticator/ssl
RUN chmod 700 /srv/oauthenticator

RUN [&amp;quot;sh&amp;quot;, &amp;quot;/srv/oauthenticator/addusers.sh&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then this bash script &lt;code&gt;addusers.sh&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh

IFS=&amp;quot;
&amp;quot;
for line in `cat userlist`; do
  test -z &amp;quot;$line&amp;quot; &amp;amp;&amp;amp; continue
  user=`echo $line | cut -f 1 -d&#39; &#39;`
  echo &amp;quot;adding user $user&amp;quot;
  useradd -m -s /bin/bash $user
#  cp -r /srv/ipython/examples /home/$user/examples
  mkdir /home/$user/examples
# may only be necessary since we are copying files from root above.
  chown -R $user /home/$user/examples
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, for now, the simplest version of our &lt;code&gt;jupyterhub_config.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration file for Jupyter Hub

c = get_config()

c.JupyterHub.log_level = 10
from oauthenticator.github import LocalGitHubOAuthenticator
c.JupyterHub.authenticator_class = LocalGitHubOAuthenticator
c.GenericOAuthenticator.login_service = &#39;my service&#39;

c.LocalGitHubOAuthenticator.create_system_users = True

c.Authenticator.whitelist = whitelist = set()
c.JupyterHub.admin_users = admin = set()

import os
import sys

join = os.path.join

here = os.path.dirname(__file__)
root = os.environ.get(&#39;OAUTHENTICATOR_DIR&#39;, here)
sys.path.insert(0, root)

with open(join(root, &#39;userlist&#39;)) as f:
    for line in f:
        if not line:
            continue
        parts = line.split()
        name = parts[0]
        whitelist.add(name)
        if len(parts) &amp;gt; 1 and parts[1] == &#39;admin&#39;:
            admin.add(name)

c.GitHubOAuthenticator.oauth_callback_url = os.environ[&#39;OAUTH_CALLBACK_URL&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;userlist&lt;/code&gt; file with github usernames&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:admin&#34;&gt;&lt;a href=&#34;#fn:admin&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mpilosov admin
mathematicalmichael
eescu 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;ssl&lt;/code&gt; folder with encryption keys in them (which we won&amp;rsquo;t use!)
(We don&amp;rsquo;t use them because we expose Jupyterhub in http, and use the reverse-proxy to handle the security).&lt;/p&gt;

&lt;p&gt;And an &lt;code&gt;env&lt;/code&gt; file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# add your github oauth config to this file,
# and run the container with `docker run -it -p 9000:8000 --env-file=env jupyterhub-oauth`
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
OAUTH_CALLBACK_URL=https://hub.consistentbayes.com/hub/oauth_callback
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which you get when you register the application on Github. (I filled in the third to show you, the first two are secrets!)&lt;/p&gt;

&lt;p&gt;So from here on, we can start tweaking the spawner, volume persistence, do checks on memory limits, etc. Write up detailed instructions. Jupyterhub from docker like this is nice.&lt;/p&gt;

&lt;p&gt;I think we can test directory-mounting right to the linux machine to be honest.&lt;/p&gt;

&lt;p&gt;OMG I RAN THIS AND IT WORKED. I mounted volumes to folders on a per-user basis (since users live inside the container that jupyterhub is in). No write permissions, but they can see files just fine. Cant duplicate.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it -p 8000:8000 -v /home/michael/repos/:/home/mathematicalmichael/examples -v /home/michael/repos:/home/mpilosov/examples --env-file=env --name hubtest jupyterhub-oauth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Problem with relying on user data in the hub is potential updates could cause loss of files. mounting volumes would fix this for sure. But they can&amp;rsquo;t write files in this new directory, so&amp;hellip;&lt;/p&gt;

&lt;p&gt;I think the best storage solution is each student has their own container. &lt;code&gt;hubname-studentname&lt;/code&gt; that a teacher can get into. For workshops, the solution presented as-is works great.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make sure to upgrade pip, no one seems to.&lt;/li&gt;
&lt;li&gt;volume permissions are probably things joe knows about.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;volumes-working&#34;&gt;VOLUMES WORKING!&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;--mount&lt;/code&gt; creates directories if they dont exist, whereas &lt;code&gt;--volume&lt;/code&gt; does not. Good to create up at root one &lt;code&gt;/shared&lt;/code&gt; directory. Additionally we can link them to volumes to host their data instead, managed via docker. Ideally we use a mix of the two.
Adding a volume (even if it doesn&amp;rsquo;t exist) to be managed by docker would be accomplished with -v &lt;code&gt;volume-name:/directory/to/mount&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So we should think about what in our docker-compose we can automatically mount. Additionally (or in replacement), volumes can be handled via the spawner.&lt;/p&gt;

&lt;p&gt;In either set up, we can shut down and restart the container all we want and data persists. We can even re-build the image. Volumes seem to just be symbolic links to directories on your unix machine, anyway, visible via &lt;code&gt;docker inspect volume-name&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d -it -p 8000:8000 --mount source=/home/michael/repos/packages/lyricalart,type=bind,target=/home/mpilosov/examples/shared-folder-mp/,bind-propagation=rshared --mount source=/home/michael/repos/packages/lyricalart,type=bind,target=/home/mathematicalmichael/shared-folder-mm/,bind-propagation=rshared --env-file=env --name hub jupyterhub-oauth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we&amp;rsquo;ve got this figured out&amp;hellip; It would be nice to figure out how to get that &lt;code&gt;docker-compose&lt;/code&gt; up and running, including with the nginx server, all based on a configuration file that takes in the website name, ip of host, etc. so you can get in, git clone, run bash script, edit the ip, and close out knowing it will work.&lt;/p&gt;

&lt;p&gt;To build everything, we did &lt;code&gt;docker build -t jupyterhub-oauth .&lt;/code&gt; in the directory we set up.&lt;/p&gt;

&lt;p&gt;Definitely want to containerize each student. Currently it&amp;rsquo;s possible to get into the directories mounted above as shared by going through Terminal. Can move files in/out&amp;hellip; not good.&lt;/p&gt;

&lt;p&gt;To destroy containers after they close down, simply add &lt;code&gt;.remove = True&lt;/code&gt; to the &lt;code&gt;c.DockerSpawner&lt;/code&gt; attributes.&lt;/p&gt;

&lt;p&gt;[8:59 PM] Pilosov, Michael
oficially did it on hub.consistentbayes.com! holy shit that took forever but I linked up the pieces. Now it spawns up containers per user, with BOTH volumes that persist even as containers change and shared directories accessible by all users, automatically mounted to every user.
One environment file controls everything. the version of jupyterhub, the docker image you want to spawn, etc.
​
[9:04 PM] Pilosov, Michael
that is our ideal set up.. the shared folders can be determined by rules such as group membership (students within class or even, and the environment to spawn can be similarly chosen. This means we can use one hub for every student across every class with total ease. No containers stick around. At all. They just get appropriately mounted to volumes when they are created. the decision to make one hub per class is purely an aesthetic one. the hub can spin up dozens of different configurations depending on what the user needs.
I&amp;rsquo;m going to package this all nice so that I can deploy to a powerful server that I can rent for like &amp;hellip;. a couple hours for testing. Throw a whole bunch of simultaneous use-cases at it.
​
[9:08 PM] Pilosov, Michael
we can even use the admin panel to start/stop servers instead of logging in simultaneously. if each single-user server has a heavy python script to run on startup, we can simulate heavy loads. I played around a little already and saw the containers being created (not restarted, created!) when I &amp;ldquo;started&amp;rdquo; the single-user server and then thrown away when I clicked &amp;ldquo;stop&amp;rdquo; which keeps our physical memory literally AT THE LOWEST possible limit at any given time since stopped containers dont have to sit around.&lt;/p&gt;

&lt;p&gt;So, how?&lt;/p&gt;

&lt;p&gt;I cloned the jupyterhub-deploy-docker repo. (again), and made my fixes&amp;hellip;&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know why the Makefile doesn&amp;rsquo;t handle this, but
&lt;code&gt;echo &amp;quot;POSTGRES_PASSWORD=$( openssl rand -hex 32)&amp;quot; &amp;gt;&amp;gt; secrets/postgres.env&lt;/code&gt; will create a necessary file for &lt;code&gt;make build&lt;/code&gt; to work. And after that works, run &lt;code&gt;make notebook_image&lt;/code&gt; to create the necessary image to be spawned based on the  &lt;code&gt;.env&lt;/code&gt; file in the root directory.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note from 1/8/2019:&lt;/em&gt; Just run &lt;code&gt;make secrets/postgres.env&lt;/code&gt; or whatever other file it needs, and it will create and set permissions. If it doesn&amp;rsquo;t create the file, then simply add it with &lt;code&gt;touch&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I commented out lines 40-49 in the &lt;code&gt;Makefile&lt;/code&gt; since I want to handle certification on my own through the reverse proxy.&lt;/p&gt;

&lt;p&gt;Would be nice to get this working with nginx as well. But all that stuff can be handled from the bash script.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file, I removed references to SSL and set up shared volumes.
It would be great to learn how to sub-class the spawner now and create rules for mounting volumes. A simple restart lets students gain new files.&lt;/p&gt;

&lt;p&gt;I also removed SSL references from &lt;code&gt;Dockerfile.jupyerhub&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/compose/compose-file/&#34; target=&#34;_blank&#34;&gt;Docker-compose guidelines&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Just tested the containerized solution and love it (even though i built small containers). I can log in, add nbextensions as root, and the changes are reflected &lt;em&gt;without touching docker&lt;/em&gt;. No restarting required.&lt;/p&gt;

&lt;p&gt;Can add user accounts as admin through the cPanel. If they don&amp;rsquo;t exist, a home directory or volume is created on their behalf.
I wouldn&amp;rsquo;t suggest sharing directories automatically for the containerized solutions. &lt;em&gt;That part&lt;/em&gt; should be part of a custom spawner (and require hub restart, which can also be done through cpanel since it runs on another port!).&lt;/p&gt;

&lt;p&gt;Admin is powerful! You can start/stop servers at your whim and launch them to poke around on your own. Very cool.&lt;/p&gt;

&lt;p&gt;For a smaller class, auto-mounting some shared directory is a great idea.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-5-2019&#34;&gt;Jan 5, 2019&lt;/h1&gt;

&lt;p&gt;To get a bash script for the set-up, you need to package the reverse-proxy with docker-compose. Let&amp;rsquo;s figure out how to use Traefik. Between these two sources, you should be able to figure it out:
&lt;a href=&#34;https://github.com/defeo/jupyterhub-docker/blob/master/docker-compose.yml&#34; target=&#34;_blank&#34;&gt;https://github.com/defeo/jupyterhub-docker/blob/master/docker-compose.yml&lt;/a&gt;
&lt;a href=&#34;https://github.com/containous/traefik/blob/master/examples/quickstart/docker-compose.yml&#34; target=&#34;_blank&#34;&gt;https://github.com/containous/traefik/blob/master/examples/quickstart/docker-compose.yml&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:admin&#34;&gt;Fun note, it may be possible to accidentally revoke admin privileges from everyone. &lt;em&gt;Test this&lt;/em&gt;. But editing the config file in the container as root should be able to make it work again.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:admin&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Deploying</title>
      <link>https://www.michaelpilosov.com/openscience/walkthrough/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/walkthrough/</guid>
      <description>

&lt;h1 id=&#34;inital-setup&#34;&gt;Inital Setup&lt;/h1&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;I presume the use of &lt;code&gt;vim&lt;/code&gt; in a few of these commands. If you are more comfortable using &lt;code&gt;nano&lt;/code&gt; for editing text, please be sure to make the appropriate substitutions.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;On a brand new server&amp;hellip;
(Change the top line to be your name)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export USER_NAME=mathematicalmichael
sudo apt update -y &amp;amp;&amp;amp; sudo apt upgrade -y
sudo apt install vim htop make -y
useradd $USER_NAME -m -s /bin/bash
passwd $USER_NAME
usermod -aG sudo $USER_NAME
su - $USER_NAME
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now set your password.
We then set privileges and switch to this new user (and new shell, which should appear in color!).&lt;/p&gt;

&lt;h2 id=&#34;configurations&#34;&gt;Configurations&lt;/h2&gt;

&lt;p&gt;Here are some aliases I like to have in my &lt;code&gt;~/.bash_aliases&lt;/code&gt; file:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;vim ~/.bash_aliases&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# show users logged into the hub who have open sessions.
alias dpsu=&#39;docker ps --format &amp;quot;table {{.ID}}\t{{.Names}}\t{{.Status}}\t{{.Ports}}&amp;quot; -f &amp;quot;name=r*user*&amp;quot;&#39;
# both of these show/filter docker processes with prettier formatting. 
alias dps=&#39;docker ps --format &amp;quot;table {{.ID}}\t{{.Names}}\t{{.Status}}\t{{.Ports}}&amp;quot;&#39;

alias ..=&#39;cd ../&#39;                         # Move up 1 directory
alias ...=&#39;cd ../../&#39;                     # Move up 2 directories
alias ....=&#39;cd ../../../&#39;                 # Move up 3 directories
alias clc=&#39;clear&#39;
alias ll=&#39;ls -ltr&#39; ## see list of files in reverse chronological order.
alias la=&#39;ls -A&#39; ## show hidden files (can add a/A to the above too... preference)

# completion from history. VERY USEFUL
alias cic=&#39;set completion-ignore-case On&#39;
alias cico=&#39;set completion-ignore-case Off&#39;
alias rr=&#39;source ~/.bashrc&#39; # refresh environment
alias erc=&#39;vim ~/.bash_aliases&#39; # shortcut to edit my shortcuts.

# don&#39;t put duplicate lines or lines starting with space in the history.
# See bash(1) for more options
HISTCONTROL=ignoreboth

# append to the history file, don&#39;t overwrite it
shopt -s histappend
HISTSIZE=10000
HISTFILESIZE=5000
# the following bind up/down to history search
bind &#39;&amp;quot;\e[A&amp;quot;: history-search-backward&#39;
bind &#39;&amp;quot;\e[B&amp;quot;: history-search-forward&#39;
if ! shopt -oq posix; then
  if [ -f /usr/share/bash-completion/bash_completion ]; then
    . /usr/share/bash-completion/bash_completion
  elif [ -f /etc/bash_completion ]; then
    . /etc/bash_completion
  fi
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then run &lt;code&gt;source ~/.bashrc&lt;/code&gt; and you&amp;rsquo;ll have a nice environment.&lt;/p&gt;

&lt;h2 id=&#34;docker-install&#34;&gt;Docker Install&lt;/h2&gt;

&lt;p&gt;If you already had an account with &lt;code&gt;sudo&lt;/code&gt; privileges, then you can start from here assuming you are logged in as such. The code that follows installs Docker, and runs a little test by checking the version to make sure everything worked.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export DOCKER_COMPOSE_VERSION=1.23.2
sudo apt install apt-transport-https ca-certificates curl software-properties-common
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(You will be prompted for your password)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&amp;quot;
sudo apt update
apt-cache policy docker-ce
sudo apt install docker-ce -y
docker --version 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Success?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo usermod -aG docker root
sudo usermod -aG docker ${USER}
sudo curl -L https://github.com/docker/compose/releases/download/$DOCKER_COMPOSE_VERSION/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
docker-compose --version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Success?&lt;/p&gt;

&lt;h2 id=&#34;ssh-keys&#34;&gt;SSH Keys&lt;/h2&gt;

&lt;p&gt;Now is a good time to reboot the machine since we just updated and installed a bunch of things. Before we do that, let us make sure we can &lt;code&gt;ssh&lt;/code&gt; in with either of the usernames now.
Hit enter at the prompt.
&lt;em&gt;YOUR COMPUTER WILL REBOOT AFTER&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh-keygen 
sudo cat /root/.ssh/authorized_keys &amp;gt; ~/.ssh/authorized_keys
reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Your computer/server might take a minute or two to reboot.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;After restarting &lt;code&gt;ssh&lt;/code&gt; in as &lt;code&gt;your-name@your-website.com&lt;/code&gt;.
We will take care of the proxy and security set up first (in order to complete the instructions that only need to be performed initially).&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;

&lt;p&gt;Here is how you do it without a container (ideally we could containerize this whole aspect as well into our &lt;code&gt;docker-compose.yml&lt;/code&gt; file, but that is not yet the case). Run all this first.&lt;/p&gt;

&lt;h2 id=&#34;encryption&#34;&gt;Encryption&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install certbot 
sudo certbot certonly
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Follow prompts, enter info for your site.
This creates a public/private key pair with a certificate authority so that browsers can trust the connection is valid.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you are behind a private network (&lt;code&gt;.pvt&lt;/code&gt; or any other non-public domain), then you must acquire this certificate and key from another (presumably the school&amp;rsquo;s) certificate authority. Make sure the paths are set properly in the configuration to reflect where you placed these keys. Furthermore, you may have to comment out the &lt;code&gt;ssl-ciphers&lt;/code&gt; line (we had to at CU Denver to make it work, but this isn&amp;rsquo;t required on public domains).&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The keys generated will by default be in &lt;code&gt;/etc/ssl/live/example.com/&lt;/code&gt;, which you will see reflected in the example configuration below (set for &lt;code&gt;example.com&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Then run the following,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo openssl dhparam -out /etc/ssl/certs/dhparam.pem 4096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This creates a long encryption key that we will pass to nginx (our proxy) in the next step for additional security.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt-get update
sudo apt install nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nginx-config&#34;&gt;Nginx Config&lt;/h3&gt;

&lt;p&gt;To secure our connection, we will create the following file in &lt;code&gt;/etc/nginx/sites-enabled/&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;You may need to remove &lt;code&gt;default.conf&lt;/code&gt;, or edit it directly to match the following instead.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you choose to edit &lt;code&gt;default.conf&lt;/code&gt;, make sure to add the following line to override the default nginx settings, which will prevent you from saving notebooks greater than 1MB in size: &lt;code&gt;client_max_body_size 20m;&lt;/code&gt; (see example below).&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Run &lt;code&gt;sudo vim /etc/nginx/sites-enabled/hub.conf&lt;/code&gt; and edit the file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# top-level http config for websocket headers
# If Upgrade is defined, Connection = upgrade
# If Upgrade is empty, Connection = close
map $http_upgrade $connection_upgrade {
    default upgrade;
    &#39;&#39;      close;
}

# HTTP server to redirect all 80 traffic to SSL/HTTPS
server {
    listen 80;
    server_name example.com;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

# HTTPS server to handle JupyterHub
server {
    listen 443;
    ssl on;

    server_name example.com;
    
     ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
     ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;

    # memory limits need to be upped for notebooks. default of 1mb is insufficient. 
    client_max_body_size 20m;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_dhparam /etc/ssl/certs/dhparam.pem;
    ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:E$
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    # Managing literal requests to the JupyterHub front end
    location /math {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }


    location /math8660 {
        proxy_pass http://127.0.0.1:8002;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That last section starting with &lt;code&gt;location&lt;/code&gt; is what we&amp;rsquo;ll be tweaking if we want to host this at &lt;code&gt;hub.mathfight.club&lt;/code&gt; or &lt;code&gt;mathfight.club/hub/&lt;/code&gt; or whatever we want. (Although in the case of a directory &lt;code&gt;/suffix/&lt;/code&gt; format, we will have to make sure the line from the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; that we commented out above matches this configuration file.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;The assumption (by default) is that the &lt;code&gt;$HUB_NAME&lt;/code&gt; is used as the suffix. &lt;code&gt;example.com/math/&lt;/code&gt; is the default &lt;code&gt;location&lt;/code&gt; we will have to set. The idea here is that we can set up multiple hubs simply by changing the &lt;code&gt;.env&lt;/code&gt; file to choose a new name and port number.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;As long as we point to the correct port, nginx (our proxy) will handle the rest. The &lt;code&gt;/&lt;/code&gt; refers to the fact that we want the hub to be hosted at &lt;code&gt;mathfight.club&lt;/code&gt; (with nothing appended/prepended).&lt;/p&gt;

&lt;p&gt;If you want some kind of homepage instead of a Hub login, you can configure that to be the case with the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;location / {
    root /var/www/public_html;
    .
    .
    .
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart nginx for changes to take effect:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service nginx restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can now proceed to adding a hub in the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/hubsetup&#34;&gt;Hub Setup&lt;/a&gt; documentation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Remote Connection</title>
      <link>https://www.michaelpilosov.com/openscience/remote/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/remote/</guid>
      <description>

&lt;p&gt;As previously mentioned, the Jupyter Notebook runs in the client (browser) and connects to a server (either running locally or remotely) to perform necessary calculations in a given language.&lt;/p&gt;

&lt;p&gt;The kernels provide the means for establishing this communication, and are effectively what &lt;code&gt;jupyter&lt;/code&gt; (the program) is set up to manage.&lt;/p&gt;

&lt;p&gt;Here, we demonstrate why this approach is so valuable.&lt;/p&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;Assuming you followed the instructions in &lt;a href=&#34;https://www.michaelpilosov.com/openscience/anaconda&#34;&gt;Installing Anaconda&lt;/a&gt; on your local machine, you&amp;rsquo;ll notice that you establish a connection to the server (running in your Terminal session, likely outputting information with green-highlighted time-stamps) through the &amp;ldquo;address&amp;rdquo; &lt;code&gt;localhost&lt;/code&gt;, which references the fact that you are running this server locally.&lt;/p&gt;

&lt;p&gt;However, this means that you can follow those instructions on any server, and with some additional commands (which we will review here), have the ability to connect to your Jupyter session from anywhere!&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:remote&#34;&gt;&lt;a href=&#34;#fn:remote&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;There are a few situations you might find yourself in, and we attempt to address several common ones here.
If there is a scenario that is not covered here that you would like us to write about, please &lt;a href=&#34;https://www.michaelpilosov.com/#contact&#34;&gt;contact us&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;server-on-campus&#34;&gt;Server on Campus&lt;/h1&gt;

&lt;h1 id=&#34;rented-server&#34;&gt;Rented Server&lt;/h1&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:remote&#34;&gt;Provided the machine running Jupyter is one that is publicly accessible. More on that later.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:remote&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Demonstration with Jupyter Lab</title>
      <link>https://www.michaelpilosov.com/openscience/demo/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/demo/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s first get a feel for the possibilities, and &lt;strong&gt;see&lt;/strong&gt; what is possible by checking out some existing websites, organizations, and repositories.
The idea of removing installation complexities, platform dependencies, etc. from your end-users is beautifully demonstrated by some of the recent advancements made over at &lt;a href=&#34;https://jupyter.org&#34; target=&#34;_blank&#34;&gt;Project Jupyter&lt;/a&gt;, all visible on &lt;a href=&#34;https://github.com/jupyter/&#34; target=&#34;_blank&#34;&gt;their Github repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My favorite example that demonstrates how slick this new approach to setting up programming environmnents is the repository demonstration with &lt;a href=&#34;https://github.com/binder-examples/jupyterlab&#34; target=&#34;_blank&#34;&gt;JupyterLab + Binder&lt;/a&gt; from the &lt;code&gt;binder-examples&lt;/code&gt; repository collection.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It even has an interactive map!!!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Head on over there, click on the little badge that reads &amp;ldquo;launch | binder,&amp;rdquo; and it will automatically open up a notebook for you.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:timeout&#34;&gt;&lt;a href=&#34;#fn:timeout&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
Have a look around, run code, do whatever you like.&lt;/p&gt;

&lt;p&gt;To then see how easy adding functionality is, run the following in a new code-cell in the notebook that opens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!jupyter labextension install @jupyter-widgets/jupyterlab-manager 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exclamation point tells the notebook to run the command using &lt;code&gt;bash.&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:bash&#34;&gt;&lt;a href=&#34;#fn:bash&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
Since widgets are already pre-packaged, all we have to do to enable them is to tell JupyterLab to get the necessary Javascript resources to show them to you in your client (web-browser).
A bunch of dialogue should show up, and then once it finishes, replace the code you just ran with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import ipywidgets as wd
wd.FloatSlider()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and you should see a slider pop up.&lt;/p&gt;

&lt;p&gt;To avoid this step and ensure that the widget functionality is ready-to-go, one can fork the &lt;a href=&#34;https://github.com/binder-examples/jupyterlab&#34; target=&#34;_blank&#34;&gt;repository&lt;/a&gt;, and edit the file &lt;code&gt;binder/postBuild&lt;/code&gt;, which runs after the initial repository is built (using &lt;a href=&#34;https://github.com/jupyter/repo2docker&#34; target=&#34;_blank&#34;&gt;repo2docker&lt;/a&gt; on the backend) but before the client displays the interface.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:timeout&#34;&gt;&lt;em&gt;Be warned&lt;/em&gt;: After a few minutes of inactivity, the &lt;a href=&#34;https://mybinder.org&#34; target=&#34;_blank&#34;&gt;mybinder.org&lt;/a&gt; service that is hosting the docker container which serves this web application will time-out. This means that it will assume you are done with it and clean up the resources it created for you. Say goodbye to whatever you were working on.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:timeout&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:bash&#34;&gt;Alternatively, you could open a new Terminal instance in JupyterLab and run the same code (without the exclamation mark).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:bash&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
