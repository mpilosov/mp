<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Michael Pilosov | Academic Website on Michael Pilosov | Academic Website</title>
    <link>https://www.michaelpilosov.com/</link>
    <description>Recent content in Michael Pilosov | Academic Website on Michael Pilosov | Academic Website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Michael Pilosov</copyright>
    <lastBuildDate>Mon, 01 Jan 2018 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Overview</title>
      <link>https://www.michaelpilosov.com/wid/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resources</title>
      <link>https://www.michaelpilosov.com/wid/resources/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 -0600</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/resources/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent Galleries</title>
      <link>https://www.michaelpilosov.com/wid/posts/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 -0600</pubDate>
      
      <guid>https://www.michaelpilosov.com/wid/posts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jupyterhub Configuration</title>
      <link>https://www.michaelpilosov.com/devlog/jupyterhub/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/jupyterhub/</guid>
      <description>

&lt;h1 id=&#34;jan-1-2019&#34;&gt;Jan 1, 2019&lt;/h1&gt;

&lt;h2 id=&#34;status-report&#34;&gt;Status Report&lt;/h2&gt;

&lt;p&gt;Okay so where are we at?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Spawner&lt;/code&gt; needs to be sussed out. Right now I really like DockerSpawner, and it seems to persist storage.

&lt;ul&gt;
&lt;li&gt;Each student gets a user account but it&amp;rsquo;s only used for authenetication right now. Can&amp;rsquo;t figure out volume-mapping.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;With &lt;code&gt;dockerspawner.DockerSpawner&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each time someone is logged in, a container is either loaded up or built from &lt;code&gt;jupyterlab_img&lt;/code&gt; container. These are very flexible, many stacks available.&lt;/li&gt;
&lt;li&gt;In this set-up, each student gets a container, which is a full-fledged linux machine. Since Docker is managing these alongside Dockerhub in the network, communication between containers is not possible right now. &lt;em&gt;should be&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;One hour of inactivity results in shutdown of container thanks to a python script from jupyter.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What we want: &lt;code&gt;dockerspawner.SystemUserSpawner&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;with maps to home directories that exist on the &lt;code&gt;jupyterhub&lt;/code&gt; container.&lt;/li&gt;
&lt;li&gt;this way a teacher opens the docker container with the &amp;ldquo;hub&amp;rdquo; and all the students are there.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What we have now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;each student has a container with their name on it. each is its own linux machine&lt;/li&gt;
&lt;li&gt;to get into their linux machines, run &lt;code&gt;docker exec -ti jupyter-{surname} /bin/bash&lt;/code&gt;, do your thing, &lt;code&gt;Ctrl-D&lt;/code&gt; to exit.&lt;/li&gt;
&lt;li&gt;The script that gets installed in the hub container stops idle single-user servers (&lt;em&gt;I think this means it shuts down the containers that are inactive&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;The containers are spun up based on a jupyterlab image.

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;What happens when we update this? Perhaps to include files for every student?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternatively, you have all of them learn to manage push/pull from a class repository&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;It appears that to do this, we &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner/issues/172&#34; target=&#34;_blank&#34;&gt;sub-class the Spawner&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;    from dockerspawner import DockerSpawner
    class MyDockerSpawner(DockerSpawner):
        team_map = {
            &#39;user1&#39;: &#39;team1&#39;,
            &#39;user2&#39;: &#39;team1&#39;,
            &#39;user3&#39;: &#39;team2&#39;,
        }

        def start(self):
            team = self.team_map[self.user.name]
            # add team volume to volumes
            self.volumes[&#39;jupyterhub-team-{}&#39;.format(team)] = {
                &#39;bind&#39;: &#39;/home/shared/{}&#39;.format(team),
                &#39;mode&#39;: &#39;rw&#39;,  # or ro for read-only
            }

    c.JupyterHub.spawner_class = MyDockerSpawner
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;new-server&#34;&gt;New Server&lt;/h2&gt;

&lt;p&gt;As root:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot;
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce

sudo groupadd docker
sudo usermod -aG docker $USER
# also add any users you want to be running docker. 
# I added `michael` on my machine. will have to log out/in to refresh group membership. 

sudo apt-get install -y docker-compose
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As user &lt;code&gt;michael&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd repos/
git clone git clone https://github.com/mathematicalmichael/hubsetup.git
cd hubsetup/

# make sure you clean up images/volumes/containers. I didn&#39;t have much there from before, did have hello-world.

docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This came up, may be a problem?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;WARNING: The COMPOSE_PROJECT_NAME variable is not set. Defaulting to a blank string.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But it kept going&amp;hellip;&lt;/p&gt;

&lt;p&gt;but then.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERROR: Service &#39;jupyterlab&#39; failed to build: failed to register layer: Error processing tar file(exit status 1): write /opt/conda/lib/python3.6/site-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so: no space left on device
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So I went ahead and deleted a couple GB of space by removing unused conda environments and Lucas&amp;rsquo; user account.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose up 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fairly sure this will fail because of a mis-specified IP address.
Should also enable security since now I have them on this server.&lt;/p&gt;

&lt;p&gt;the SSL is messing with me since I already have it set up on the server.&lt;/p&gt;

&lt;p&gt;trying to launch jupyterhub with dockerspawner with jupyterhub local install.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export DOCKER_JUPYTER_IMAGE=jupyter/datascience-notebook:7254cdcfa22b&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Okay well the hub worked and spawner did not.&lt;/p&gt;

&lt;p&gt;I dove into making a custom spawner (may be necessary?), but it was a rabbit hole.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note from 1/8/19:&lt;/em&gt; The image needs to be available on the machine. It is separate from the hub, so just make sure the names line up correctly by checking &lt;code&gt;docker images&lt;/code&gt; against the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-2-3-2019&#34;&gt;Jan 2-3, 2019&lt;/h1&gt;

&lt;p&gt;See &lt;a href=&#34;https://www.michaelpilosov.com/devlog/proxy&#34;&gt;proxy&lt;/a&gt; page.&lt;/p&gt;

&lt;h2 id=&#34;useful-reading&#34;&gt;Useful Reading&lt;/h2&gt;

&lt;p&gt;Here is something interesting for version-controlling notebooks.
&lt;a href=&#34;https://github.com/mwouts/jupytext&#34; target=&#34;_blank&#34;&gt;https://github.com/mwouts/jupytext&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is an introduction to the notebook format.
&lt;a href=&#34;https://nbformat.readthedocs.io/en/latest/format_description.html&#34; target=&#34;_blank&#34;&gt;https://nbformat.readthedocs.io/en/latest/format_description.html&lt;/a&gt;
&lt;em&gt;TODO:&lt;/em&gt; You should turn this into a write-up.&lt;/p&gt;

&lt;p&gt;The basic examples in here are actually a great demo of publishing LaTeX documents right from Jupyter.
&lt;a href=&#34;https://github.com/jupyter/nbconvert-examples&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/nbconvert-examples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nice article
&lt;a href=&#34;https://blog.dominodatalab.com/data-science-vs-engineering-tension-points/&#34; target=&#34;_blank&#34;&gt;https://blog.dominodatalab.com/data-science-vs-engineering-tension-points/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might be how to set up binderhub on your own &amp;ndash; minikube
&lt;a href=&#34;https://github.com/jupyterhub/binderhub/blob/master/CONTRIBUTING.md&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/binderhub/blob/master/CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Other Projects for sharing results:
&lt;a href=&#34;https://github.com/minrk/thebelab&#34; target=&#34;_blank&#34;&gt;https://github.com/minrk/thebelab&lt;/a&gt;
&lt;a href=&#34;https://github.com/QuantStack/voila&#34; target=&#34;_blank&#34;&gt;https://github.com/QuantStack/voila&lt;/a&gt;
Write about them in a new section summarizing sharing results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jupyter/dashboards&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/dashboards&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Adding extra libraries to the jupyter-stacks image
&lt;a href=&#34;https://github.com/binder-examples/jupyter-stacks&#34; target=&#34;_blank&#34;&gt;https://github.com/binder-examples/jupyter-stacks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Allowing students to get latest files without knowing git
&lt;a href=&#34;https://github.com/jupyterhub/nbgitpuller&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/nbgitpuller&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When a link is clicked, we try to make opinionated intelligent guesses on how to do a merge automatically, without making the user do a conflict resolution. nbgitpuller is designed to be used by folks who do not know that git is being used underneath, and are only pulling content one way from a source and modifying it - not pushing it back. So we have made the following opinionated decisions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If content has changed in both places, prefer local changes over remote changes.&lt;/li&gt;
&lt;li&gt;If a file was deleted locally but present in the remote, remote file is restored to local repository. This allows users to get a &amp;lsquo;fresh copy&amp;rsquo; of a file by just deleting the file locally &amp;amp; clicking the link again.&lt;/li&gt;
&lt;li&gt;If a file exists locally but is untracked by git (maybe someone uploaded it manually), then rename the file, and pull in remote copy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hippylib-Hub, example to follow.
&lt;a href=&#34;https://github.com/g2s3-2018/hippylib-hub&#34; target=&#34;_blank&#34;&gt;https://github.com/g2s3-2018/hippylib-hub&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;dockerspawner&#34;&gt;Dockerspawner&lt;/h2&gt;

&lt;p&gt;Want:
    - Dockerspawner is nice (can restart hub without issues).
    - Although, restarting if all-in-one isn&amp;rsquo;t that bad, either. Temporary inconvenience.&lt;/p&gt;

&lt;p&gt;Add this to installations!!! It&amp;rsquo;s amazing.
&lt;a href=&#34;https://github.com/yuvipanda/nbresuse&#34; target=&#34;_blank&#34;&gt;https://github.com/yuvipanda/nbresuse&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This might be a good thing to test on our server.
&lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/&#34; target=&#34;_blank&#34;&gt;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;USEFUL: in Vim:
&lt;code&gt;r:! openssl rand -hex 32&lt;/code&gt; will paste a token into a file like &lt;code&gt;config.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;proxy:
    secretToken: xxxx
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;file-storage&#34;&gt;File Storage&lt;/h2&gt;

&lt;p&gt;Wow I can&amp;rsquo;t believe this exists.
&lt;a href=&#34;https://www.katacoda.com/&#34; target=&#34;_blank&#34;&gt;https://www.katacoda.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a good file-storage solution
&lt;a href=&#34;https://www.youtube.com/watch?v=hqE5c5pyfrk&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/watch?v=hqE5c5pyfrk&lt;/a&gt;
&lt;a href=&#34;https://storageos.com/developers/&#34; target=&#34;_blank&#34;&gt;https://storageos.com/developers/&lt;/a&gt;
another alternative, which appears to be a bit more complicated to set-up (though helm-chart should be available by now), but is open-source and from redhat: &lt;a href=&#34;https://www.youtube.com/watch?v=Fgpr2lMnBVY&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/watch?v=Fgpr2lMnBVY&lt;/a&gt; [16:30]&lt;/p&gt;

&lt;h2 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;

&lt;p&gt;Kubernetes 101 introduction
&lt;a href=&#34;https://medium.com/google-cloud/kubernetes-101-pods-nodes-containers-and-clusters-c1509e409e16&#34; target=&#34;_blank&#34;&gt;https://medium.com/google-cloud/kubernetes-101-pods-nodes-containers-and-clusters-c1509e409e16&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The monitoring of my memory usage led me to discover that repeated execution of plotting cells led to memory usage going through the roof. The solution was to add this cell-magic to the top of any plotting-cell: &lt;code&gt;%reset -f out&lt;/code&gt;. What this does is purge the output of the cell&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-4-5-2019&#34;&gt;Jan 4-5, 2019&lt;/h1&gt;

&lt;p&gt;Tried and failed to get Traefik working. See &lt;a href=&#34;https://www.michaelpilosov.com/devlog/proxy&#34;&gt;proxy&lt;/a&gt; notes. Took some time to relax.&lt;/p&gt;

&lt;p&gt;Note&lt;/p&gt;

&lt;p&gt;If you base a Dockerfile on this image:&lt;/p&gt;

&lt;p&gt;FROM juptyerhub/jupyterhub-onbuild:0.6
&amp;hellip;
then your jupyterhub_config.py adjacent to your Dockerfile will be loaded into the image and used by JupyterHub.&lt;/p&gt;

&lt;h2 id=&#34;file-permissions&#34;&gt;File permissions&lt;/h2&gt;

&lt;p&gt;Correct permissions for exposed shared directories require
&lt;code&gt;chmod -R 777&lt;/code&gt; for the folder at the top&lt;/p&gt;

&lt;p&gt;What this means:&lt;/p&gt;

&lt;p&gt;Permissions:
1 – can execute
2 – can write
4 – can read&lt;/p&gt;

&lt;p&gt;The octal number is the sum of those free permissions, i.e.
3 (1+2) – can execute and write
6 (2+4) – can write and read&lt;/p&gt;

&lt;p&gt;Position of the digit in value:
1 – what owner can
2 – what users in the file group(class) can
3 – what users &lt;em&gt;not&lt;/em&gt; in the file group(class) can&lt;/p&gt;

&lt;p&gt;So the third is what we care about since no we don&amp;rsquo;t want to create users on the machine running docker.&lt;/p&gt;

&lt;h2 id=&#34;database&#34;&gt;Database&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyterhub.readthedocs.io/en/stable/reference/database.html&#34; target=&#34;_blank&#34;&gt;https://jupyterhub.readthedocs.io/en/stable/reference/database.html&lt;/a&gt;
It comes pre-packaged with one, but it is recommended to use something else for production, which we will do!&lt;/p&gt;

&lt;p&gt;Hash authentication&amp;hellip; Very nice
&lt;a href=&#34;https://github.com/thedataincubator/jupyterhub-hashauthenticator&#34; target=&#34;_blank&#34;&gt;https://github.com/thedataincubator/jupyterhub-hashauthenticator&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can generate a good &lt;code&gt;secret key&lt;/code&gt; with &lt;code&gt;openssl rand -hex 32&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.authenticator_class = &#39;hashauthenticator.HashAuthenticator&#39;
c.HashAuthenticator.secret_key = &#39;my secret key&#39;  # Defaults to &#39;&#39;
c.HashAuthenticator.password_length = 10          # Defaults to 6
c.HashAuthenticator.show_logins = True            # Optional, defaults to False
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the &lt;code&gt;show_logins&lt;/code&gt; option is set to &lt;code&gt;True&lt;/code&gt;, a CSV file containing login names and passwords will be served (to admins only) at &lt;code&gt;/hub/login_list&lt;/code&gt;. &lt;em&gt;Do we want this?&lt;/em&gt; Maybe for analytics? If possible.&lt;/p&gt;

&lt;p&gt;To figure out my password, I used
&lt;code&gt;hashauthpw --length 10 mathematicalmichael [secret key]&lt;/code&gt; on any computer that has run &lt;code&gt;pip install jupyterhub-hashauthenticator&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;multiple-spawners&#34;&gt;Multiple Spawners&lt;/h2&gt;

&lt;p&gt;multiple spawners! definitely my favorite way to go. Says this will allow them to choose upon login.
If so&amp;hellip; amazing.&lt;/p&gt;

&lt;p&gt;[multiple spawners issue on github][&lt;a href=&#34;https://github.com/jupyterhub/dockerspawner/issues/236]:&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/dockerspawner/issues/236]:&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from dockerspawner import SystemUserSpawner

class MultiDockerImageSpawner(SystemUserSpawner):
    images = {
        &#39;SciPy&#39;: &#39;jupyter/scipy-notebook:0f73f7488fa0&#39;,
        &#39;Tensorflow&#39;: &#39;jupyter/tensorflow-notebook:59904dd7776a&#39;,
        &#39;R&#39;: &#39;jupyter/r-notebook:59904dd7776a&#39;,
    }
    def _options_form_default(self):
        outval = &amp;quot;&amp;quot;&amp;quot;
        &amp;lt;label for=&amp;quot;image&amp;quot;&amp;gt;Docker Image&amp;lt;/label&amp;gt;
        &amp;lt;select name=&amp;quot;image&amp;quot;&amp;gt;
        &amp;quot;&amp;quot;&amp;quot;
        for name, image in self.images.items():
            outval += &amp;quot;&amp;lt;option value=\&amp;quot;%s\&amp;quot;&amp;gt;%s (%s)&amp;lt;/option&amp;gt;&amp;quot; % (name, name, image)

        outval += &amp;quot;&amp;quot;&amp;quot;
        &amp;lt;/select&amp;gt;
        &amp;quot;&amp;quot;&amp;quot;
        return outval

    def options_from_form(self, formdata):
        options = {}
        options[&#39;image&#39;] = formdata.get(&#39;image&#39;, [&#39;SciPy&#39;])[0]
        self.image = self.images[options[&#39;image&#39;]]
        return options
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Everything is now up and running! New images can be added with total ease, the hub restart only has minimal disruption.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A note on startup files:&lt;/em&gt;
&amp;gt; IPython startup files, placed in ~/.ipython/profile_default/startup will be executed. These can be Python scripts (.py) or IPython scripts (.ipy with %magic commands). Notebooks aren&amp;rsquo;t supported as startup files, but if it really needs to be a notebook, you can use %run /path/to/notebook.ipynb in a .ipy startup file.&lt;/p&gt;

&lt;p&gt;This means that for testing, we can create an image with a file that gets run at startup, set it as the temporary default, and launch servers.&lt;/p&gt;

&lt;p&gt;I GOT RSTUDIO WORKING.
Okay, so just, build any image you want, and reference it in the spawner.
If you can execute the following and see the same output, you&amp;rsquo;ll have something working properly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mpilosov@math-ws-204:~/Packages/deploy/singleuser$ docker run --rm -ti rstudio_test
Executing the command: jupyter notebook
[I 22:39:24.130 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret
[I 22:39:24.745 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.7/site-packages/jupyterlab
[I 22:39:24.745 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab
[I 22:39:24.748 NotebookApp] Serving notebooks from local directory: /home/jovyan
[I 22:39:24.748 NotebookApp] The Jupyter Notebook is running at:
[I 22:39:24.748 NotebookApp] http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
[I 22:39:24.749 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 22:39:24.749 NotebookApp]

    Copy/paste this URL into your browser when you connect for the first time,
    to login with a token:
        http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
^C[I 22:39:36.445 NotebookApp] interrupted
Serving notebooks from local directory: /home/jovyan
0 active kernels
The Jupyter Notebook is running at:
http://(620acce394ce or 127.0.0.1):8888/?token=cbf208a110db20a3fce4814d5cf1bf2e41aca5e4a165c69d
Shutdown this notebook server (y/[n])? ^C[C 22:39:37.364 NotebookApp] received signal 2, stopping
[I 22:39:37.366 NotebookApp] Shutting down 0 kernels
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-6-7-2019&#34;&gt;Jan 6-7, 2019&lt;/h1&gt;

&lt;h2 id=&#34;math-hub&#34;&gt;Math-hub&lt;/h2&gt;

&lt;p&gt;everything is up and running on math-hub,
100 notebooks idle take up 8gb of ram.&lt;/p&gt;

&lt;p&gt;I managed to mount volumes easily, but if you create a new volume with docker, use &lt;code&gt;docker inspect&lt;/code&gt; to find out where it is and change the permissions.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pilosovm@math-hub:~/repos/deploy$ docker inspect rw_shared_volume
[
    {
        &amp;quot;CreatedAt&amp;quot;: &amp;quot;2019-01-04T17:57:04-07:00&amp;quot;,
        &amp;quot;Driver&amp;quot;: &amp;quot;local&amp;quot;,
        &amp;quot;Labels&amp;quot;: {},
        &amp;quot;Mountpoint&amp;quot;: &amp;quot;/var/lib/docker/volumes/rw_shared_volume/_data&amp;quot;,
        &amp;quot;Name&amp;quot;: &amp;quot;rw_shared_volume&amp;quot;,
        &amp;quot;Options&amp;quot;: {},
        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;
    }
]
pilosovm@math-hub:~/repos/deploy$ sudo chmod 777 /var/lib/docker/volumes/rw_shared_volume/_data
[sudo] password for pilosovm:
pilosovm@math-hub:~/repos/deploy$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;startup scripts: bootstrap scripts &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/tree/master/examples/bootstrap-script&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/jupyterhub/tree/master/examples/bootstrap-script&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-8-2019&#34;&gt;Jan 8, 2019&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.paraview.org/web/&#34; target=&#34;_blank&#34;&gt;https://www.paraview.org/web/&lt;/a&gt;
Paraview in-browser is now a thing&amp;hellip; Can we somehow create a container that includes the ability to launch this application?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html&#34; target=&#34;_blank&#34;&gt;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/recipes.html&lt;/a&gt;
Jupyter Docker-Stacks&lt;/p&gt;

&lt;h2 id=&#34;python-2&#34;&gt;Python 2&lt;/h2&gt;

&lt;p&gt;Adding Python 2:
dd a Python 2.x environment
Python 2.x was removed from all images on August 10th, 2017, starting in tag cc9feab481f7. You can add a Python 2.x environment by defining your own Dockerfile inheriting from one of the images like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Choose your desired base image
FROM jupyter/scipy-notebook:latest

# Create a Python 2.x environment using conda including at least the ipython kernel
# and the kernda utility. Add any additional packages you want available for use
# in a Python 2 notebook to the first line here (e.g., pandas, matplotlib, etc.)
RUN conda create --quiet --yes -p $CONDA_DIR/envs/python2 python=2.7 ipython ipykernel kernda numpy pandas matplotlib ipywidgets yaml &amp;amp;&amp;amp; \
    conda clean -tipsy

USER root

# Create a global kernelspec in the image and modify it so that it properly activates
# the python2 conda environment.
RUN $CONDA_DIR/envs/python2/bin/python -m ipykernel install &amp;amp;&amp;amp; \
$CONDA_DIR/envs/python2/bin/kernda -o -y /usr/local/share/jupyter/kernels/python2/kernel.json

USER $NB_USER
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mixed-authentication&#34;&gt;Mixed Authentication&lt;/h2&gt;

&lt;p&gt;The main &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/wiki/Authenticators&#34; target=&#34;_blank&#34;&gt;authentication page&lt;/a&gt; on the Jupyterhub wiki is pretty useful but also kind of incomplete.&lt;/p&gt;

&lt;p&gt;Right now I am creating users based on the folders in &lt;code&gt;/home/math&lt;/code&gt;, authenticating with &lt;code&gt;HashAuthenticator&lt;/code&gt;, but &lt;a href=&#34;https://github.com/compmodels/jupyterhub/blob/master/docker_oauth.py&#34; target=&#34;_blank&#34;&gt;this example&lt;/a&gt; demonstrates how to mix Authentication methods.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;TO DO&lt;/em&gt;
Try &lt;a href=&#34;https://github.com/jupyterhub/oauthenticator#google-setup&#34; target=&#34;_blank&#34;&gt;google authentication&lt;/a&gt; on your own website.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Early Exploration with Docker &amp; Kubernetes</title>
      <link>https://www.michaelpilosov.com/devlog/docker/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/docker/</guid>
      <description>

&lt;p&gt;Dec 22, 2018
Today I began to structure and fill in the basic information for the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker&#34;&gt;Open Science/Docker&lt;/a&gt; Documentation.&lt;/p&gt;

&lt;p&gt;12/24/2019 - 01/01/2019&lt;/p&gt;

&lt;p&gt;Today I started by watching a video to be aware of the problems I might face going forward with JupyterHub.
I watched someone from Berkeley describe how they&amp;rsquo;ve scaled to thousands of users across many professors and managed to not grow their IT team while doing so.&lt;/p&gt;

&lt;p&gt;I will start by using this space here to take notes on the following video(s):&lt;/p&gt;

&lt;h2 id=&#34;deploying-jupyter-notebooks-for-students-and-researchers-pydata-2016&#34;&gt;Deploying Jupyter Notebooks for Students and Researchers (PyData 2016)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/gSVvxOchT8Y&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;managing-a-1000-student-jupyterhub-without-losing-your-sanity-jupytercon-2018&#34;&gt;Managing a 1000+ Student JupyterHub without Losing your Sanity (JupyterCon 2018)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/ivswAxysfTk&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Here are the stated goals in the video:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;[7:30] Infrastructure Shouldn&amp;rsquo;t Bottleneck

&lt;ul&gt;
&lt;li&gt;Instructors should be able to install packages as needed&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[8:00] Anyone can Deploy

&lt;ul&gt;
&lt;li&gt;Treat Admins as Equal (grad students, teachers, etc)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[9:00] Automate Workflows

&lt;ul&gt;
&lt;li&gt;Avoid manual processes. No one-off scripts to bootstrap solutions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[9:30] Reduce Human Maintenance

&lt;ul&gt;
&lt;li&gt;Build on top of tools that already exist&lt;/li&gt;
&lt;li&gt;Let academic edit Dockerfile directly on Github, issue pull-request.&lt;/li&gt;
&lt;li&gt;Travis Process builds image, and if successful, requests to merge&lt;/li&gt;
&lt;li&gt;Rather than CLI, hit a couple buttons to set off other Travis Processes to update Helm&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[13:55]: Reproducibility

&lt;ul&gt;
&lt;li&gt;Tag versions, everything.&lt;/li&gt;
&lt;li&gt;The release cycles of the core infrastructure components do not align with each other.&lt;/li&gt;
&lt;li&gt;In pip file, in Dockerfile, all of it.&lt;/li&gt;
&lt;li&gt;Get git hashes for latest commits.&lt;/li&gt;
&lt;li&gt;Tag Docker images with the hashes of the repositories that generated them&lt;/li&gt;
&lt;li&gt;This makes it much easier to re-deploy!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[15:30] Horror Story of Hub failing during Finals week because a Cloud bill was unpaid (grant ran out)

&lt;ul&gt;
&lt;li&gt;All the versioning helped saved them&lt;/li&gt;
&lt;li&gt;Despite coming up on different nodes, the same hub came out of it.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[17:00] Observability

&lt;ul&gt;
&lt;li&gt;Monitoring (container provider may have analytics)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;This may be less of a problem for us if we deploy on our own servers.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Figure out needs of students to figure out how many nodes.&lt;/li&gt;
&lt;li&gt;After observing, they noticed most students used under 1GB, allowing them to double capacity per node. Students that went above were writing runaway processes anyway.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[19:30] Incident Reporting

&lt;ul&gt;
&lt;li&gt;any time something goes down, write a report.&lt;/li&gt;
&lt;li&gt;[Incident Reports at Berkeley][github.com/data-8/infrastructure]&lt;/li&gt;
&lt;li&gt;Improves deployment.&lt;/li&gt;
&lt;li&gt;Event summary, timeline, conclusion, and action items.&lt;/li&gt;
&lt;li&gt;Reports are &amp;ldquo;blameless&amp;rdquo; to encourage transparency with relevant details&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[21:30] Generalization

&lt;ul&gt;
&lt;li&gt;Be a good open-source citizen&lt;/li&gt;
&lt;li&gt;This means digging into problems and reporting bugs&lt;/li&gt;
&lt;li&gt;Not every problem is your fault. Sometimes an upstream thing breaks it, and if you report it, you may save other people time/effort.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t rely on forks and custom patches. Contribute. Think about reproducible deployment scenarios.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[24:30] Contact Information (encouraged)

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;mailto:rylo@berkeley.edu&#34; target=&#34;_blank&#34;&gt;Ryan Lovett&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;mailto:yuvipanda@berkeley.edu&#34; target=&#34;_blank&#34;&gt;Yuvi Panda&lt;/a&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;scaling-jupyterhub-to-many-users-pydata-tel-aviv-2018&#34;&gt;Scaling JupyterHub to many users (PyData Tel-Aviv 2018)&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/QN8T9zdnyLc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;jupyterhub-and-jupyterlab-perfect-together-pydata-2018&#34;&gt;&amp;ldquo;JupyterHub and JupyterLab: Perfect Together (PyData 2018)&amp;rdquo;&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/AXCo39qMn1E&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;h2 id=&#34;jupyterhub-with-kubernetes&#34;&gt;JupyterHub with Kubernetes:&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/uiLUmuecU7I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;log&#34;&gt;Log&lt;/h2&gt;

&lt;p&gt;A lot of solutions exist for using docker to handle the file storage and user authentication.&lt;/p&gt;

&lt;p&gt;Here is the solution that I think will work best for workshops:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://opendreamkit.org/2018/10/17/jupyterhub-docker/&#34; target=&#34;_blank&#34;&gt;Open DreamKit&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[11:37 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;Okay, can&amp;rsquo;t confirm until I try it, but I am reasonably certain that while this set-up is useful in many contexts.
It doesn&amp;rsquo;t address the teacher/student/group collab management that we quite wanted (and that I focused on getting working first and have done already).
​&lt;/p&gt;

&lt;p&gt;[11:39 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;The way the build works here with data management is actually much &amp;ldquo;slimmer&amp;rdquo; in fact, and I think there&amp;rsquo;s a use for it for us for sure&amp;hellip; but I suspect it doesn&amp;rsquo;t allow two users to share data, or a super-user to poke around in files.
​&lt;/p&gt;

&lt;p&gt;[11:41 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;But it would allow for secure authentication for like, a workshop, just using people&amp;rsquo;s github accounts, and data-persistence and management would be more ideal in that sense since you can turn on permanence for each user, destroy it when the workshop is over as superuser (but without ever being able to poke around in their files, which is a nice security feature for the user I suppose&amp;hellip;).&lt;/p&gt;

&lt;p&gt;[11:52 AM] Pilosov, Michael&lt;/p&gt;

&lt;p&gt;In short, what we want instead is for docker to launch up a virtual LINUX machine, where all memory persists within the container.
It&amp;rsquo;s as if you set up a &amp;ldquo;new computer&amp;rdquo; for each class/workshop. Each class gets its own port.
Importantly, this makes &amp;ldquo;management&amp;rdquo; very familiar, identical to what you already know how to do, rather than having to &amp;ldquo;learn docker&amp;rdquo; to manage student&amp;rsquo;s work.
also, updating things can be done this way without re-building images through docker. which is really nice for on-the-fly changes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What&amp;rsquo;s the downside you ask?&lt;/em&gt;
It&amp;rsquo;s definitely less memory efficient, but it&amp;rsquo;s not a problem at all. we&amp;rsquo;re talking like&amp;hellip; cheap laptop levels of storage, nothing major.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;[12:20 AM]
Finished watching the first video and going throught he tutorial above for the most part.
I still think the Linux within each container is the simplest option for someone to manage on their own.
it is definitely the most familiar environment.&lt;/p&gt;

&lt;p&gt;To start, let me &lt;code&gt;ssh&lt;/code&gt; into my workstation and see if I can revive the docker container from the summer workshop. I will log my commands here!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# start the server
docker run -td -p 80:8000 --name=labhub mathematicalmichael/labhub-test

# check that it is up
docker ps

# look for ip under process associated with your machine. look for 
# inet addr: &amp;lt;XXX.XXX.XXX.XXX&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we connect to auraria-anywhere via Cisco AnyConnect and attempt to connect to &lt;XXX.XXX.XXX.XXX&gt;:8000 via our browser.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;This site can&amp;rsquo;t be reached&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Debug mode:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker logs labhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;showed me that&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Creating 3 new users...
Created user0 with password Breckenridge0_g2s3
Created user1 with password Breckenridge1_g2s3
Created user2 with password Breckenridge2_g2s3
*** Running /etc/rc.local...
*** Booting runit daemon...
*** Runit started as PID 66
*** Running jupyterhub --Spawner.cmd=&#39;jupyter-labhub&#39; --no-ssl...
*** jupyterhub --Spawner.cmd=&#39;jupyter-labhub&#39; --no-ssl exited with status 127.
*** Shutting down runit daemon (PID 66)...
*** Killing all processes...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So that tells me I messed up the .Dockerfile.
It might be instructive to just learn from what they did. I don&amp;rsquo;t really need their libraries (which is what I believe was causing the build to fail before).&lt;/p&gt;

&lt;p&gt;** It will definitely be better to start with a fresh Linux image and go from there, since we want to build on top of the newest release anyway, and make sure we understand how its done, keep images/layers light. **&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;https://github.com/g2s3-2018/hippylib-hub&#34; target=&#34;_blank&#34;&gt;MUQ-Hippylib&lt;/a&gt; (see &lt;a href=&#34;https://bitbucket.org/mituq/&#34; target=&#34;_blank&#34;&gt;muq&lt;/a&gt; for more info)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM quay.io/fenicsproject/stable:2017.2.0.r3
MAINTAINER U. Villa

USER root

RUN apt-get update &amp;amp;&amp;amp; \
    apt-get install -yy pwgen npm nodejs-legacy python3-pip libgeos-dev&amp;amp;&amp;amp; \
    npm install -g configurable-http-proxy &amp;amp;&amp;amp; \
    pip3 install jupyterhub==0.8.1 &amp;amp;&amp;amp; \
    pip3 install ipython[notebook]==6.2.1 h5py pandas &amp;amp;&amp;amp; \
    pip install --user https://github.com/matplotlib/basemap/archive/master.zip

RUN apt-get clean &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

#RUN mkdir /etc/certs
#RUN touch /etc/certs/ssl.key
#RUN touch /etc/certs/ssl.crt
#RUN openssl req -x509 -nodes -days 730 -newkey rsa:2048 \
#                 -subj &amp;quot;/C=XY/ST=XYZ/L=XYZ/O=XYZ/CN=example.com&amp;quot; \
#                 -keyout /etc/certs/ssl.key -out /etc/certs/ssl.crt

USER fenics

# Install MUQ
RUN cd /home/fenics &amp;amp;&amp;amp; \
    mkdir Installations; mkdir Installations/MUQ_INSTALL &amp;amp;&amp;amp; \
    git clone --depth 1 https://bitbucket.org/mituq/muq2.git &amp;amp;&amp;amp; \
    cd muq2/; mkdir build; cd build;  \
    cmake -DCMAKE_INSTALL_PREFIX=/home/fenics/Installations/MUQ_INSTALL -DMUQ_USE_PYTHON=ON ../ &amp;amp;&amp;amp; \
    make install

# Install hIPPYlib
RUN cd /home/fenics/Installations &amp;amp;&amp;amp; \
    git clone https://github.com/hippylib/hippylib.git &amp;amp;&amp;amp; \
    chmod -R o+rx hippylib

# Copy the notebooks
RUN cd /home/fenics/Installations &amp;amp;&amp;amp; \
    git clone https://github.com/g2s3-2018/labs.git

COPY python3_config.json /usr/local/share/jupyter/kernels/python3/kernel.json
ENV LD_LIBRARY_PATH /home/fenics/Installations/MUQ_INSTALL/lib:/home/fenics/Installations/MUQ_INSTALL/muq_external/lib
ENV PYTHONPATH /home/fenics/Installations/MUQ_INSTALL/lib:/home/fenics/Installations/hippylib

USER root

COPY jupyterhub_config.py /home/fenics/jupyterhub_config.py
COPY make-users-std-password.sh /etc/my_init.d/make-users-std-password.sh
RUN chmod +x /etc/my_init.d/make-users-std-password.sh
RUN rm /etc/my_init.d/set-home-permissions.sh
COPY update_lab.sh /home/fenics/update_lab.sh
RUN chmod +x /home/fenics/update_lab.sh
RUN mkdir -p /home/fenics/.jupyter
COPY jupyter_notebook_config.py /home/fenics/.jupyter/jupyter_notebook_config.py


ENV NUMBER_OF_USERS 60
WORKDIR /home/fenics/
ENTRYPOINT [&amp;quot;/sbin/my_init&amp;quot;,&amp;quot;--&amp;quot;]
CMD [&amp;quot;jupyterhub&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So it appears that we&amp;rsquo;re starting with a root image from the Fenics Project.
&lt;a href=&#34;https://quay.io/repository/fenicsproject/stable?tag=latest&amp;amp;tab=tags&#34; target=&#34;_blank&#34;&gt;Quay.io&lt;/a&gt; has a summary of security vulnerabilities for each repository tag.&lt;/p&gt;

&lt;p&gt;The one used by Dr. Umberto Villa had 3 High-Risk Vulnerabilities and 151 fixable. More modern ones such as &lt;code&gt;2018.1.0.r3&lt;/code&gt; have only 57 Medium-Risk ones and 25 fixable.&lt;/p&gt;

&lt;p&gt;This is a considerable advantage and thus I believe the correct place to start from. It is also evident that the developers have been working on reducing image sizes, with a clear downward-trend each time a new one comes up.
The latest does also seem to be built on top of the Ubuntu 18.04, which is exactly what we wanted!!!&lt;/p&gt;

&lt;p&gt;Wonderful.&lt;/p&gt;

&lt;p&gt;Okay, but before I go on building my customized version[^builderrors], I want to remember how to get the &lt;code&gt;hippylib-muq&lt;/code&gt; one working. I have the Dockerhub image from &lt;code&gt;mparno/hippylib-muq&lt;/code&gt; and can run it (create an instance) with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -td -p 80:8000 --name=labhub mparno/muq-hippylib
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So this creates an instance that will map to port 80 (default address when you land on an IP, something we should map with sub-domains later on to have &lt;code&gt;classhub.math.ucdenver.edu&lt;/code&gt; rather than ports to memorize).
This &amp;ldquo;instance&amp;rdquo; (container) is now created and the ports mapped, so now we have to start it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker start labhub

# now can go to base IP address and log in! 

# later on... stop it.
docker stop labhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alright, that&amp;rsquo;s fine and well. We have a baseline set of instructions to go off now, and can learn from.
 However, seeing as quite a lot is happening in those instructions, and no SSL security has been established, I would like to perhaps instead start with Dockerfiles from the Jupyter Project. Moreover, these will be newer versions and should come with Lab enabled already since it is finally in a stable release.&lt;/p&gt;

&lt;p&gt;[^builderrors] I remember that some updates to MUQ&amp;hellip; likely because of a lack of pinning to specific releases, caused build errors when I tried to start up my labhub. Though it might have been the initial commands, based on the readout above.&lt;/p&gt;

&lt;p&gt;SO we&amp;rsquo;ll have to do two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Get Hub/Lab up and running with a single user based on the instructions from Project Jupyter.&lt;/li&gt;
&lt;li&gt;Use this on top of the Fenics build to get &lt;code&gt;import dolfin&lt;/code&gt; working inside of the Hub.&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt; The ease of sharing memory for class-uses is actually a BRAND NEW effort from Jupyter (a week old?). &lt;a href=&#34;https://github.com/jupyterhub/hubshare&#34; target=&#34;_blank&#34;&gt;See here&lt;/a&gt;, which should remove the need for the solution we&amp;rsquo;re building, allow for much better and more lightweight scalability.&lt;/p&gt;

&lt;p&gt;I just came across &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner&#34; target=&#34;_blank&#34;&gt;dockerspawner&lt;/a&gt;
which can be enabled with the following in &lt;code&gt;jupyterhub_config.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.spawner_class = &#39;dockerspawner.DockerSpawner&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;More appropriate for the use case we have is &lt;code&gt;SystemUserSpawner&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you want to spawn notebook servers for users that correspond to system users, you can use the SystemUserSpawner instead. Add the following to your jupyterhub_config.py:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c.JupyterHub.spawner_class = &#39;dockerspawner.SystemUserSpawner&#39;&lt;/code&gt;
The SystemUserSpawner will also need to know where the user home directories are on the host. By default, it expects them to be in &lt;code&gt;/home/&amp;lt;username&amp;gt;&lt;/code&gt;, but if you want to change this, you&amp;rsquo;ll need to further modify the &lt;code&gt;jupyterhub_config.py&lt;/code&gt;. For example, the following will look for a user&amp;rsquo;s home directory on the host system at &lt;code&gt;/volumes/user/&amp;lt;username&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.SystemUserSpawner.host_homedir_format_string = &#39;/volumes/user/{username}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a full example of how SystemUserSpawner is used, see the &lt;a href=&#34;https://github.com/jhamrick/compmodels-jupyterhub&#34; target=&#34;_blank&#34;&gt;compmodels-jupyterhub&lt;/a&gt; (warning: old) repository (this additionally runs the JupyterHub server within a docker container, and authenticates users using GitHub OAuth).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;I believe the correct entry-point for us will actually be &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, at Project Jupyter&amp;rsquo;s Deploy-Docker repository.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;jupyterhub-deploy-docker&lt;/code&gt; provides a reference deployment of JupyterHub, a multi-user Jupyter Notebook environment, on a single host using Docker.
This deployment is NOT intended for a production environment. It is a reference implementation that does not meet traditional requirements in terms of availability nor scalability.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker/raw/master/internal/jupyterhub-docker.png&#34; alt=&#34;schematic&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Okay, so this is actually a great solution, but it&amp;rsquo;s the same thing more/less as the &amp;ldquo;french&amp;rdquo; solution, with the encryption being handled directly by Jupyterhub.&lt;/p&gt;

&lt;p&gt;Since we want to be building Linux images and then running a Hub on each one, we basically just need to paste installation instructions into the Dockerfile.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c conda-forge jupyterhub
conda install jupyterlab
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;docker-jupyter-stacks&#34;&gt;Docker Jupyter Stacks&lt;/h1&gt;

&lt;p&gt;However, I then came across &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;Jupyter Docker Stacks&lt;/a&gt;, which appear to be a number of recipes I can start with.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s go ahead and try this on the server.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Example 2: This command pulls the jupyter/datascience-notebook image tagged 3772fffc4aa4 from Docker Hub if it is not already present on the local host.
It then starts an ephemeral container running a Jupyter Notebook server and exposes the server on host port 10000. The command mounts the current working directory on the host as /home/jovyan/work in the container. The server logs appear in the terminal. Visiting http://&lt;hostname&gt;:10000/?token=&lt;token&gt; in a browser loads JupyterLab, where hostname is the name of the computer running docker and token is the secret token printed in the console. Docker destroys the container after notebook server exit, but any files written to ~/work in the container remain intact on the host.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm -p 10000:8888 -e JUPYTER_ENABLE_LAB=yes -v &amp;quot;$PWD&amp;quot;:/home/jovyan/work jupyter/datascience-notebook:3772fffc4aa4
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;My workstation was unable to find the image locally so it began to pull it from docker-cloud. &lt;em&gt;This took a moment.&lt;/em&gt; Appears to be several gb large.&lt;/p&gt;

&lt;p&gt;Okay, well I managed to connect to it by visiting &lt;code&gt;&amp;lt;IP&amp;gt;:10000/?token=XXXX...XXXX&lt;/code&gt;, where I grabbed the token from the output of the terminal window.&lt;/p&gt;

&lt;p&gt;This is great functionality, but it&amp;rsquo;s not the hub we&amp;rsquo;re looking for. That said, the &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;included dockerfiles&lt;/a&gt; are very instructive.&lt;/p&gt;

&lt;p&gt;Here is the dependency list. Each one is a root image of the next.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;base-notebook&lt;/code&gt; &amp;gt; &lt;code&gt;minimal-notebook&lt;/code&gt; &amp;gt;  &lt;code&gt;scipy-notebook&lt;/code&gt; &amp;gt; &lt;code&gt;datascience-notebook&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The last install, the [&lt;code&gt;datascience-notebook&lt;/code&gt;][&lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/datascience-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyter/docker-stacks/blob/master/datascience-notebook/Dockerfile&lt;/a&gt;] includes R and Julia on top of Python. The heavy &lt;code&gt;HDF5&lt;/code&gt; dependency for Julia is not included if the build is in test-mode (see line 10 and 73).
It will also link the kernels together.
As tempting as it is to start here, I&amp;rsquo;d like to start earlier.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/scipy-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy-notebook&lt;/code&gt;&lt;/a&gt; features installs of widgets and more, and is the minimum requirement for most of what we need.&lt;/p&gt;

&lt;p&gt;Something I noticed was that it includes an old version of pip.
If you launch the container, it mounts whatever directory you were in when you executed the &lt;code&gt;docker run&lt;/code&gt; command to a &amp;ldquo;fake one&amp;rdquo; inside docker (so &lt;code&gt;pwd&lt;/code&gt; returns &lt;code&gt;/home/jovyan/work&lt;/code&gt;).
This is actually kind of nice. If volumes of students can be mounted by the professor to have a look around, that would be great. That would, of course, require learning some docker.
Students can even install additional libraries as needed, but they will disappear next time they connect (though the files stick around!).&lt;/p&gt;

&lt;p&gt;What we need to do (I think), is merge this Dockerfile with the JupyterHub deployments. I think this just comes down to configuring the authenticator correctly (and referencing Umberto&amp;rsquo;s file above).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/base-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;base-notebook&lt;/code&gt;&lt;/a&gt;, since it seems that &lt;a href=&#34;https://github.com/jupyter/docker-stacks/blob/master/scipy-notebook/Dockerfile&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy-notebook&lt;/code&gt;&lt;/a&gt; just adds bells and whistles (widgets already is calling jupyterlab extension manager).
And yes, it appears hub is installed!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.

# Ubuntu 18.04 (bionic) from 2018-05-26
# https://github.com/docker-library/official-images/commit/aac6a45b9eb2bffb8102353c350d341a410fb169
ARG BASE_CONTAINER=ubuntu:bionic-20180526@sha256:c8c275751219dadad8fa56b3ac41ca6cb22219ff117ca98fe82b42f24e1ba64e
FROM $BASE_CONTAINER

LABEL maintainer=&amp;quot;Jupyter Project &amp;lt;jupyter@googlegroups.com&amp;gt;&amp;quot;
ARG NB_USER=&amp;quot;jovyan&amp;quot;
ARG NB_UID=&amp;quot;1000&amp;quot;
ARG NB_GID=&amp;quot;100&amp;quot;

USER root

# Install all OS dependencies for notebook server that starts but lacks all
# features (e.g., download as all possible file formats)
ENV DEBIAN_FRONTEND noninteractive
RUN apt-get update &amp;amp;&amp;amp; apt-get -yq dist-upgrade \
 &amp;amp;&amp;amp; apt-get install -yq --no-install-recommends \
    wget \
    bzip2 \
    ca-certificates \
    sudo \
    locales \
    fonts-liberation \
 &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*

RUN echo &amp;quot;en_US.UTF-8 UTF-8&amp;quot; &amp;gt; /etc/locale.gen &amp;amp;&amp;amp; \
    locale-gen

# Configure environment
ENV CONDA_DIR=/opt/conda \
    SHELL=/bin/bash \
    NB_USER=$NB_USER \
    NB_UID=$NB_UID \
    NB_GID=$NB_GID \
    LC_ALL=en_US.UTF-8 \
    LANG=en_US.UTF-8 \
    LANGUAGE=en_US.UTF-8
ENV PATH=$CONDA_DIR/bin:$PATH \
    HOME=/home/$NB_USER

ADD fix-permissions /usr/local/bin/fix-permissions
# Create jovyan user with UID=1000 and in the &#39;users&#39; group
# and make sure these dirs are writable by the `users` group.
RUN groupadd wheel -g 11 &amp;amp;&amp;amp; \
    echo &amp;quot;auth required pam_wheel.so use_uid&amp;quot; &amp;gt;&amp;gt; /etc/pam.d/su &amp;amp;&amp;amp; \
    useradd -m -s /bin/bash -N -u $NB_UID $NB_USER &amp;amp;&amp;amp; \
    mkdir -p $CONDA_DIR &amp;amp;&amp;amp; \
    chown $NB_USER:$NB_GID $CONDA_DIR &amp;amp;&amp;amp; \
    chmod g+w /etc/passwd &amp;amp;&amp;amp; \
    fix-permissions $HOME &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR

USER $NB_UID

# Setup work directory for backward-compatibility
RUN mkdir /home/$NB_USER/work &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install conda as jovyan and check the md5 sum provided on the download site
ENV MINICONDA_VERSION 4.5.11
RUN cd /tmp &amp;amp;&amp;amp; \
    wget --quiet https://repo.continuum.io/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \
    echo &amp;quot;e1045ee415162f944b6aebfe560b8fee *Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh&amp;quot; | md5sum -c - &amp;amp;&amp;amp; \
    /bin/bash Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh -f -b -p $CONDA_DIR &amp;amp;&amp;amp; \
    rm Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --prepend channels conda-forge &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --set auto_update_conda false &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda config --system --set show_channel_urls true &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda install --quiet --yes conda=&amp;quot;${MINICONDA_VERSION%.*}.*&amp;quot; &amp;amp;&amp;amp; \
    $CONDA_DIR/bin/conda update --all --quiet --yes &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    rm -rf /home/$NB_USER/.cache/yarn &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install Tini
RUN conda install --quiet --yes &#39;tini=0.18.0&#39; &amp;amp;&amp;amp; \
    conda list tini | grep tini | tr -s &#39; &#39; | cut -d &#39; &#39; -f 1,2 &amp;gt;&amp;gt; $CONDA_DIR/conda-meta/pinned &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

# Install Jupyter Notebook, Lab, and Hub
# Generate a notebook server config
# Cleanup temporary files
# Correct permissions
# Do all this in a single RUN command to avoid duplicating all of the
# files across image layers when the permissions change
RUN conda install --quiet --yes \
    &#39;notebook=5.7.2&#39; \
    &#39;jupyterhub=0.9.4&#39; \
    &#39;jupyterlab=0.35.4&#39; &amp;amp;&amp;amp; \
    conda clean -tipsy &amp;amp;&amp;amp; \
    jupyter labextension install @jupyterlab/hub-extension@^0.12.0 &amp;amp;&amp;amp; \
    npm cache clean --force &amp;amp;&amp;amp; \
    jupyter notebook --generate-config &amp;amp;&amp;amp; \
    rm -rf $CONDA_DIR/share/jupyter/lab/staging &amp;amp;&amp;amp; \
    rm -rf /home/$NB_USER/.cache/yarn &amp;amp;&amp;amp; \
    fix-permissions $CONDA_DIR &amp;amp;&amp;amp; \
    fix-permissions /home/$NB_USER

USER root

EXPOSE 8888
WORKDIR $HOME

# Configure container startup
ENTRYPOINT [&amp;quot;tini&amp;quot;, &amp;quot;-g&amp;quot;, &amp;quot;--&amp;quot;]
CMD [&amp;quot;start-notebook.sh&amp;quot;]

# Add local files as late as possible to avoid cache busting
COPY start.sh /usr/local/bin/
COPY start-notebook.sh /usr/local/bin/
COPY start-singleuser.sh /usr/local/bin/
COPY jupyter_notebook_config.py /etc/jupyter/
RUN fix-permissions /etc/jupyter/

# Switch back to jovyan to avoid accidental container runs as root
USER $NB_UID
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It seems that the implementation at the &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deploy-Docker&lt;/a&gt; repository actually handles multi-users, and you can CHOOSE ANY OF the aforementioned builds from &lt;a href=&#34;https://hub.docker.com/u/jupyter&#34; target=&#34;_blank&#34;&gt;Jupyter&amp;rsquo;s Page on Docker Cloud&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think I will try this approach. The key difference here is that users are isolated through where docker mounts their directories, not through permissions.&lt;/p&gt;

&lt;p&gt;So the idea is that you have a Linux machine running docker. All the students files are in some directory there. The Hub spawns up a Docker container on-demand for each student, mounting them appropriately. A teacher can access the files since they are simply the user that is using Docker. (anyone with sudo permissions on the UNIX machine? or just part of the correct usergroup? Joe can help there.) When the teachers log in, their accounts get mounted in a place they can see the whole class, but not other instructor&amp;rsquo;s classes!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Virtualization can be used to segment classes, or they can run together. It doesn&amp;rsquo;t matter. Port-forwarding with sub-addresses can be used to direct to the correct hub for login. One hub runs per class. One docker instance manages all the hubs.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m going to try it this way first, rather than the isolated UNIX-machine way.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;the-correct-way&#34;&gt;The &amp;ldquo;Correct Way&amp;rdquo;&lt;/h1&gt;

&lt;p&gt;We will be using &lt;a href=&#34;https://github.com/jupyterhub/dockerspawner&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;dockerspawner&lt;/code&gt;&lt;/a&gt;, and the directions in their &lt;code&gt;README&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Actually&amp;hellip;&lt;/em&gt;
It seems this is what the point of &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deploy Docker&lt;/a&gt; is. Slight modifications are made so that the &lt;code&gt;dockerspawner&lt;/code&gt; launches up our chosen base-image!&lt;/p&gt;

&lt;p&gt;Choose a pinned image on &lt;a href=&#34;https://hub.docker.com/u/jupyter&#34; target=&#34;_blank&#34;&gt;docker cloud&lt;/a&gt; based on the builds from the &lt;a href=&#34;https://github.com/jupyter/docker-stacks&#34; target=&#34;_blank&#34;&gt;stacks on github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Since we really need all the stuff included in the  &lt;a href=&#34;https://hub.docker.com/r/jupyter/scipy-notebook/tags&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;scipy&lt;/code&gt;&lt;/a&gt; stack, and these images are no smaller than 2GB, we might as well spring for the &lt;a href=&#34;https://hub.docker.com/r/jupyter/datascience-notebook/tags&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;datascience&lt;/code&gt;&lt;/a&gt; stack since they are the same size and include R and Julia, which our colleagues may appreciate.&lt;/p&gt;

&lt;p&gt;As of this writing, here is a recent tag: &lt;code&gt;7254cdcfa22b&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;when running, be aware that no sudo priviledges will be granted. &lt;code&gt;-e GRANT_SUDO=yes&lt;/code&gt; needs to be included upon docker run.&lt;/p&gt;

&lt;p&gt;So, following the Deploy-Docker Dockerfile, I can see that it is running relatively recent versions of &lt;code&gt;jupyterhub&lt;/code&gt; and &lt;code&gt;dockerspawner&lt;/code&gt;, despite many files being unchanged for years. That&amp;rsquo;s actually kind of promising for maintenance purposes.&lt;/p&gt;

&lt;p&gt;Starting from Zero&amp;hellip; SSH into my main machine. Move into a directory to perform the cloning. Needed to first run&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sudo apt install docker-compose&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/jupyterhub/jupyterhub-deploy-docker.git
cd jupyterhub-deploy-docker

mkdir -p secrets
cd secrets
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout mykey.key -out mycert.pem

# bad idea?
mv mycert.pem jupyterhub.crt 
mv mykey.key jupyterhub.key

cd ..
mv .env

# change line 19 to 
DOCKER_NOTEBOOK_IMAGE=jupyter/datascience-notebook:7254cdcfa22b

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;jupyterhub_config.py&lt;/code&gt; add the lines&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.DockerSpawner.environment = { &#39;JUPYTER_ENABLE_LAB&#39;: &#39;yes&#39; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we face the authentication problem. We did generate a self-signed cert (hopefully), but the IP address of my workstation is not public. For extra security, best to keep it this way.&lt;/p&gt;

&lt;p&gt;We want to change authentication to users&amp;hellip;
The problem is that I don&amp;rsquo;t want to be setting up github users accounts. Lines 56-57 in &lt;code&gt;juptyerhub_config.py&lt;/code&gt; are the problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c.JupyterHub.authenticator_class = &#39;oauthenticator.GitHubOAuthenticator&#39;
c.GitHubOAuthenticator.oauth_callback_url = os.environ[&#39;OAUTH_CALLBACK_URL&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;I think by commenting it out, PAMAuthenticator is default. Should be good enough?&lt;/em&gt;
Well now if we change this we will have to create user accounts to log in with.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s create a userlist file in the root directory &lt;code&gt;vim userlist&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;michael admin
troy admin
varis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now to actually create these users. Let&amp;rsquo;s see how this was done in &lt;code&gt;hippylib-hub&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

echo &amp;quot;Update Lab materials from GitHub&amp;quot;
cd /home/fenics/Installations/labs &amp;amp;&amp;amp; git pull

echo &amp;quot;Creating ${NUMBER_OF_USERS} new users...&amp;quot;
for ((i = 0; i &amp;lt; ${NUMBER_OF_USERS}; i++));
do
    password=&amp;quot;Breckenridge${i}_g2s3&amp;quot;
    useradd &amp;quot;user${i}&amp;quot; -m -s /bin/bash
    echo &amp;quot;user${i}:${password}&amp;quot; | chpasswd user${i}
    
    cp -rf /home/fenics/.jupyter /home/user${i}/.jupyter
    chown -R user${i} /home/user${i}/.jupyter
    chmod -R u+rX /home/user${i}/.jupyter
    
    cp -r /home/fenics/Installations/labs/Labs /home/user${i}/
    chown -R user${i} /home/user${i}/Labs
    chmod -R u+rX /home/user${i}/Labs
 
    echo &amp;quot;Created user${i} with password ${password}&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So we have to translate this into our &lt;code&gt;Dockerfile.jupyterhub&lt;/code&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Copyright (c) Jupyter Development Team.
# Distributed under the terms of the Modified BSD License.
ARG JUPYTERHUB_VERSION
FROM jupyterhub/jupyterhub-onbuild:$JUPYTERHUB_VERSION

# Install dockerspawner, oauth, postgres
RUN /opt/conda/bin/conda install -yq psycopg2=2.7 &amp;amp;&amp;amp; \
    /opt/conda/bin/conda clean -tipsy &amp;amp;&amp;amp; \
    /opt/conda/bin/pip install --no-cache-dir \
        oauthenticator==0.8.* \
        dockerspawner==0.9.*

# We make additions here.
RUN useradd michael -m -s /bin/bash
RUN echo &amp;quot;michael:test_password&amp;quot; | chpasswd michael
RUN echo &amp;quot;Created user Michael&amp;quot;

# Copy TLS certificate and key
ENV SSL_CERT /srv/jupyterhub/secrets/jupyterhub.crt
ENV SSL_KEY /srv/jupyterhub/secrets/jupyterhub.key
COPY ./secrets/*.crt $SSL_CERT
COPY ./secrets/*.key $SSL_KEY
RUN chmod 700 /srv/jupyterhub/secrets &amp;amp;&amp;amp; \
    chmod 600 /srv/jupyterhub/secrets/*

COPY ./userlist /srv/jupyterhub/userlist
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try it?? The instructions say all I need now is to run &lt;code&gt;make build&lt;/code&gt; in the root directory.&lt;/p&gt;

&lt;p&gt;Failed. Commenting out lines referencing GitHub in &lt;code&gt;Makefile&lt;/code&gt; (lines 23-24) and &lt;code&gt;secrets/oauth.env&lt;/code&gt; (line 48).&lt;/p&gt;

&lt;p&gt;I dont have any clue what is going on in the secrets files. Doing my best but unable to make it work.&lt;/p&gt;

&lt;p&gt;Okay let&amp;rsquo;s try this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -p 8000:8000 -d --name jupyterhub jupyterhub/jupyterhub jupyterhub
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My errors seem to be caused by outdated docker. Since I was running on 16.04, the apt repositories didn&amp;rsquo;t have newer versions, so I needed to manually add the updates:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&amp;quot;
sudo apt-get update
apt-cache policy docker-ce
sudo apt-get install -y docker-ce
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;after setting
&lt;code&gt;ARG JUPYTERHUB_VERSION=0.90&lt;/code&gt; in the header, I was able to finally run &lt;code&gt;make build&lt;/code&gt; (but who knows how it will work).&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s no particular reason Hub has to run in a docker container. It can still spawn up new processes with docker.&lt;/p&gt;

&lt;p&gt;Once &lt;code&gt;make build&lt;/code&gt; finished, I had to run &lt;code&gt;docker-compose up -d&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker ps&lt;/code&gt; revealed two containers. One is a database of some sort (what was causing me trouble with installation earlier before I faked the files).&lt;/p&gt;

&lt;p&gt;Logs are showing me that my problem is indeed with &lt;code&gt;POSTGRES_PASSWORD&lt;/code&gt; &amp;hellip; and this part is certainly a bit above my paygrade.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Docker</title>
      <link>https://www.michaelpilosov.com/openscience/docker/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/docker/</guid>
      <description>

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;nav id=&#34;TableOfContents&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#images&#34;&gt;Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#containers&#34;&gt;Containers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#comparison-to-virtual-machines&#34;&gt;Comparison to Virtual Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#documentation&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#install&#34;&gt;Install&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#linux&#34;&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#macos&#34;&gt;macOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#windows&#34;&gt;Windows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#configure&#34;&gt;Configure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#permissions&#34;&gt;Permissions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#start-on-boot&#34;&gt;Start on boot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#re-route-ip&#34;&gt;Re-route IP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#troubleshooting&#34;&gt;Troubleshooting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ip-forwarding&#34;&gt;IP Forwarding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limiting&#34;&gt;Limiting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#security&#34;&gt;Security&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#security-tips&#34;&gt;Security Tips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deployment&#34;&gt;Deployment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#making-docker-safe-for-production&#34;&gt;Making Docker Safe for Production&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#port-exposal&#34;&gt;Port-Exposal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more&#34;&gt;More&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#user-namespaces&#34;&gt;User Namespaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-security-roadmap&#34;&gt;The Security Roadmap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#security-videos&#34;&gt;Security Videos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cheat-sheet&#34;&gt;Cheat Sheet&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#images-1&#34;&gt;Images&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-up&#34;&gt;Cleaning up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#load-save-image&#34;&gt;Load/Save image&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#layers&#34;&gt;Layers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#containers-1&#34;&gt;Containers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-1&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#starting-and-stopping&#34;&gt;Starting and Stopping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-1&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#import-export&#34;&gt;Import / Export&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#executing-commands&#34;&gt;Executing Commands&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#container-import-export&#34;&gt;Container Import/Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#management&#34;&gt;Management&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cpu-constraints&#34;&gt;CPU Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#memory-constraints&#34;&gt;Memory Constraints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#capabilities&#34;&gt;Capabilities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dockerfile&#34;&gt;Dockerfile&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#instructions&#34;&gt;Instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tutorial&#34;&gt;Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#examples&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#networks&#34;&gt;Networks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-2&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-2&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#connection&#34;&gt;Connection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#registries&#34;&gt;Registries&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#registries-v-repositories&#34;&gt;Registries v. Repositories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#run-local-registry&#34;&gt;Run local registry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#links&#34;&gt;Links&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#volumes&#34;&gt;Volumes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lifecycle-3&#34;&gt;Lifecycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#info-3&#34;&gt;Info&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#useful-commands-tips&#34;&gt;Useful Commands/Tips&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#versions&#34;&gt;Versions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basics&#34;&gt;Basics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#get-ip-address&#34;&gt;Get IP Address&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#get-port-mapping&#34;&gt;Get Port Mapping&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#general&#34;&gt;General&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#find-containers-using-regular-expression&#34;&gt;Find containers using regular expression:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#get-environment-settings&#34;&gt;Get environment settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kill-running-containers&#34;&gt;Kill running containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-all-containers-force-running-or-stopped-containers&#34;&gt;Delete all containers (force!! running or stopped containers)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-old-containers&#34;&gt;Delete old containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-stopped-containers&#34;&gt;Delete stopped containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-containers-after-stopping&#34;&gt;Delete containers after stopping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-dangling-images&#34;&gt;Delete dangling images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-all-images&#34;&gt;Delete all images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#delete-dangling-volumes&#34;&gt;Delete dangling volumes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#show-image-dependencies&#34;&gt;Show image dependencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#df&#34;&gt;df&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#heredoc-docker-container&#34;&gt;Heredoc Docker Container&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prune&#34;&gt;Prune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#last-ids&#34;&gt;Last Ids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#commit&#34;&gt;Commit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monitoring&#34;&gt;Monitoring&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#monitor-system-resource-utilization-for-running-containers&#34;&gt;Monitor system resource utilization for running containers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#volumes-can-be-files&#34;&gt;Volumes can be files&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#efficiency&#34;&gt;Efficiency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#best-practices&#34;&gt;Best Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;From the &lt;a href=&#34;https://docs.docker.com/get-started/&#34; target=&#34;_blank&#34;&gt;Docker Documentation&lt;/a&gt;:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. &amp;gt; The use of Linux containers to deploy applications is called containerization. Containers are not new, but their use for easily deploying applications is.&lt;/p&gt;

&lt;p&gt;Containerization is increasingly popular because containers are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Flexible: Even the most complex applications can be containerized.&lt;/li&gt;
&lt;li&gt;Lightweight: Containers leverage and share the host kernel.&lt;/li&gt;
&lt;li&gt;Interchangeable: You can deploy updates and upgrades on-the-fly.&lt;/li&gt;
&lt;li&gt;Portable: You can build locally, deploy to the cloud, and run anywhere.&lt;/li&gt;
&lt;li&gt;Scalable: You can increase and automatically distribute container replicas.&lt;/li&gt;
&lt;li&gt;Stackable: You can stack services vertically and on-the-fly.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;images&#34;&gt;Images&lt;/h2&gt;

&lt;p&gt;An image is a collection of files (a package) that is executable.
It has &lt;strong&gt;all the files&lt;/strong&gt; necessary to run an application, from dependencies to configuration files.&lt;/p&gt;

&lt;p&gt;It is analogous to a &lt;code&gt;class&lt;/code&gt; from object-oriented programming.&lt;/p&gt;

&lt;h2 id=&#34;containers&#34;&gt;Containers&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;A &lt;strong&gt;container&lt;/strong&gt; is a runtime instance of an image,&amp;rdquo; or in other words, it is an instance of a class.
One image can be used to &amp;ldquo;spin up&amp;rdquo; many containers.
A container is what an image becomes (in the computer&amp;rsquo;s memory) when it is launched.
It is a user process with a state and need for access to resources.&lt;/p&gt;

&lt;p&gt;Docker being a &amp;ldquo;machine&amp;rdquo; of sorts, it has its own processes, which happen to be instances of images&amp;ndash;containers.&lt;/p&gt;

&lt;p&gt;Just as you would in Linux, you can see a list of your running containers by issuing &lt;code&gt;(sudo) docker ps&lt;/code&gt; (more on that soon).&lt;/p&gt;

&lt;h3 id=&#34;comparison-to-virtual-machines&#34;&gt;Comparison to Virtual Machines&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;A container runs natively on Linux and shares the kernel of the host machine with other containers. It runs a discrete process, taking no more memory than any other executable, making it lightweight.&lt;/p&gt;

&lt;p&gt;By contrast, a virtual machine (VM) runs a full-blown “guest” operating system with virtual access to host resources through a hypervisor. In general, VMs provide an environment with more resources than most applications need.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here is a Virtual Machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.docker.com/images/VM%402x.png&#34; alt=&#34;container-vm-comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And here is a Container:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.docker.com/images/Container%402x.png&#34; alt=&#34;container-vm-comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how Docker sits atop the Host Operating System &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:os-footnote&#34;&gt;&lt;a href=&#34;#fn:os-footnote&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and is performing the management role of resources among applications in place of a &amp;ldquo;hypervisor&amp;rdquo; from a Virtual Machine.&lt;/p&gt;

&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;

&lt;p&gt;Here is the &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Cheatsheet&lt;/a&gt; from which I will be pulling much of what is in this post.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;install&#34;&gt;Install&lt;/h1&gt;

&lt;h2 id=&#34;linux&#34;&gt;Linux&lt;/h2&gt;

&lt;p&gt;Quick and easy install script provided by Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -sSL https://get.docker.com/ | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;From the author of the cheatsheet:&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re not willing to run a random shell script, please see the &lt;a href=&#34;https://docs.docker.com/engine/installation/linux/&#34; target=&#34;_blank&#34;&gt;installation&lt;/a&gt; instructions for your distribution.
If you are a complete Docker newbie, you should follow the &lt;a href=&#34;https://docs.docker.com/engine/getstarted/&#34; target=&#34;_blank&#34;&gt;series of tutorials&lt;/a&gt; now.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;macos&#34;&gt;macOS&lt;/h2&gt;

&lt;p&gt;Download and install &lt;a href=&#34;https://www.docker.com/community-edition&#34; target=&#34;_blank&#34;&gt;Docker Community Edition&lt;/a&gt;. if you have Homebrew-Cask, just type &lt;code&gt;brew cask install docker&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Once you&amp;rsquo;ve installed Docker Community Edition, click the docker icon in Launchpad. Then start up a container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; You may have to restart your shell session (either by closing and re-launching a new one, or logging out of your remote server connection with &lt;code&gt;Ctrl-D&lt;/code&gt; and logging back in with &lt;code&gt;ssh&lt;/code&gt;). This is what I had to do.&lt;/p&gt;

&lt;p&gt;If successful, you should see a &amp;ldquo;Hello from Docker!&amp;rdquo; printout in your console.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;And that&amp;rsquo;s it, you have a running Docker container (this one comes with the install).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;However, we are not quite done yet. Let&amp;rsquo;s get to some configuration&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;windows&#34;&gt;Windows&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/docker-for-windows/install/&#34; target=&#34;_blank&#34;&gt;Go deal with it yourself&lt;/a&gt;. It&amp;rsquo;s similar to the Desktop-version available for Mac, but comes with &lt;strong&gt;all sorts of caveats you should read through first.&lt;/strong&gt;
It should be fairly straightforward for Windows 10 Users.
My suggestion is to simply go with Linux, since our focus is on using Docker for deploying to servers, which are unlikely to be running Windows for the use-cases we have in mind. That said, &lt;em&gt;should be doable, if you insist on it.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;configure&#34;&gt;Configure&lt;/h1&gt;

&lt;p&gt;One thing you may notice is that &lt;code&gt;docker&lt;/code&gt; commands require the use of &lt;code&gt;sudo&lt;/code&gt;, which we would like to avoid.
To avoid permission errors (and the use of sudo), add your user to the &lt;code&gt;docker&lt;/code&gt; group.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;Post-Installation Steps&lt;/a&gt; contains optional procedures for configuring Linux hosts to work better with Docker. &lt;em&gt;The following is taken from that source, and much more &lt;strong&gt;Troubleshooting Information can be found there&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;permissions&#34;&gt;Permissions&lt;/h2&gt;

&lt;p&gt;To create the docker group and add your user:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Create the docker group.&lt;/li&gt;
&lt;li&gt;Add your user to the docker group.&lt;/li&gt;
&lt;li&gt;Log out and log back in so that your group membership is re-evaluated. Some caveats may apply. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:usergroup-caveats&#34;&gt;&lt;a href=&#34;#fn:usergroup-caveats&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo groupadd docker
sudo usermod -aG docker $USER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verify that you can run docker commands without sudo.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run hello-world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command downloads a test image and runs it in a container. When the container runs, it prints an informational message and exits.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you initially ran Docker CLI commands using sudo before adding your user to the docker group, you may see the following error, which indicates that your &lt;code&gt;~/.docker/&lt;/code&gt; directory was created with incorrect permissions due to the sudo commands.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WARNING: Error loading config file: /home/user/.docker/config.json 
- stat /home/user/.docker/config.json: permission denied
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To fix this problem, either remove the &lt;code&gt;~/.docker/ directory&lt;/code&gt; (it is recreated automatically, but any custom settings are lost), or change its ownership and permissions using the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chown &amp;quot;$USER&amp;quot;:&amp;quot;$USER&amp;quot; /home/&amp;quot;$USER&amp;quot;/.docker -R
sudo chmod g+rwx &amp;quot;$HOME/.docker&amp;quot; -R
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;start-on-boot&#34;&gt;Start on boot&lt;/h2&gt;

&lt;p&gt;Sometimes you want Docker to be the main thing running on a server and thus started up on boot (for the occasional restart).
This feature may be desired for servers that host critical processes using Docker.
Most current Linux distributions (RHEL, CentOS, Fedora, Ubuntu 16.04 and higher) use &lt;code&gt;systemd&lt;/code&gt; to manage which services start when the system boots. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:linux-version&#34;&gt;&lt;a href=&#34;#fn:linux-version&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl enable docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To disable this behavior, use &lt;code&gt;disable&lt;/code&gt; instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl disable docker
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;re-route-ip&#34;&gt;Re-route IP&lt;/h2&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;By default, the Docker daemon listens for connections on a UNIX socket to accept requests from local clients.&lt;/p&gt;

&lt;p&gt;It is possible to allow Docker to accept requests from remote hosts by configuring it to listen on an IP address and port as well as the UNIX socket.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;For more detailed information on this configuration option take a look at “Bind Docker to another host/port or a unix socket” section of the &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/dockerd/&#34; target=&#34;_blank&#34;&gt;Docker CLI Reference article&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;&lt;strong&gt;Security Notice&lt;/strong&gt;: Before configuring Docker to accept connections from remote hosts it is critically important that you understand the security implications of opening docker to the network. If steps are not taken to secure the connection, it is possible for remote non-root users to gain root access on the host. For more information on how to use TLS certificates to secure this connection, check this article on how to protect the Docker daemon socket.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Configuring Docker to accept remote connections can be done with the &lt;code&gt;docker.service&lt;/code&gt; &lt;code&gt;systemd&lt;/code&gt; unit file for Linux distributions using &lt;code&gt;systemd&lt;/code&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Use the command &lt;code&gt;sudo systemctl edit docker.service&lt;/code&gt; to open an override file for &lt;code&gt;docker.service&lt;/code&gt; in a text editor.&lt;/p&gt;

&lt;p&gt;Add or modify the following lines, &lt;em&gt;substituting your own values.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H fd:// -H tcp://127.0.0.1:2375
Save the file.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reload the systemctl configuration and restart Docker.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl daemon-reload
sudo systemctl restart docker.service
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Check to see whether the change was honored by reviewing the output of &lt;code&gt;netstat&lt;/code&gt; to confirm &lt;code&gt;dockerd&lt;/code&gt; is listening on the configured port, which should look similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo netstat -lntp | grep dockerd
tcp        0      0 127.0.0.1:2375          0.0.0.0:*               LISTEN      3758/dockerd
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;To enable IPv6 on the Docker daemon, see &lt;a href=&#34;https://docs.docker.com/config/daemon/ipv6/&#34; target=&#34;_blank&#34;&gt;Enable IPv6 support&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;

&lt;p&gt;More troubleshooting information can be found in the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/#troubleshooting&#34; target=&#34;_blank&#34;&gt;Troubleshooting section&lt;/a&gt; of the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;Post-Install&lt;/a&gt; documentation page.&lt;/p&gt;

&lt;p&gt;Here we attempt to address just a couple of the most common things that we may have to do.&lt;/p&gt;

&lt;h3 id=&#34;ip-forwarding&#34;&gt;IP Forwarding&lt;/h3&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you manually configure your network using &lt;code&gt;systemd-network&lt;/code&gt; with &lt;code&gt;systemd&lt;/code&gt; &lt;strong&gt;version 219 or higher,&lt;/strong&gt; &lt;em&gt;Docker containers may not be able to access your network.&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Beginning with &lt;code&gt;systemd&lt;/code&gt; &lt;strong&gt;version 220&lt;/strong&gt;, the forwarding setting for a given network (&lt;code&gt;net.ipv4.conf.&amp;lt;interface&amp;gt;.forwarding&lt;/code&gt;) defaults to &lt;code&gt;off&lt;/code&gt;.
This setting prevents IP forwarding.
It also conflicts with Docker’s behavior of enabling the &lt;code&gt;net.ipv4.conf.all.forwarding&lt;/code&gt; setting within containers.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;To work around this on RHEL, CentOS, or Fedora, edit the &lt;code&gt;&amp;lt;interface&amp;gt;.network&lt;/code&gt; file in &lt;code&gt;/usr/lib/systemd/network/&lt;/code&gt; on your Docker host (ex: &lt;code&gt;/usr/lib/systemd/network/80-container-host0.network&lt;/code&gt;) and add the following block within the &lt;code&gt;[Network]&lt;/code&gt; section.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Network]
...
IPForward=kernel
# OR
IPForward=true
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;This configuration allows IP forwarding from the container as expected.&lt;/p&gt;

&lt;h3 id=&#34;limiting&#34;&gt;Limiting&lt;/h3&gt;

&lt;p&gt;You may see&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;WARNING: Your kernel does not support swap limit capabilities. Limitation discarded.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;This warning does not occur on RPM-based systems, which enable these capabilities by default.
If you don’t need these capabilities, you can ignore the warning.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can enable these capabilities on Ubuntu or Debian by following these instructions.
Memory and swap accounting incur an overhead of about 1% of the total available memory and a 10% overall performance degradation, even if Docker is not running.&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Log into the Ubuntu or Debian host as a user with sudo privileges.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Edit the &lt;code&gt;/etc/default/grub&lt;/code&gt; file. Add or edit the &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt; line to add the following two key-value pairs:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;GRUB_CMDLINE_LINUX=&amp;quot;cgroup_enable=memory swapaccount=1&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Save and close the file.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Update GRUB.
&lt;code&gt;sudo update-grub&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If your GRUB configuration file has incorrect syntax, an error occurs. In this case, repeat steps 3 and 4.
 The changes take effect when the system is rebooted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;security&#34;&gt;Security&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;This is where security tips about Docker go. The Docker &lt;a href=&#34;https://docs.docker.com/engine/security/security/&#34; target=&#34;_blank&#34;&gt;security&lt;/a&gt; page goes into more detail.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First things first: &lt;strong&gt;Docker runs as root.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you are in the &lt;code&gt;docker&lt;/code&gt; group, you effectively &lt;a href=&#34;http://reventlov.com/advisories/using-the-docker-command-to-root-the-host&#34; target=&#34;_blank&#34;&gt;have root access&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;If you &lt;em&gt;expose the docker UNIX socket to a container&lt;/em&gt;, you are giving the container &lt;a href=&#34;https://www.lvh.io/posts/dont-expose-the-docker-socket-not-even-to-a-container.html&#34; target=&#34;_blank&#34;&gt;root access to the host&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Docker should not be your only defense. You should secure and harden it.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;The security tips following are useful if you&amp;rsquo;ve already hardened containers in the past, but are &lt;strong&gt;not a substitute for understanding.&lt;/strong&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:security&#34;&gt;&lt;a href=&#34;#fn:security&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h2 id=&#34;security-tips&#34;&gt;Security Tips&lt;/h2&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;For greatest security, you want to run Docker inside a virtual machine.
(Source: Docker Security Team Lead  &lt;a href=&#34;http://www.slideshare.net/jpetazzo/linux-containers-lxc-docker-and-security&#34; target=&#34;_blank&#34;&gt;slides&lt;/a&gt; / &lt;a href=&#34;http://www.projectatomic.io/blog/2014/08/is-it-safe-a-look-at-docker-and-security-from-linuxcon/&#34; target=&#34;_blank&#34;&gt;notes&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Then, run with AppArmor / seccomp / SELinux / grsec etc to &lt;a href=&#34;http://linux-audit.com/docker-security-best-practices-for-your-vessel-and-containers/&#34; target=&#34;_blank&#34;&gt;limit the container permissions&lt;/a&gt;. See the &lt;a href=&#34;https://blog.docker.com/2016/02/docker-engine-1-10-security/&#34; target=&#34;_blank&#34;&gt;Docker 1.10 security features&lt;/a&gt; for more details.&lt;/p&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Docker image ids are &lt;a href=&#34;https://medium.com/@quayio/your-docker-image-ids-are-secrets-and-its-time-you-treated-them-that-way-f55e9f14c1a4&#34; target=&#34;_blank&#34;&gt;sensitive information&lt;/a&gt; and should not be exposed to the outside world. Treat them like passwords.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;See the &lt;a href=&#34;https://github.com/konstruktoid/Docker/blob/master/Security/CheatSheet.adoc&#34; target=&#34;_blank&#34;&gt;Docker Security Cheat Sheet&lt;/a&gt; by &lt;a href=&#34;https://github.com/konstruktoid&#34; target=&#34;_blank&#34;&gt;Thomas Sjögren&lt;/a&gt;: some good stuff about container hardening in there.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Check out the &lt;strong&gt;&lt;a href=&#34;https://github.com/docker/docker-bench-security&#34; target=&#34;_blank&#34;&gt;docker bench security script&lt;/a&gt;&lt;/strong&gt; for a security benchmark.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Download the &lt;a href=&#34;https://blog.docker.com/2015/05/understanding-docker-security-and-best-practices/&#34; target=&#34;_blank&#34;&gt;white papers&lt;/a&gt; and subscribe to the &lt;a href=&#34;https://www.docker.com/docker-security&#34; target=&#34;_blank&#34;&gt;mailing lists&lt;/a&gt; (unfortunately Docker does not have a unique mailing list, only dev / user). To begin with, see this (foot)note from the cheatsheet &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:begin&#34;&gt;&lt;a href=&#34;#fn:begin&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;

&lt;h3 id=&#34;making-docker-safe-for-production&#34;&gt;Making Docker Safe for Production&lt;/h3&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Since Docker 1.11, you can easily limit the number of active processes running inside a container to prevent fork bombs.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This requires a Linux kernel &amp;gt;= 4.3 with &lt;code&gt;CGROUP_PIDS=y&lt;/code&gt; to be in the kernel configuration.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --pids-limit=64
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Also available since docker 1.11 is the ability to prevent processes from gaining new privileges.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This feature have been in the Linux kernel since version 3.5. You can read more about it in &lt;a href=&#34;http://www.projectatomic.io/blog/2016/03/no-new-privs-docker/&#34; target=&#34;_blank&#34;&gt;this&lt;/a&gt; blog post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --security-opt=no-new-privileges
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;From the &lt;a href=&#34;http://container-solutions.com/content/uploads/2015/06/15.06.15_DockerCheatSheet_A2.pdf&#34; target=&#34;_blank&#34;&gt;Docker Security Cheat Sheet&lt;/a&gt; (it&amp;rsquo;s in PDF which makes it hard to use, so copying below) by &lt;a href=&#34;(http://container-solutions.com/is-docker-safe-for-production/)&#34; target=&#34;_blank&#34;&gt;Container Solutions&lt;/a&gt; :&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;Be aware that the following may affect the performance of your applications in unexpected ways if you are not sure what kinds of communications requirements you need.&lt;/p&gt;

&lt;p&gt;Proceed with caution. Reference the [presentation above][docker-production].&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Turn off interprocess communication with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker -d --icc=false --iptables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set the container to be read-only:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --read-only
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Verify images with a hashsum:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull debian@sha256:a25306f3850e1bd44541976aa7b5fd0a29be
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set volumes to be read only:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -v $(pwd)/secrets:/secrets:ro debian
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Define and run a user in your Dockerfile so you don&amp;rsquo;t run as root inside the container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN groupadd -r user &amp;amp;&amp;amp; useradd -r -g user user
USER user
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;port-exposal&#34;&gt;Port-Exposal&lt;/h2&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Exposing incoming ports through the host container is &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#expose-incoming-ports&#34; target=&#34;_blank&#34;&gt;fiddly but doable&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;This is done by mapping the container port to the host port (only using localhost interface) using &lt;code&gt;-p&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -p 127.0.0.1:$HOSTPORT:$CONTAINERPORT --name CONTAINER -t someimage
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can tell Docker that the container listens on the specified network ports at runtime by using &lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#expose&#34; target=&#34;_blank&#34;&gt;EXPOSE&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPOSE &amp;lt;CONTAINERPORT&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that EXPOSE does not expose the port itself &amp;ndash; only &lt;code&gt;-p&lt;/code&gt; will do that. To expose the container&amp;rsquo;s port on your localhost&amp;rsquo;s port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -t nat -A DOCKER -p tcp --dport &amp;lt;LOCALHOSTPORT&amp;gt; -j DNAT --to-destination &amp;lt;CONTAINERIP&amp;gt;:&amp;lt;PORT&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;re running Docker in Virtualbox, you then need to forward the port there as well, using &lt;a href=&#34;https://docs.vagrantup.com/v2/networking/forwarded_ports.html&#34; target=&#34;_blank&#34;&gt;forwarded_port&lt;/a&gt;. Define a range of ports in your Vagrantfile like this so you can dynamically map them:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  ...

  (49000..49900).each do |port|
    config.vm.network :forwarded_port, :host =&amp;gt; port, :guest =&amp;gt; port
  end

  ...
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you forget what you mapped the port to on the host container, use &lt;code&gt;docker port&lt;/code&gt; to show it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker port CONTAINER $CONTAINERPORT
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;more&#34;&gt;More&lt;/h2&gt;

&lt;h3 id=&#34;user-namespaces&#34;&gt;User Namespaces&lt;/h3&gt;

&lt;p&gt;There&amp;rsquo;s also work on &lt;a href=&#34;https://s3hh.wordpress.com/2013/07/19/creating-and-using-containers-without-privilege/&#34; target=&#34;_blank&#34;&gt;user namespaces&lt;/a&gt; &amp;ndash; it is in 1.10 but is not enabled by default.&lt;/p&gt;

&lt;p&gt;To enable user namespaces (&amp;ldquo;remap the userns&amp;rdquo;) in Ubuntu 15.10, &lt;a href=&#34;https://raesene.github.io/blog/2016/02/04/Docker-User-Namespaces/&#34; target=&#34;_blank&#34;&gt;follow the blog example&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;the-security-roadmap&#34;&gt;The Security Roadmap&lt;/h3&gt;

&lt;p&gt;The Docker roadmap talks about &lt;a href=&#34;https://github.com/docker/docker/blob/master/ROADMAP.md#11-security&#34; target=&#34;_blank&#34;&gt;seccomp support&lt;/a&gt;.
There is an AppArmor policy generator called &lt;a href=&#34;https://github.com/jfrazelle/bane&#34; target=&#34;_blank&#34;&gt;bane&lt;/a&gt;, and they&amp;rsquo;re working on &lt;a href=&#34;https://github.com/docker/docker/issues/17142&#34; target=&#34;_blank&#34;&gt;security profiles&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;security-videos&#34;&gt;Security Videos&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/04LOuMgNj9U&#34; target=&#34;_blank&#34;&gt;Using Docker Safely&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/KmxOXmPhZbk&#34; target=&#34;_blank&#34;&gt;Securing your applications using Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/a9lE9Urr6AQ&#34; target=&#34;_blank&#34;&gt;Container security: Do containers actually contain?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=iN6QbszB1R8&#34; target=&#34;_blank&#34;&gt;Linux Containers: Future or Fantasy?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;cheat-sheet&#34;&gt;Cheat Sheet&lt;/h1&gt;

&lt;p&gt;The following is full &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet&#34; target=&#34;_blank&#34;&gt;Cheat Sheet&lt;/a&gt; mentioned earlier, and presented here for convenience. Feel free to use the table of contents on the right sidebar (or duplicated below for mobile users) to more easily navigate this page than on the Github Gist &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:gist&#34;&gt;&lt;a href=&#34;#fn:gist&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;Table of Contents&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;images-1&#34;&gt;Images&lt;/h2&gt;

&lt;p&gt;Images are just &lt;a href=&#34;https://docs.docker.com/engine/understanding-docker/#how-does-a-docker-image-work&#34; target=&#34;_blank&#34;&gt;templates for docker containers&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/images&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker images&lt;/code&gt;&lt;/a&gt; shows all images.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/import&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker import&lt;/code&gt;&lt;/a&gt; creates an image from a tarball.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/build&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker build&lt;/code&gt;&lt;/a&gt; creates image from Dockerfile.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/commit&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker commit&lt;/code&gt;&lt;/a&gt; creates image from a container, pausing it temporarily if it is running.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rmi&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rmi&lt;/code&gt;&lt;/a&gt; removes an image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/load&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker load&lt;/code&gt;&lt;/a&gt; loads an image from a tar archive as STDIN, including images and tags (as of 0.7).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/save&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker save&lt;/code&gt;&lt;/a&gt; saves an image to a tar archive stream to STDOUT with all parent layers, tags &amp;amp; versions (as of 0.7).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/history&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker history&lt;/code&gt;&lt;/a&gt; shows history of image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/tag&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker tag&lt;/code&gt;&lt;/a&gt; tags an image to a name (local or registry).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;cleaning-up&#34;&gt;Cleaning up&lt;/h3&gt;

&lt;p&gt;While you can use the &lt;code&gt;docker rmi&lt;/code&gt; command to remove specific images, there&amp;rsquo;s a tool called &lt;a href=&#34;https://github.com/spotify/docker-gc&#34; target=&#34;_blank&#34;&gt;docker-gc&lt;/a&gt; that will safely clean up images that are no longer used by any containers.&lt;/p&gt;

&lt;h3 id=&#34;load-save-image&#34;&gt;Load/Save image&lt;/h3&gt;

&lt;p&gt;Load an image from file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker load &amp;lt; my_image.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save an existing image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker save my_image:my_tag | gzip &amp;gt; my_image.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;layers&#34;&gt;Layers&lt;/h2&gt;

&lt;p&gt;The versioned filesystem in Docker is based on layers. They&amp;rsquo;re like &lt;a href=&#34;https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/&#34; target=&#34;_blank&#34;&gt;git commits or changesets for filesystems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Eventually you&amp;rsquo;ll want to make changes to an existing image, and will find yourself manipulating the &lt;code&gt;Dockerfile&lt;/code&gt; that defines the build and configuration of the image.
You can think of this as mimicking the keystrokes a user would have to enter in order to set up each application on a fresh computer.&lt;/p&gt;

&lt;p&gt;Pretty much every image we&amp;rsquo;ll be interested in will have it&amp;rsquo;s origin in some version of a Linux distribution on top of which a number of commands are run to define the files necessary for the use-case.&lt;/p&gt;

&lt;p&gt;Since each &amp;ldquo;version&amp;rdquo; of an image is an entire filesystem, building one version of an image based on a previous one can lead to lots of unnecessary files being tracked.&lt;/p&gt;

&lt;p&gt;As stated in the &lt;a href=&#34;#dockerfile&#34;&gt;Dockerfile section&lt;/a&gt;, the command &lt;code&gt;RUN&lt;/code&gt; executes any commands in a &lt;em&gt;new layer&lt;/em&gt; &lt;strong&gt;on top&lt;/strong&gt; of the current image, and commits the results.&lt;/p&gt;

&lt;p&gt;This &amp;ldquo;on top&amp;rdquo; part is especially important to understand, and several things can be done to keep subsequent changes to an image relatively &amp;ldquo;lightweight.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;For example, make sure to &lt;a href=&#34;#efficiency&#34;&gt;clean up&lt;/a&gt; the &lt;code&gt;APT&lt;/code&gt; repositories.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;containers-1&#34;&gt;Containers&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://etherealmind.com/basics-docker-containers-hypervisors-coreos/&#34; target=&#34;_blank&#34;&gt;Your basic isolated Docker process&lt;/a&gt;. Containers are to Virtual Machines as threads are to processes. Or you can think of them as chroots on steroids.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle-1&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/create&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker create&lt;/code&gt;&lt;/a&gt; creates a container but does not start it.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rename/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rename&lt;/code&gt;&lt;/a&gt; allows the container to be renamed.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/run&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker run&lt;/code&gt;&lt;/a&gt; creates and starts a container in one operation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/rm&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker rm&lt;/code&gt;&lt;/a&gt; deletes a container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/update/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker update&lt;/code&gt;&lt;/a&gt; updates a container&amp;rsquo;s resource limits.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Normally if you run a container without options it will start and stop immediately, if you want keep it running you can use the command, &lt;code&gt;docker run -td container_id&lt;/code&gt; this will use the option &lt;code&gt;-t&lt;/code&gt; that will allocate a pseudo-TTY session and &lt;code&gt;-d&lt;/code&gt; that will detach automatically the container (run container in background and print container ID).&lt;/p&gt;

&lt;p&gt;If you want a transient container, &lt;code&gt;docker run --rm&lt;/code&gt; will remove the container after it stops.&lt;/p&gt;

&lt;p&gt;If you want to map a directory on the host to a docker container, &lt;code&gt;docker run -v $HOSTDIR:$DOCKERDIR&lt;/code&gt;. Also see &lt;a href=&#34;https://github.com/wsargent/docker-cheat-sheet/#volumes&#34; target=&#34;_blank&#34;&gt;Volumes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you want to remove also the volumes associated with the container, the deletion of the container must include the &lt;code&gt;-v&lt;/code&gt; switch like in &lt;code&gt;docker rm -v&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s also a &lt;a href=&#34;https://docs.docker.com/engine/admin/logging/overview/&#34; target=&#34;_blank&#34;&gt;logging driver&lt;/a&gt; available for individual containers in docker 1.10. To run docker with a custom log driver (i.e., to syslog), use &lt;code&gt;docker run --log-driver=syslog&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Another useful option is &lt;code&gt;docker run --name yourname docker_image&lt;/code&gt; because when you specify the &lt;code&gt;--name&lt;/code&gt; inside the run command this will allow you to start and stop a container by calling it with the name the you specified when you created it.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;starting-and-stopping&#34;&gt;Starting and Stopping&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/start&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker start&lt;/code&gt;&lt;/a&gt; starts a container so it is running.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stop&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker stop&lt;/code&gt;&lt;/a&gt; stops a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/restart&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker restart&lt;/code&gt;&lt;/a&gt; stops and starts a container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/pause/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker pause&lt;/code&gt;&lt;/a&gt; pauses a running container, &amp;ldquo;freezing&amp;rdquo; it in place.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/unpause/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker unpause&lt;/code&gt;&lt;/a&gt; will unpause a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/wait&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker wait&lt;/code&gt;&lt;/a&gt; blocks until running container stops.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/kill&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker kill&lt;/code&gt;&lt;/a&gt; sends a SIGKILL to a running container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/attach&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker attach&lt;/code&gt;&lt;/a&gt; will connect to a running container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you want to integrate a container with a &lt;a href=&#34;https://docs.docker.com/engine/admin/host_integration/&#34; target=&#34;_blank&#34;&gt;host process manager&lt;/a&gt;, start the daemon with &lt;code&gt;-r=false&lt;/code&gt; then use &lt;code&gt;docker start -a&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you want to expose container ports through the host, see the &lt;a href=&#34;#exposing-ports&#34;&gt;exposing ports&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;Restart policies on crashed docker instances are &lt;a href=&#34;http://container42.com/2014/09/30/docker-restart-policies/&#34; target=&#34;_blank&#34;&gt;covered here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;info-1&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/ps&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker ps&lt;/code&gt;&lt;/a&gt; shows running containers.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/logs&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker logs&lt;/code&gt;&lt;/a&gt; gets logs from container.  (You can use a custom log driver, but logs is only available for &lt;code&gt;json-file&lt;/code&gt; and &lt;code&gt;journald&lt;/code&gt; in 1.10).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/inspect&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker inspect&lt;/code&gt;&lt;/a&gt; looks at all the info on a container (including IP address).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/events&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker events&lt;/code&gt;&lt;/a&gt; gets events from container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/port&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker port&lt;/code&gt;&lt;/a&gt; shows public facing port of container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/top&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker top&lt;/code&gt;&lt;/a&gt; shows running processes in container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stats&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker stats&lt;/code&gt;&lt;/a&gt; shows containers&amp;rsquo; resource usage statistics.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/diff&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker diff&lt;/code&gt;&lt;/a&gt; shows changed files in the container&amp;rsquo;s FS.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;docker ps -a&lt;/code&gt; shows running and stopped containers.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker stats --all&lt;/code&gt; shows a running list of containers.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;import-export&#34;&gt;Import / Export&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/cp&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker cp&lt;/code&gt;&lt;/a&gt; copies files or folders between a container and the local filesystem.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/export&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker export&lt;/code&gt;&lt;/a&gt; turns container filesystem into tarball archive stream to STDOUT.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;executing-commands&#34;&gt;Executing Commands&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/exec&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker exec&lt;/code&gt;&lt;/a&gt; to execute a command in container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To enter a running container, attach a new shell process to a running container called foo, use: &lt;code&gt;docker exec -it foo /bin/bash&lt;/code&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;container-import-export&#34;&gt;Container Import/Export&lt;/h3&gt;

&lt;p&gt;Import a container as an image from file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat my_container.tar.gz | docker import - my_image:my_tag
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Export an existing container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker export my_container | gzip &amp;gt; my_container.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;The difference between &lt;em&gt;loading a saved image&lt;/em&gt; and importing an exported &lt;em&gt;container as an image&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Loading an image using the &lt;code&gt;load&lt;/code&gt; command creates a new image including its history.&lt;/p&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;Importing a container as an image using the &lt;code&gt;import&lt;/code&gt; command creates a new image, &lt;strong&gt;excluding the history,&lt;/strong&gt; which results in a &lt;em&gt;smaller image size compared to loading an image&lt;/em&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;management&#34;&gt;Management&lt;/h2&gt;

&lt;h3 id=&#34;cpu-constraints&#34;&gt;CPU Constraints&lt;/h3&gt;

&lt;p&gt;You can limit CPU, either using a percentage of all CPUs, or by using specific cores.&lt;/p&gt;

&lt;p&gt;For example, you can tell the &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/cpu-share-constraint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cpu-shares&lt;/code&gt;&lt;/a&gt; setting.  The setting is a bit strange &amp;ndash; 1024 means 100% of the CPU, so if you want the container to take 50% of all CPU cores, you should specify 512.  See &lt;a href=&#34;https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu&#34; target=&#34;_blank&#34;&gt;https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/#_cpu&lt;/a&gt; for more:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti -c 512 agileek/cpuset-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also only use some CPU cores using &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/cpuset-constraint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;cpuset-cpus&lt;/code&gt;&lt;/a&gt;.  See &lt;a href=&#34;https://agileek.github.io/docker/2014/08/06/docker-cpuset/&#34; target=&#34;_blank&#34;&gt;https://agileek.github.io/docker/2014/08/06/docker-cpuset/&lt;/a&gt; for details and some nice videos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -ti --cpuset-cpus=0,4,6 agileek/cpuset-test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that Docker can still &lt;strong&gt;see&lt;/strong&gt; all of the CPUs inside the container &amp;ndash; it just isn&amp;rsquo;t using all of them.  See &lt;a href=&#34;https://github.com/docker/docker/issues/20770&#34; target=&#34;_blank&#34;&gt;https://github.com/docker/docker/issues/20770&lt;/a&gt; for more details.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;memory-constraints&#34;&gt;Memory Constraints&lt;/h3&gt;

&lt;p&gt;You can also set &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/user-memory-constraints&#34; target=&#34;_blank&#34;&gt;memory constraints&lt;/a&gt; on Docker:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it -m 300M ubuntu:14.04 /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;capabilities&#34;&gt;Capabilities&lt;/h3&gt;

&lt;p&gt;Linux capabilities can be set by using &lt;code&gt;cap-add&lt;/code&gt; and &lt;code&gt;cap-drop&lt;/code&gt;.  See &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34; target=&#34;_blank&#34;&gt;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;This should be used for greater security.&lt;/p&gt;

&lt;/div&gt;

To mount a FUSE based filesystem, you need to combine both &amp;ndash;cap-add and &amp;ndash;device:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm -it --cap-add SYS_ADMIN --device /dev/fuse sshfs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give access to a single device:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it --device=/dev/ttyUSB0 debian bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Give access to all devices:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb debian bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;more info about privileged containers &lt;a href=&#34;https://docs.docker.com/engine/reference/run/#/runtime-privilege-and-linux-capabilities&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;dockerfile&#34;&gt;Dockerfile&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34; target=&#34;_blank&#34;&gt;The configuration file&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sets up a Docker container when you run &lt;code&gt;docker build&lt;/code&gt; on it. Vastly preferable to &lt;code&gt;docker commit&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here are some common text editors and their syntax highlighting modules you could use to create Dockerfiles:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://packagecontrol.io/packages/Dockerfile%20Syntax%20Highlighting&#34; target=&#34;_blank&#34;&gt;Sublime Text 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://atom.io/packages/language-docker&#34; target=&#34;_blank&#34;&gt;Atom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ekalinin/Dockerfile.vim&#34; target=&#34;_blank&#34;&gt;Vim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/spotify/dockerfile-mode&#34; target=&#34;_blank&#34;&gt;Emacs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Also see &lt;a href=&#34;https://domeide.github.io/&#34; target=&#34;_blank&#34;&gt;Docker meets the IDE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;instructions&#34;&gt;Instructions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#dockerignore-file&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;.dockerignore&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#from&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;FROM&lt;/code&gt;&lt;/a&gt; Sets the Base Image for subsequent instructions.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#maintainer-deprecated&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;MAINTAINER&lt;/code&gt; (deprecated - use LABEL instead)&lt;/a&gt; Set the Author field of the generated images.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#run&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;RUN&lt;/code&gt;&lt;/a&gt; execute any commands in a new layer on top of the current image and commit the results.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#cmd&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;CMD&lt;/code&gt;&lt;/a&gt; provide defaults for an executing container.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#expose&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;EXPOSE&lt;/code&gt;&lt;/a&gt; informs Docker that the container listens on the specified network ports at runtime.  NOTE: does not actually make ports accessible.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#env&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ENV&lt;/code&gt;&lt;/a&gt; sets environment variable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#add&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ADD&lt;/code&gt;&lt;/a&gt; copies new files, directories or remote file to container.  Invalidates caches. Avoid &lt;code&gt;ADD&lt;/code&gt; and use &lt;code&gt;COPY&lt;/code&gt; instead.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#copy&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;COPY&lt;/code&gt;&lt;/a&gt; copies new files or directories to container.  Note that this only copies as root, so you have to chown manually regardless of your USER / WORKDIR setting.  See &lt;a href=&#34;https://github.com/moby/moby/issues/30110&#34; target=&#34;_blank&#34;&gt;https://github.com/moby/moby/issues/30110&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#entrypoint&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ENTRYPOINT&lt;/code&gt;&lt;/a&gt; configures a container that will run as an executable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#volume&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;VOLUME&lt;/code&gt;&lt;/a&gt; creates a mount point for externally mounted volumes or other containers.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#user&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;USER&lt;/code&gt;&lt;/a&gt; sets the user name for following RUN / CMD / ENTRYPOINT commands.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#workdir&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;WORKDIR&lt;/code&gt;&lt;/a&gt; sets the working directory.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#arg&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ARG&lt;/code&gt;&lt;/a&gt; defines a build-time variable.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#onbuild&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ONBUILD&lt;/code&gt;&lt;/a&gt; adds a trigger instruction when the image is used as the base for another build.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#stopsignal&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;STOPSIGNAL&lt;/code&gt;&lt;/a&gt; sets the system call signal that will be sent to the container to exit.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/labels-custom-metadata/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;LABEL&lt;/code&gt;&lt;/a&gt; apply key/value metadata to your images, containers, or daemons.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;tutorial&#34;&gt;Tutorial&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://flux7.com/blogs/docker/docker-tutorial-series-part-3-automation-is-the-word-using-dockerfile/&#34; target=&#34;_blank&#34;&gt;Flux7&amp;rsquo;s Dockerfile Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/#dockerfile-examples&#34; target=&#34;_blank&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/&#34; target=&#34;_blank&#34;&gt;Best practices for writing Dockerfiles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://crosbymichael.com/&#34; target=&#34;_blank&#34;&gt;Michael Crosby&lt;/a&gt; has some more &lt;a href=&#34;http://crosbymichael.com/dockerfile-best-practices.html&#34; target=&#34;_blank&#34;&gt;Dockerfiles best practices&lt;/a&gt; / &lt;a href=&#34;http://crosbymichael.com/dockerfile-best-practices-take-2.html&#34; target=&#34;_blank&#34;&gt;take 2&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://jonathan.bergknoff.com/journal/building-good-docker-images&#34; target=&#34;_blank&#34;&gt;Building Good Docker Images&lt;/a&gt; / &lt;a href=&#34;http://jonathan.bergknoff.com/journal/building-better-docker-images&#34; target=&#34;_blank&#34;&gt;Building Better Docker Images&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://speakerdeck.com/garethr/managing-container-configuration-with-metadata&#34; target=&#34;_blank&#34;&gt;Managing Container Configuration with Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rock-it.pl/how-to-write-excellent-dockerfiles/&#34; target=&#34;_blank&#34;&gt;How to write excellent Dockerfiles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;networks&#34;&gt;Networks&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker has a &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/&#34; target=&#34;_blank&#34;&gt;networks&lt;/a&gt; feature.
Not much is known about it, so this is a good place to expand the cheat sheet.
There is a note saying that it&amp;rsquo;s a good way to configure docker containers to talk to each other without using ports.
See &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/work-with-networks/&#34; target=&#34;_blank&#34;&gt;working with networks&lt;/a&gt; for more details.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;lifecycle-2&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_create/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network create&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_rm/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network rm&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info-2&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_ls/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network ls&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_inspect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network inspect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;connection&#34;&gt;Connection&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_connect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network connect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/network_disconnect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker network disconnect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can specify a &lt;a href=&#34;https://blog.jessfraz.com/post/ips-for-all-the-things/&#34; target=&#34;_blank&#34;&gt;specific IP address for a container&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# create a new bridge network with your subnet and gateway for your ip block
$ docker network create --subnet 203.0.113.0/24 --gateway 203.0.113.254 iptastic

# run a nginx container with a specific ip in that block
$ docker run --rm -it --net iptastic --ip 203.0.113.2 nginx

# curl the ip from any other place (assuming this is a public ip block duh)
$ curl 203.0.113.2
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;registries&#34;&gt;Registries&lt;/h2&gt;

&lt;h3 id=&#34;registries-v-repositories&#34;&gt;Registries v. Repositories&lt;/h3&gt;

&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;A repository is a &lt;em&gt;hosted&lt;/em&gt; collection of tagged images that together create the file system for a container.&lt;/p&gt;

&lt;/div&gt;


&lt;div class=&#34;alert alert-&#34;&gt;
  &lt;p&gt;A registry is a &lt;em&gt;host&lt;/em&gt; &amp;ndash; a server that stores repositories and provides an HTTP API for &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockerrepos/&#34; target=&#34;_blank&#34;&gt;managing the uploading and downloading of repositories&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;Docker.com hosts its own &lt;a href=&#34;https://hub.docker.com/&#34; target=&#34;_blank&#34;&gt;index&lt;/a&gt; to a central registry which contains a large number of repositories.&lt;/p&gt;

&lt;p&gt;Having said that, the central docker registry &lt;a href=&#34;https://titanous.com/posts/docker-insecurity&#34; target=&#34;_blank&#34;&gt;does not do a good job of verifying images&lt;/a&gt; and should be avoided if you&amp;rsquo;re worried about security.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/login&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker login&lt;/code&gt;&lt;/a&gt; to login to a registry.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/logout&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker logout&lt;/code&gt;&lt;/a&gt; to logout from a registry.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/search&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker search&lt;/code&gt;&lt;/a&gt; searches registry for image.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/pull&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker pull&lt;/code&gt;&lt;/a&gt; pulls an image from registry to local machine.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/push&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker push&lt;/code&gt;&lt;/a&gt; pushes an image to the registry from local machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;run-local-registry&#34;&gt;Run local registry&lt;/h3&gt;

&lt;p&gt;You can run a local registry by using the &lt;a href=&#34;https://github.com/docker/distribution&#34; target=&#34;_blank&#34;&gt;docker distribution&lt;/a&gt; project and looking at the &lt;a href=&#34;https://github.com/docker/docker.github.io/blob/master/registry/deploying.md&#34; target=&#34;_blank&#34;&gt;local deploy&lt;/a&gt; instructions.&lt;/p&gt;

&lt;p&gt;Also see the &lt;a href=&#34;https://groups.google.com/a/dockerproject.org/forum/#!forum/distribution&#34; target=&#34;_blank&#34;&gt;mailing list&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;p&gt;Links are how Docker containers talk to each other &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/&#34; target=&#34;_blank&#34;&gt;through TCP/IP ports&lt;/a&gt;. &lt;a href=&#34;https://docs.docker.com/engine/examples/running_redis_service/&#34; target=&#34;_blank&#34;&gt;Linking into Redis&lt;/a&gt; and &lt;a href=&#34;https://blogs.atlassian.com/2013/11/docker-all-the-things-at-atlassian-automation-and-wiring/&#34; target=&#34;_blank&#34;&gt;Atlassian&lt;/a&gt; show worked examples. You can also resolve &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/#/updating-the-etchosts-file&#34; target=&#34;_blank&#34;&gt;links by hostname&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This has been deprected to some extent by &lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/#user-defined-networks&#34; target=&#34;_blank&#34;&gt;user-defined networks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;NOTE: If you want containers to ONLY communicate with each other through links, start the docker daemon with &lt;code&gt;-icc=false&lt;/code&gt; to disable inter process communication.&lt;/p&gt;

&lt;p&gt;If you have a container with the name CONTAINER (specified by &lt;code&gt;docker run --name CONTAINER&lt;/code&gt;) and in the Dockerfile, it has an exposed port:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPOSE 1337
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then if we create another container called LINKED like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d --link CONTAINER:ALIAS --name LINKED user/wordpress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the exposed ports and aliases of CONTAINER will show up in LINKED with the following environment variables:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ALIAS_PORT_1337_TCP_PORT
$ALIAS_PORT_1337_TCP_ADDR
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can connect to it that way.&lt;/p&gt;

&lt;p&gt;To delete links, use &lt;code&gt;docker rm --link&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Generally, linking between docker services is a subset of &amp;ldquo;service discovery&amp;rdquo;, a big problem if you&amp;rsquo;re planning to use Docker at scale in production.  Please read &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/the-docker-ecosystem-service-discovery-and-distributed-configuration-stores&#34; target=&#34;_blank&#34;&gt;The Docker Ecosystem: Service Discovery and Distributed Configuration Stores&lt;/a&gt; for more info.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;volumes&#34;&gt;Volumes&lt;/h2&gt;

&lt;p&gt;Docker volumes are &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/&#34; target=&#34;_blank&#34;&gt;free-floating filesystems&lt;/a&gt;. They don&amp;rsquo;t have to be connected to a particular container. You should use volumes mounted from &lt;a href=&#34;https://medium.com/@ramangupta/why-docker-data-containers-are-good-589b3c6c749e&#34; target=&#34;_blank&#34;&gt;data-only containers&lt;/a&gt; for portability.&lt;/p&gt;

&lt;h3 id=&#34;lifecycle-3&#34;&gt;Lifecycle&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_create/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume create&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_rm/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume rm&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;info-3&#34;&gt;Info&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_ls/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume ls&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/volume_inspect/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker volume inspect&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Volumes are useful in situations where you can&amp;rsquo;t use links (which are TCP/IP only). For instance, if you need to have two docker instances communicate by leaving stuff on the filesystem.&lt;/p&gt;

&lt;p&gt;You can mount them in several docker containers at once, using &lt;code&gt;docker run --volumes-from&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Because volumes are isolated filesystems, they are often used to store state from computations between transient containers. That is, you can have a stateless and transient container run from a recipe, blow it away, and then have a second instance of the transient container pick up from where the last one left off.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&#34;http://crosbymichael.com/advanced-docker-volumes.html&#34; target=&#34;_blank&#34;&gt;advanced volumes&lt;/a&gt; for more details. Container42 is &lt;a href=&#34;http://container42.com/2014/11/03/docker-indepth-volumes/&#34; target=&#34;_blank&#34;&gt;also helpful&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You can &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/#mount-a-host-directory-as-a-data-volume&#34; target=&#34;_blank&#34;&gt;map MacOS host directories as docker volumes&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -v /Users/wsargent/myapp/src:/src
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use remote NFS volumes if you&amp;rsquo;re &lt;a href=&#34;https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-shared-storage-volume-as-a-data-volume&#34; target=&#34;_blank&#34;&gt;feeling brave&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You may also consider running data-only containers as described &lt;a href=&#34;http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; to provide some data portability.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#volumes-can-be-files&#34;&gt;Be aware that you can mount files as volumes.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;#table-of-contents&#34;&gt;back to top&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;useful-commands-tips&#34;&gt;Useful Commands/Tips&lt;/h1&gt;

&lt;p&gt;Sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://sssslide.com/speakerdeck.com/bmorearty/15-docker-tips-in-5-minutes&#34; target=&#34;_blank&#34;&gt;15 Docker Tips in 5 minutes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codefresh.io/blog/everyday-hacks-docker/&#34; target=&#34;_blank&#34;&gt;CodeFresh Everyday Hacks Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;versions&#34;&gt;Versions&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;It is very important that you always know the current version of Docker you are currently running on at any point in time.&lt;/em&gt;
This is very helpful because you get to know what features are compatible with what you have running.
This is also important because you know what containers to run from the docker store when you are trying to get template containers.
That said let see how to know what version of docker we have running currently&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/version/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;docker version&lt;/code&gt;&lt;/a&gt; checks what version of docker you have running&lt;/li&gt;
&lt;li&gt;Usage: &lt;code&gt;docker version [OPTIONS]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Get the server version&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker version --format &#39;{{.Server.Version}}&#39;

1.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dump raw JSON data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker version --format &#39;{{json .}}&#39;

{&amp;quot;Client&amp;quot;:{&amp;quot;Version&amp;quot;:&amp;quot;1.8.0&amp;quot;,&amp;quot;ApiVersion&amp;quot;:&amp;quot;1.20&amp;quot;,&amp;quot;GitCommit&amp;quot;:&amp;quot;f5bae0a&amp;quot;,&amp;quot;GoVersion&amp;quot;:&amp;quot;go1.4.2&amp;quot;,&amp;quot;Os&amp;quot;:&amp;quot;linux&amp;quot;,&amp;quot;Arch&amp;quot;:&amp;quot;am&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;basics&#34;&gt;Basics&lt;/h2&gt;

&lt;h3 id=&#34;get-ip-address&#34;&gt;Get IP Address&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker inspect $(dl) | grep -wm1 IPAddress | cut -d &#39;&amp;quot;&#39; -f 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or install &lt;a href=&#34;https://stedolan.github.io/jq/&#34; target=&#34;_blank&#34;&gt;jq&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker inspect $(dl) | jq -r &#39;.[0].NetworkSettings.IPAddress&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or using a &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/inspect&#34; target=&#34;_blank&#34;&gt;go template&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker inspect -f &#39;{{ .NetworkSettings.IPAddress }}&#39; &amp;lt;container_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or when building an image from Dockerfile, when you want to pass in a build argument:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DOCKER_HOST_IP=`ifconfig | grep -E &amp;quot;([0-9]{1,3}\.){3}[0-9]{1,3}&amp;quot; | grep -v 127.0.0.1 | awk &#39;{ print $2 }&#39; | cut -f2 -d: | head -n1`
echo DOCKER_HOST_IP = $DOCKER_HOST_IP
docker build \
  --build-arg ARTIFACTORY_ADDRESS=$DOCKER_HOST_IP 
  -t sometag \
  some-directory/
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;get-port-mapping&#34;&gt;Get Port Mapping&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker inspect -f &#39;{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} -&amp;gt; {{(index $conf 0).HostPort}} {{end}}&#39; &amp;lt;containername&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;general&#34;&gt;General&lt;/h2&gt;

&lt;h3 id=&#34;find-containers-using-regular-expression&#34;&gt;Find containers using regular expression:&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;for i in $(docker ps -a | grep &amp;quot;REGEXP_PATTERN&amp;quot; | cut -f1 -d&amp;quot; &amp;quot;); do echo $i; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-environment-settings&#34;&gt;Get environment settings&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm ubuntu env
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;kill-running-containers&#34;&gt;Kill running containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker kill $(docker ps -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-all-containers-force-running-or-stopped-containers&#34;&gt;Delete all containers (force!! running or stopped containers)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rm -f $(docker ps -qa)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-old-containers&#34;&gt;Delete old containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a | grep &#39;weeks ago&#39; | awk &#39;{print $1}&#39; | xargs docker rm
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-stopped-containers&#34;&gt;Delete stopped containers&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rm -v $(docker ps -a -q -f status=exited)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-containers-after-stopping&#34;&gt;Delete containers after stopping&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker stop $(docker ps -aq) &amp;amp;&amp;amp; docker rm -v $(docker ps -aq)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-dangling-images&#34;&gt;Delete dangling images&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q -f dangling=true)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-all-images&#34;&gt;Delete all images&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-dangling-volumes&#34;&gt;Delete dangling volumes&lt;/h3&gt;

&lt;p&gt;As of Docker 1.9:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker volume rm $(docker volume ls -q -f dangling=true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In 1.9.0, the filter &lt;code&gt;dangling=false&lt;/code&gt; does &lt;em&gt;not&lt;/em&gt; work - it is ignored and will list all volumes.&lt;/p&gt;

&lt;h3 id=&#34;show-image-dependencies&#34;&gt;Show image dependencies&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker images -viz | dot -Tpng -o docker.png
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;df&#34;&gt;df&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker system df&lt;/code&gt; presents a summary of the space currently used by different docker objects.&lt;/p&gt;

&lt;h3 id=&#34;heredoc-docker-container&#34;&gt;Heredoc Docker Container&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;docker build -t htop - &amp;lt;&amp;lt; EOF
FROM alpine
RUN apk --no-cache add htop
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;prune&#34;&gt;Prune&lt;/h3&gt;

&lt;p&gt;The new &lt;a href=&#34;https://github.com/docker/docker/pull/26108&#34; target=&#34;_blank&#34;&gt;Data Management Commands&lt;/a&gt; have landed as of Docker 1.13:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;docker system prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker volume prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker network prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker container prune&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker image prune&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;last-ids&#34;&gt;Last Ids&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;alias dl=&#39;docker ps -l -q&#39;
docker run ubuntu echo hello world
docker commit $(dl) helloworld
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;commit&#34;&gt;Commit&lt;/h3&gt;

&lt;p&gt;with command (needs Dockerfile)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker commit -run=&#39;{&amp;quot;Cmd&amp;quot;:[&amp;quot;postgres&amp;quot;, &amp;quot;-too -many -opts&amp;quot;]}&#39; $(dl) postgres
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;monitoring&#34;&gt;Monitoring&lt;/h2&gt;

&lt;h3 id=&#34;monitor-system-resource-utilization-for-running-containers&#34;&gt;Monitor system resource utilization for running containers&lt;/h3&gt;

&lt;p&gt;To check the CPU, memory, and network I/O usage of a single container, you can use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats &amp;lt;container&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by id:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats $(docker ps -q)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by name:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker stats $(docker ps --format &#39;{{.Names}}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all containers listed by image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a -f ancestor=ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove all untagged images&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker rmi $(docker images | grep “^” | awk &#39;{split($0,a,&amp;quot; &amp;quot;); print a[3]}&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove container by a regular expression&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker ps -a | grep wildfly | awk &#39;{print $1}&#39; | xargs docker rm -f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove all exited containers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker rm -f $(docker ps -a | grep Exit | awk &#39;{ print $1 }&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;volumes-can-be-files&#34;&gt;Volumes can be files&lt;/h3&gt;

&lt;p&gt;Be aware that you can mount files as volumes. For example you can inject a configuration file like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# copy file from container
docker run --rm httpd cat /usr/local/apache2/conf/httpd.conf &amp;gt; httpd.conf

# edit file
vim httpd.conf

# start container with modified configuration
docker run --rm -ti -v &amp;quot;$PWD/httpd.conf:/usr/local/apache2/conf/httpd.conf:ro&amp;quot; -p &amp;quot;80:80&amp;quot; httpd
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;efficiency&#34;&gt;Efficiency&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cleaning &lt;code&gt;APT&lt;/code&gt; in a &lt;code&gt;RUN&lt;/code&gt; layer. &lt;em&gt;Note&lt;/em&gt; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:clean&#34;&gt;&lt;a href=&#34;#fn:clean&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN {apt commands} \
&amp;amp;&amp;amp; apt-get clean \
&amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Flatten an image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ID=$(docker run -d image-name /bin/bash)
docker export $ID | docker import – flat-image-name
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For backup&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ID=$(docker run -d image-name /bin/bash)
(docker export $ID | gzip -c &amp;gt; image.tgz)
gzip -dc image.tgz | docker import - flat-image-name
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h2&gt;

&lt;p&gt;This is where general Docker best practices and war stories go:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gregoryszorc.com/blog/2014/10/16/the-rabbit-hole-of-using-docker-in-automated-tests/&#34; target=&#34;_blank&#34;&gt;The Rabbit Hole of Using Docker in Automated Tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/bridgetkromhout&#34; target=&#34;_blank&#34;&gt;Bridget Kromhout&lt;/a&gt; has a useful blog post on &lt;a href=&#34;http://sysadvent.blogspot.co.uk/2014/12/day-1-docker-in-production-reality-not.html&#34; target=&#34;_blank&#34;&gt;running Docker in production&lt;/a&gt; (2014) at Dramafever.&lt;/li&gt;
&lt;li&gt;There&amp;rsquo;s also a best practices &lt;a href=&#34;http://developers.lyst.com/devops/2014/12/08/docker/&#34; target=&#34;_blank&#34;&gt;blog post&lt;/a&gt; (2014) from Lyst.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tersesystems.com/2013/11/20/building-a-development-environment-with-docker/&#34; target=&#34;_blank&#34;&gt;Building a Development Environment With Docker&lt;/a&gt; (2013)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://samsaffron.com/archive/2013/11/07/discourse-in-a-docker-container&#34; target=&#34;_blank&#34;&gt;Discourse in a Docker Container&lt;/a&gt; (2013)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:os-footnote&#34;&gt;In this tutorial, we will be using Linux since that is what almost every server runs, but as the principle of Docker is that it makes applications independent of platforms, everything herein should be applicable no matter what machine you are running.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:os-footnote&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:usergroup-caveats&#34;&gt;If testing on a virtual machine, it may be necessary to restart the virtual machine for changes to take effect. On a desktop Linux environment such as X Windows, log out of your session completely and then log back in.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:usergroup-caveats&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:linux-version&#34;&gt;Ubuntu 14.10 and below use &lt;code&gt;upstart&lt;/code&gt;. See the &lt;a href=&#34;https://docs.docker.com/install/linux/linux-postinstall/&#34; target=&#34;_blank&#34;&gt;post-installation&lt;/a&gt; instructions for support.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:linux-version&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:security&#34;&gt;For an understanding of what containers leave exposed, you should read &lt;a href=&#34;https://www.nccgroup.trust/globalassets/our-research/us/whitepapers/2016/april/ncc_group_understanding_hardening_linux_containers-1-1.pdf&#34; target=&#34;_blank&#34;&gt;Understanding and Hardening Linux Containers&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/dyn___&#34; target=&#34;_blank&#34;&gt;Aaron Grattafiori&lt;/a&gt;. This is a complete and comprehensive guide to the issues involved with containers, with a plethora of links and footnotes leading on to yet more useful content.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:security&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:begin&#34;&gt;You should start off by using a kernel with unstable patches for &lt;code&gt;grsecurity / pax&lt;/code&gt; compiled in, such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Alpine_Linux&#34; target=&#34;_blank&#34;&gt;Alpine Linux&lt;/a&gt;. If you are using &lt;code&gt;grsecurity&lt;/code&gt; in production, you should spring for &lt;a href=&#34;https://grsecurity.net/business_support.php&#34; target=&#34;_blank&#34;&gt;commercial support&lt;/a&gt; for the &lt;a href=&#34;https://grsecurity.net/announce.php&#34; target=&#34;_blank&#34;&gt;stable patches&lt;/a&gt;, same as you would do for RedHat. It&amp;rsquo;s $200 a month, which is nothing to your devops budget.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:begin&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:gist&#34;&gt;The gist was scraped and mildly edited on &lt;em&gt;12/22/18&lt;/em&gt;, so it may behoove you to check the original source for any updates. If you find typos/corrections/updates that should be included below, please &lt;a href=&#34;https://www.michaelpilosov.com/#contact&#34;&gt;get in touch&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:gist&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:clean&#34;&gt;This should be done in the same layer as other apt commands. Otherwise, the previous layers still persist the original information and your images will still be fat.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:clean&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>JupyterHub</title>
      <link>https://www.michaelpilosov.com/openscience/jupyterhub/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/jupyterhub/</guid>
      <description>

&lt;h1 id=&#34;the-end-user-experience&#34;&gt;The End-User Experience&lt;/h1&gt;

&lt;p&gt;You go to a web-address and are confronted with the Jupyterhub login portal.
Once you log in, you see a drop-down menu that allows you to choose what &amp;ldquo;stack&amp;rdquo; of software dependencies you would like to use.
After you make your selection, you are redirected to an in-browser interface where all your files are available.
Jupyter Notebooks, R Scripts, anything you want, can now be run directly through this interface.&lt;/p&gt;

&lt;p&gt;The work is performed &amp;ldquo;in the cloud.&amp;rdquo; What this means is that a connection is established between your browser window (the client) and a server (the host) elsewhere that is capable of performing the calculations you need.&lt;/p&gt;

&lt;h2 id=&#34;benefits&#34;&gt;Benefits&lt;/h2&gt;

&lt;p&gt;You do not have to worry about installing software dependencies, since the administrator has already loaded them into the environment that you selected.
The machine you are working on will not be doing anything except communicating commands to the host and displaying the result, which means your computer will run on less energy.&lt;/p&gt;

&lt;p&gt;Moreover, it means that since &lt;em&gt;all you need is a functional internet browser,&lt;/em&gt; you can do all of your scientific work with a budget laptop (or in a pinch, a phone/tablet).
For academic institutions, this means that entire laboratories of computers can be re-purposed for better uses, since students will not be limited by the technology they can afford.&lt;/p&gt;

&lt;p&gt;If you are an administrative user, you can add other users through a control-panel available through this interface, and even be able to see when these users are logged in.
If configured by the system administrator who set all this up, you may also be able to start an environment &lt;em&gt;as&lt;/em&gt; any of these users, and look around their folders/files, perhaps as a teacher helping de-bug some code during remotely-held office hours.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sounds neat, doesn&amp;rsquo;t it?&lt;/em&gt;
Especially for academics, this lowering of friction to programming is especially appealing.
The hardest parts of setting up a class with the resources they need to start learning how to code have all been abstracted away for both the students and teachers who serve as administrators.
All of this is already possible, and there are &lt;em&gt;a lot&lt;/em&gt; of ways to set this exact thing up, which makes navigating how to do so a little difficult.
We will discuss this later after building up the proper motivation.&lt;/p&gt;

&lt;h2 id=&#34;application-architecture&#34;&gt;Application Architecture&lt;/h2&gt;

&lt;p&gt;This separation of where work is performed and where its results are shown is actually essential to understanding how most modern  &amp;ldquo;applications&amp;rdquo; are built.
By not burdening end-users with installation dependencies that vary with the technology they own, application developers avoid worrying about cross-platform support.
Most applications are now simply re-skinned versions of a browser called Chromium&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:chrome&#34;&gt;&lt;a href=&#34;#fn:chrome&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, which direct you to the company&amp;rsquo;s servers where all the work is performed.&lt;/p&gt;

&lt;p&gt;In this spirit, the Jupyter Project has done the same thing for scientists and programmers.
The open-source community that powers most of the work done by Jupyter is largely concentrated at UC Berkeley, and the adoption of their work is spreading fast across the world.
However, due to the rapid pace of development, a cohesive narrative that explains how all the technologies developed by the Jupyter Project are connected is hard to come by.
We attempt to address this problem with this document, stepping through the layers of abstraction and building up a story that helps develop an understanding of how these underlying technologies interface and the many ways in which they can be configured&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:config&#34;&gt;&lt;a href=&#34;#fn:config&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h1 id=&#34;jupyterhub&#34;&gt;Jupyterhub&lt;/h1&gt;

&lt;p&gt;The management of users and the environments they are able to use is done through the interface known as Jupyterhub (the &amp;ldquo;Hub&amp;rdquo; for short).
The Hub controls who is allowed to access a notebook server through an &lt;em&gt;Authenticator&lt;/em&gt;.
This can be a username/password combination, or a one-click login through a third-party such as Github, Gitlab, Google, Azure, or your university&amp;rsquo;s login page.&lt;/p&gt;

&lt;p&gt;Jupyterhub passes information to an Authenticator, which returns a &amp;ldquo;successful&amp;rdquo; (or not) message to the Hub, which (if successful) then performs some action.
In the example above, the action is performed was to first display a drop-down menu that allows a user to select an environment.
(This can be bypassed if you want every end-user to have the same environment).
Jupyterhub then &amp;ldquo;spawns&amp;rdquo; a &amp;ldquo;single-user (notebook) server&amp;rdquo; to establish the connection between computational resources and the user-facing interface through the browser&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:server&#34;&gt;&lt;a href=&#34;#fn:server&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
The Hub launches such a server for each user that successfully logs in.&lt;/p&gt;

&lt;p&gt;Jupyterhub is thus made up of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An Authenticator (that lets people in or keeps them out),&lt;/li&gt;
&lt;li&gt;a Spawner (which defines individual environments),&lt;/li&gt;
&lt;li&gt;a Database (to store users), and&lt;/li&gt;
&lt;li&gt;a Server (to connect all of it).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker/raw/master/internal/jupyterhub-docker.png&#34; alt=&#34;schematic&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;notebook-server&#34;&gt;Notebook Server&lt;/h2&gt;

&lt;p&gt;At the heart of the system is the Jupyter Notebook (server).
The notebook server communicates with the relevant processes on the host machine to carry out the computations that you (the client) asked it to perform through your browser interface.
The machine running the notebook server has all the necessary dependencies to perform the work, and your end-user experienced is managed through the Jupyter notebook server.&lt;/p&gt;

&lt;p&gt;The native file-format for the interface the notebook server is the &amp;ldquo;interactive notebook&amp;rdquo; (which has the &lt;code&gt;.ipynb&lt;/code&gt; ending).
All that these notebooks are is a collection of key-value pairs (dictionaries, linked lists, many words exist), each of which corresponds to one &amp;ldquo;cell&amp;rdquo; in the notebook and carries input/output information along with formatting specifications.
Since it is best to see by example, here is an abstraction of what this looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&amp;quot;cell_1&amp;quot;: {info} }
{&amp;quot;cell_2&amp;quot;: {info} }
{&amp;quot;cell_3&amp;quot;: {info} }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where each one of these &lt;code&gt;{info}&lt;/code&gt; elements corresponds to a dictionary itself, which might look something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{&amp;quot;input&amp;quot;: &amp;lt;&amp;gt;, 
 &amp;quot;output&amp;quot;: &amp;lt;&amp;gt;,
 &amp;quot;execution_count&amp;quot;: &amp;lt;&amp;gt;, 
 &amp;quot;kernel&amp;quot;: &amp;lt;&amp;gt;, ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of this information is used to format an HTML page that is then rendered by a browser of your choice, since at this point it is simply a web page.&lt;/p&gt;

&lt;p&gt;Now, it is important to note at this time that if you are using a computer that has all the required software dependencies you need, then you can become the &amp;ldquo;host&amp;rdquo; yourself, and run the notebook server locally.
In the event that you do this, the website you visit to see the notebook server file-browsing interface and work with notebooks will look something like &lt;code&gt;http://localhost:8000&lt;/code&gt;, where &lt;code&gt;localhost&lt;/code&gt; is telling your browser that &amp;hellip; well, the host is &lt;em&gt;local&lt;/em&gt;, not somewhere &lt;em&gt;remote&lt;/em&gt;&amp;hellip;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:web&#34;&gt;&lt;a href=&#34;#fn:web&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.
The &lt;code&gt;:8000&lt;/code&gt; (the number can differ) is the &lt;em&gt;port&lt;/em&gt; that is being opened on the machine to allow for input/output connections, which is what is handled by the server.
&lt;em&gt;(Remember this&amp;hellip; it&amp;rsquo;ll come up later).&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;An Analogy&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If the website is considered the &amp;ldquo;address&amp;rdquo; of the machine(s), the port is the &amp;ldquo;apartment number.&amp;rdquo;
Many &amp;ldquo;tenants&amp;rdquo; (applications) can &amp;ldquo;live&amp;rdquo; (be hosted) at the same &amp;ldquo;address&amp;rdquo; (website).
Some buildings choose to have a doorman, so you can ask for directions to the right place &lt;em&gt;by name&lt;/em&gt; instead of apartment number.
So if you do not see a port number (&lt;code&gt;:XXXX&lt;/code&gt;) anywhere in the browser address, you can assume that the configuration implemented has a &amp;ldquo;doorman&amp;rdquo; (proxy) directing traffic to the right places.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This about sums up what you need to know about the notebook server.
&lt;em&gt;Somewhere there exists a machine that can do what you want.
By running a notebook server on this machine, you can connect to it through a web-browser.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;spawning&#34;&gt;Spawning&lt;/h2&gt;

&lt;p&gt;There are many ways to start the (single-user) notebook servers.
They can be started as individual processes on the same machine that the Hub is running on, which is the default behavior, and the implementation used in &lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub&#34; target=&#34;_blank&#34;&gt;The Littlest Jupyterhub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;However, in the spirit of modularity, they can also be started on machines elsewhere in the world.
These machines may be set up with all the dependencies, waiting for authenticated connections from Hub, or they can be created (and destroyed) &lt;em&gt;on-demand.&lt;/em&gt;
They can be physical machines, or &amp;ldquo;virtual machines,&amp;rdquo; which (as the name suggests) are emulations of computers that run as processes on top of some existing architecture.&lt;/p&gt;

&lt;h3 id=&#34;containerization&#34;&gt;Containerization&lt;/h3&gt;

&lt;p&gt;Virtual machines allow for something called &amp;ldquo;containerization,&amp;rdquo; which isolated applications in (usually Linux) virtual environments that contain little else but the bare necessities for running a given application.&lt;/p&gt;

&lt;p&gt;To scale to millions of users, services exist that allow for the creation and destruction of virtual machines on-demand, with low latency, and pricing computed by the second.
Such services sit atop a software platform called Kubernetes, and require a decent amount of technical experience to configure.
Jupyterhub can be configured to &amp;ldquo;spawn&amp;rdquo; single-user notebook servers through such a service using an extension called &amp;ldquo;Kubespawner.&amp;rdquo;
However, we do not provide any more information about this herein because the wiki for Jupyterhub is written specifically for this implementation case.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We focus on a solution that is capable of scaling to hundreds of users and can be built with existing server resources that a department may have that are underutilized, but is a little more technically challenging to implement than &lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub&#34; target=&#34;_blank&#34;&gt;The Littlest Jupyterhub&lt;/a&gt;, which basically functions as a one-click install and provides its own set of configuration scripts.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;docker&#34;&gt;Docker&lt;/h3&gt;

&lt;p&gt;A simpler solution though, can be achieved through &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker&#34;&gt;Docker&lt;/a&gt;, which (although it has a learning curve), is capable of scaling to very large workloads and can be configured to connect multiple servers and balance traffic amongst them.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We choose to run Jupyterhub within a Docker container, the Database in another container, and then spawn single-user notebook servers each in isolated containers as well.
The latter containers are ephemeral, which means that once a user shuts down their single-user server (or it is shut down due to inactivity after a predetermined amount of time), the container is destroyed.
Containerizing every aspect of this project allows for a really simple deployment scenario, which we walk through on the &lt;a href=&#34;https://www.michaelpilosov.com/openscience/deploy&#34;&gt;Deployment&lt;/a&gt; page.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can &amp;ldquo;containerize&amp;rdquo; the environments we want our users to experience in their single-user notebook servers through the use of a &amp;ldquo;Dockerfile,&amp;rdquo; which simply lists a set of instructions to configure a brand-new Ubuntu (Linux distribution) machine to handle all the dependencies.&lt;/p&gt;

&lt;p&gt;The single-user notebook servers can be launched from a choice of &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker/#images&#34;&gt;&amp;ldquo;images,&amp;rdquo;&lt;/a&gt; which define the containers that are created/destroyed on-demand.&lt;/p&gt;

&lt;p&gt;In this way, our applications are &amp;ldquo;stateless,&amp;rdquo; which means that all the information (files, data, configuration) is connected to the application virtually (Docker handles these connections through something called &lt;a href=&#34;https://www.michaelpilosov.com/openscience/docker#volumes&#34;&gt;&amp;ldquo;volumes&amp;rdquo;&lt;/a&gt;.
So, if properly configured, &lt;em&gt;a student can launch any environment they want and still see the same set of files.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;database&#34;&gt;Database&lt;/h2&gt;

&lt;p&gt;A basic SQL database comes prepackaged and configured with Jupyterhub, but for &amp;ldquo;production&amp;rdquo; purposes, the developers in the Jupyter Project advise using a more resilient database such as PostgresDB, which is the solution we implemented, following the &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub-deploy-docker&#34; target=&#34;_blank&#34;&gt;Deployment Example&lt;/a&gt; provided by Jupyter.&lt;/p&gt;

&lt;p&gt;This postgres database will exist inside its own container and be connected to an external volume (managed by Docker), so that we can create/destroy the Hub and not lose any of our user data.&lt;/p&gt;

&lt;h2 id=&#34;authenticator&#34;&gt;Authenticator&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/jupyterhub/jupyterhub/wiki/Authenticators&#34; target=&#34;_blank&#34;&gt;Wiki&lt;/a&gt; has a list of authenticator options.
The default behavior is to check the system users on the machine running Jupyterhub.
In the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file which is used to set up the Hub, a &lt;code&gt;whitelist&lt;/code&gt; and &lt;code&gt;admins&lt;/code&gt; attribute are defined to control who is allowed in.
If inside a container, this means that users must be created inside of there!
The nice thing about using an authentication service such as OAuth is that it simplifies the login entirely, since accounts exist on other platforms to verify users.
The downside is that you must own a &amp;ldquo;fully qualified domain name&amp;rdquo; in order to do this, which means you must own the website (can be as low as $2-10/year, available via &lt;a href=&#34;https://namecheap.com or similar provider&#34; target=&#34;_blank&#34;&gt;Namecheap&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;p&gt;As mentioned in the analogy in &lt;a href=&#34;./#notebook-server&#34;&gt;earlier sections&lt;/a&gt;, the &amp;ldquo;doorman&amp;rdquo; that directs traffic around is the component of this application known as the &amp;ldquo;proxy&amp;rdquo;, and is the last part left in securing and configuring your server.&lt;/p&gt;

&lt;h2 id=&#34;volumes&#34;&gt;Volumes&lt;/h2&gt;

&lt;p&gt;Files and folders, as mentioned, persist on the machine that is hosting the application, and can even be configured (e.g., with symbolic links), to connect to file-servers elsewhere.
My university, for example, has a system for all of us to be able to store files on a remote server, and we can &amp;ldquo;mount&amp;rdquo; these connections appropriately by configuring Jupyterhub so that students can more readily access such resources.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:chrome&#34;&gt;which serves as the backbone for Google Chrome.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:chrome&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:config&#34;&gt;We note that the reason that there are so many possible ways to set up such a system is because the developers ensured the modularity of all the application components. There is a lot of segmentation that allows for this technology to scale to thousands of users. The lessons learned by mobile developers about scaling in popularity have all been implemented here.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:config&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:server&#34;&gt;The distinction is made for (single-user) servers since Jupyterhub itself is a server communicating with other applications/servers.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:server&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:web&#34;&gt;I suppose this would be a good time to mention that any website you visit is simply an alias for an &amp;ldquo;address&amp;rdquo; to some other computer elsewhere in the world. The address system used on the internet is known as the &amp;ldquo;IP address&amp;rdquo;, so the &lt;code&gt;localhost&lt;/code&gt; is telling the browser to look for a connection on the same machine.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:web&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Open Science: Working towards reproducibility</title>
      <link>https://www.michaelpilosov.com/devlog/openscience/</link>
      <pubDate>Sat, 22 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/openscience/</guid>
      <description>

&lt;h1 id=&#34;jan-1-2019&#34;&gt;Jan 1, 2019&lt;/h1&gt;

&lt;p&gt;Today I split up the documentation here on devlog and began the write-ups for Jupyterhub.
I think I should segment out a section that goes through the entire process of deployment&lt;/p&gt;

&lt;p&gt;Notes:
- bash script to give you nice shortcuts
- SSH key generated ahead of time, ready to log in without passwords
- get Traefik proxy working
    - It seems extremely straightforward except that I do not know how to direct traffic to a folder. I suppose that since it is running port-mappings, I could have an nginx server&lt;/p&gt;

&lt;p&gt;This is helpful, but it&amp;rsquo;s not using docker.
&lt;a href=&#34;https://github.com/jupyterhub/the-littlest-jupyterhub/tree/master/tljh&#34; target=&#34;_blank&#34;&gt;https://github.com/jupyterhub/the-littlest-jupyterhub/tree/master/tljh&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;okay the only thing I&amp;rsquo;ve managed to set up correctly is nginx outside of docker. This is annoying.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 3 * * 1 certbot renew --pre-hook &amp;quot;service nginx stop&amp;quot; --post-hook &amp;quot;service nginx start&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;crontab for renewals.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hub.conf&lt;/code&gt; inside of &lt;code&gt;/etc/nginx/sites-enabled&lt;/code&gt; (to be mounted)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# top-level http config for websocket headers
# If Upgrade is defined, Connection = upgrade
# If Upgrade is empty, Connection = close
map $http_upgrade $connection_upgrade {
    default upgrade;
    &#39;&#39;      close;
}

# HTTP server to redirect all 80 traffic to SSL/HTTPS
server {
    listen 80;
    server_name hub.consistentbayes.com;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

# HTTPS server to handle JupyterHub
server {
    listen 443;
    ssl on;

    server_name hub.consistentbayes.com;

    ssl_certificate /etc/letsencrypt/live/consistentbayes.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/consistentbayes.com/privkey.pem;

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_dhparam /etc/ssl/certs/dhparam.pem;
    ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&#39;;
    
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    # Managing literal requests to the JupyterHub front end
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;whereas the website looks like &lt;code&gt;/etc/nginxsites-enabled/consistentbayes.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    server_name consistentbayes.com;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

server {
    listen 443;
    ssl on;

    # INSERT OTHER SSL PARAMETERS HERE AS ABOVE
    ssl_certificate /etc/letsencrypt/live/consistentbayes.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/consistentbayes.com/privkey.pem;

    # Set the appropriate root directory
    root /var/www/consistentbayes.com/public_html;

    # Set URI handling
    location / {
        try_files $uri $uri/ =404;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Traefik Problems&lt;/em&gt;
&lt;code&gt;netstat -ltnp | grep -w &#39;:80&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So far this is the easiest I&amp;rsquo;ve had it configuring the set-up.. with nginx. Talk to Joe about getting Traefik to work.
&lt;a href=&#34;https://blog.raveland.org/post/traefik_le/&#34; target=&#34;_blank&#34;&gt;https://blog.raveland.org/post/traefik_le/&lt;/a&gt;
maybe that will help???
&lt;a href=&#34;https://www.bennadel.com/blog/3420-obtaining-a-wildcard-ssl-certificate-from-letsencrypt-using-the-dns-challenge.htm&#34; target=&#34;_blank&#34;&gt;https://www.bennadel.com/blog/3420-obtaining-a-wildcard-ssl-certificate-from-letsencrypt-using-the-dns-challenge.htm&lt;/a&gt;
or that&amp;hellip; (it is important to note that you need to follow instructions after feb 18 due to letsencrypt changing something major).&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-2-2019&#34;&gt;Jan 2, 2019&lt;/h1&gt;

&lt;p&gt;Spent day configuring proxy. Succeeded eventually on my domain, but not with a reverse proxy. Just a regular one&amp;hellip;&lt;/p&gt;

&lt;p&gt;Messed around with apache but couldn&amp;rsquo;t make it work.
&lt;a href=&#34;https://jupyterhub.readthedocs.io/en/latest/reference/config-proxy.html&#34; target=&#34;_blank&#34;&gt;Documentation on Jupyter&amp;rsquo;s website is god awful&lt;/a&gt;, there are numerous omissions and a typo in the configuration files (including ones from the &lt;a href=&#34;https://github.com/jupyterhub/oauthenticator/tree/master/examples/full&#34; target=&#34;_blank&#34;&gt;repository&lt;/a&gt; I got my original setup files), no context or setup instructions. They just assume you know what you are doing.&lt;/p&gt;

&lt;p&gt;I do not, though. So let&amp;rsquo;s go through it.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s what a reverse-proxy is doing.
It catches requests to a website and handles them.&lt;/p&gt;

&lt;p&gt;When you hit &lt;a href=&#34;consistentbayes.com&#34; target=&#34;_blank&#34;&gt;consistentbayes.com&lt;/a&gt;, it directs you to a folder with a bunch of files that make up my website. I had that working with Apache but couldn&amp;rsquo;t do what I wanted, which was direct traffic to &amp;ldquo;hub.consistentbayes.com&amp;rdquo; instead.&lt;/p&gt;

&lt;p&gt;I got the &amp;ldquo;hub&amp;rdquo; part set up by adding an &lt;code&gt;A Record&lt;/code&gt; into my DNS Control Panel (talk more about that later). Now the proxy just had to be able to handle and direct that request to a jupyterhub instance running in a docker container that was exposing itself on &lt;code&gt;http://127.0.0.1:8000&lt;/code&gt; (I&amp;rsquo;ll show config files later). The hub would be in a container that is just a Linux machine, with users and everything in there.&lt;/p&gt;

&lt;p&gt;If the container name is &amp;ldquo;nostalgic_colden&amp;rdquo; (TO DO: figure out how to name these)&amp;hellip; then running&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker exec -ti -u mpilosov nostalgic_colden /bin/bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will log you into the linux computer as &amp;ldquo;mpilosov&amp;rdquo;&lt;/p&gt;

&lt;p&gt;The user accounts are handled at build-time, but can be managed within the computer just as you would on a linux machine (to log in as &lt;code&gt;root&lt;/code&gt;, omit &lt;code&gt;-u mpilosov&lt;/code&gt; above).&lt;/p&gt;

&lt;p&gt;So&amp;hellip; those accounts.
Github usernames. By far the best authentication method I found, but it relied on having a Fully Qualified Domain Name (website name, which the server at school would not let me do).
But&amp;hellip; we can loop the authenticator to whatever we want.&lt;/p&gt;

&lt;p&gt;Here are my nginx configurations:&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;/etc/nginx/sites-enabled/consistentbayes.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    server_name NO_HUB.DOMAIN.TLD;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

server {
    listen 443;
    ssl on;

    # INSERT OTHER SSL PARAMETERS HERE AS ABOVE
    # SSL cert may differ

    # Set the appropriate root directory
    root /var/www/html;

    # Set URI handling
    location / {
        try_files $uri $uri/ =404;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In &lt;code&gt;/etc/nginx/sites-enabled/jupyterhub.conf&lt;/code&gt; (titles dont matter it seems).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# top-level http config for websocket headers
# If Upgrade is defined, Connection = upgrade
# If Upgrade is empty, Connection = close
map $http_upgrade $connection_upgrade {
    default upgrade;
    &#39;&#39;      close;
}

# HTTP server to redirect all 80 traffic to SSL/HTTPS
server {
    listen 80;
    server_name HUB.DOMAIN.TLD;

    # Tell all requests to port 80 to be 302 redirected to HTTPS
    return 302 https://$host$request_uri;
}

# HTTPS server to handle JupyterHub
server {
    listen 443;
    ssl on;

    server_name HUB.DOMAIN.TLD;

    ssl_certificate /etc/letsencrypt/live/HUB.DOMAIN.TLD/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/HUB.DOMAIN.TLD/privkey.pem;

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    ssl_dhparam /etc/ssl/certs/dhparam.pem;
    ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA&#39;;
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_stapling on;
    ssl_stapling_verify on;
    add_header Strict-Transport-Security max-age=15768000;

    # Managing literal requests to the JupyterHub front end
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        # websocket headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
    }

    # Managing requests to verify letsencrypt host
    location ~ /.well-known {
        allow all;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Talk about how you had to generate letsencrypt scripts for nginx with &lt;code&gt;certbot&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install python-certbot-nginx
sudo apt-get update
sudo apt-get install software-properties-common
sudo add-apt-repository universe
sudo add-apt-repository ppa:certbot/certbot
sudo apt-get update
sudo apt-get install python-certbot-nginx 
sudo certbot --nginx certonly
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I actually ran into trouble being unable to start nginx with the sites enabled. Kind of a catch-22. Removed letsencrypt files&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo certbot certonly --webroot -w /var/www/example -d example.com -d www.example.com -w /var/www/thing -d thing.is -d m.thing.is
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will obtain a single cert for example.com, www.example.com, thing.is, and m.thing.is; it will place files below /var/www/example to prove control of the first two domains, and under /var/www/thing for the second pair.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I dont quite want that. Let&amp;rsquo;s try the interactive.;&lt;/em&gt;
&lt;code&gt;sudo certbot certonly&lt;/code&gt;
Hit 1, enter website names (consistentbayes.com, www.consistentbayes.com),&lt;/p&gt;

&lt;p&gt;Then do the same again for the hub.consistentbayes.com&lt;/p&gt;

&lt;p&gt;And we&amp;rsquo;re golden. The files have been placed where nginx is expecting them to be. (e.g. &lt;code&gt;/etc/letsencrypt/live/hub.consistentbayes.com/fullchain.pem&lt;/code&gt;)&lt;/p&gt;

&lt;p&gt;And also you will need to issue the following command once.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl dhparam -out /etc/ssl/certs/dhparam.pem 4096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then go ahead and make the &lt;code&gt;Dockerfile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Designed to be run as
#
# docker run -it -p 8000:8000 jupyterhub/oauthenticator

FROM jupyterhub/jupyterhub

MAINTAINER Project Jupyter &amp;lt;ipython-dev@scipy.org&amp;gt;

# Install oauthenticator from git
RUN python3 -m pip install oauthenticator
RUN python3 -m pip install notebook&amp;gt;=4.0
# Create oauthenticator directory and put necessary files in it
RUN mkdir /srv/oauthenticator
WORKDIR /srv/oauthenticator
ENV OAUTHENTICATOR_DIR /srv/oauthenticator
ADD jupyterhub_config.py jupyterhub_config.py
ADD addusers.sh /srv/oauthenticator/addusers.sh
ADD userlist /srv/oauthenticator/userlist
ADD ssl /srv/oauthenticator/ssl
RUN chmod 700 /srv/oauthenticator

RUN [&amp;quot;sh&amp;quot;, &amp;quot;/srv/oauthenticator/addusers.sh&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then this bash script &lt;code&gt;addusers.sh&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh

IFS=&amp;quot;
&amp;quot;
for line in `cat userlist`; do
  test -z &amp;quot;$line&amp;quot; &amp;amp;&amp;amp; continue
  user=`echo $line | cut -f 1 -d&#39; &#39;`
  echo &amp;quot;adding user $user&amp;quot;
  useradd -m -s /bin/bash $user
#  cp -r /srv/ipython/examples /home/$user/examples
  mkdir /home/$user/examples
# may only be necessary since we are copying files from root above.
  chown -R $user /home/$user/examples
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And, for now, the simplest version of our &lt;code&gt;jupyterhub_config.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Configuration file for Jupyter Hub

c = get_config()

c.JupyterHub.log_level = 10
from oauthenticator.github import LocalGitHubOAuthenticator
c.JupyterHub.authenticator_class = LocalGitHubOAuthenticator
c.GenericOAuthenticator.login_service = &#39;my service&#39;

c.LocalGitHubOAuthenticator.create_system_users = True

c.Authenticator.whitelist = whitelist = set()
c.JupyterHub.admin_users = admin = set()

import os
import sys

join = os.path.join

here = os.path.dirname(__file__)
root = os.environ.get(&#39;OAUTHENTICATOR_DIR&#39;, here)
sys.path.insert(0, root)

with open(join(root, &#39;userlist&#39;)) as f:
    for line in f:
        if not line:
            continue
        parts = line.split()
        name = parts[0]
        whitelist.add(name)
        if len(parts) &amp;gt; 1 and parts[1] == &#39;admin&#39;:
            admin.add(name)

c.GitHubOAuthenticator.oauth_callback_url = os.environ[&#39;OAUTH_CALLBACK_URL&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;userlist&lt;/code&gt; file with github usernames&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:admin&#34;&gt;&lt;a href=&#34;#fn:admin&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mpilosov admin
mathematicalmichael
eescu 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A &lt;code&gt;ssl&lt;/code&gt; folder with encryption keys in them (which we won&amp;rsquo;t use!)
(We don&amp;rsquo;t use them because we expose Jupyterhub in http, and use the reverse-proxy to handle the security).&lt;/p&gt;

&lt;p&gt;And an &lt;code&gt;env&lt;/code&gt; file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# add your github oauth config to this file,
# and run the container with `docker run -it -p 9000:8000 --env-file=env jupyterhub-oauth`
OAUTH_CLIENT_ID=
OAUTH_CLIENT_SECRET=
OAUTH_CALLBACK_URL=https://hub.consistentbayes.com/hub/oauth_callback
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which you get when you register the application on Github. (I filled in the third to show you, the first two are secrets!)&lt;/p&gt;

&lt;p&gt;So from here on, we can start tweaking the spawner, volume persistence, do checks on memory limits, etc. Write up detailed instructions. Jupyterhub from docker like this is nice.&lt;/p&gt;

&lt;p&gt;I think we can test directory-mounting right to the linux machine to be honest.&lt;/p&gt;

&lt;p&gt;OMG I RAN THIS AND IT WORKED. I mounted volumes to folders on a per-user basis (since users live inside the container that jupyterhub is in). No write permissions, but they can see files just fine. Cant duplicate.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -it -p 8000:8000 -v /home/michael/repos/:/home/mathematicalmichael/examples -v /home/michael/repos:/home/mpilosov/examples --env-file=env --name hubtest jupyterhub-oauth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Problem with relying on user data in the hub is potential updates could cause loss of files. mounting volumes would fix this for sure. But they can&amp;rsquo;t write files in this new directory, so&amp;hellip;&lt;/p&gt;

&lt;p&gt;I think the best storage solution is each student has their own container. &lt;code&gt;hubname-studentname&lt;/code&gt; that a teacher can get into. For workshops, the solution presented as-is works great.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make sure to upgrade pip, no one seems to.&lt;/li&gt;
&lt;li&gt;volume permissions are probably things joe knows about.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;volumes-working&#34;&gt;VOLUMES WORKING!&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;--mount&lt;/code&gt; creates directories if they dont exist, whereas &lt;code&gt;--volume&lt;/code&gt; does not. Good to create up at root one &lt;code&gt;/shared&lt;/code&gt; directory. Additionally we can link them to volumes to host their data instead, managed via docker. Ideally we use a mix of the two.
Adding a volume (even if it doesn&amp;rsquo;t exist) to be managed by docker would be accomplished with -v &lt;code&gt;volume-name:/directory/to/mount&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So we should think about what in our docker-compose we can automatically mount. Additionally (or in replacement), volumes can be handled via the spawner.&lt;/p&gt;

&lt;p&gt;In either set up, we can shut down and restart the container all we want and data persists. We can even re-build the image. Volumes seem to just be symbolic links to directories on your unix machine, anyway, visible via &lt;code&gt;docker inspect volume-name&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d -it -p 8000:8000 --mount source=/home/michael/repos/packages/lyricalart,type=bind,target=/home/mpilosov/examples/shared-folder-mp/,bind-propagation=rshared --mount source=/home/michael/repos/packages/lyricalart,type=bind,target=/home/mathematicalmichael/shared-folder-mm/,bind-propagation=rshared --env-file=env --name hub jupyterhub-oauth
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we&amp;rsquo;ve got this figured out&amp;hellip; It would be nice to figure out how to get that &lt;code&gt;docker-compose&lt;/code&gt; up and running, including with the nginx server, all based on a configuration file that takes in the website name, ip of host, etc. so you can get in, git clone, run bash script, edit the ip, and close out knowing it will work.&lt;/p&gt;

&lt;p&gt;To build everything, we did &lt;code&gt;docker build -t jupyterhub-oauth .&lt;/code&gt; in the directory we set up.&lt;/p&gt;

&lt;p&gt;Definitely want to containerize each student. Currently it&amp;rsquo;s possible to get into the directories mounted above as shared by going through Terminal. Can move files in/out&amp;hellip; not good.&lt;/p&gt;

&lt;p&gt;To destroy containers after they close down, simply add &lt;code&gt;.remove = True&lt;/code&gt; to the &lt;code&gt;c.DockerSpawner&lt;/code&gt; attributes.&lt;/p&gt;

&lt;p&gt;[8:59 PM] Pilosov, Michael
oficially did it on hub.consistentbayes.com! holy shit that took forever but I linked up the pieces. Now it spawns up containers per user, with BOTH volumes that persist even as containers change and shared directories accessible by all users, automatically mounted to every user.
One environment file controls everything. the version of jupyterhub, the docker image you want to spawn, etc.
​
[9:04 PM] Pilosov, Michael
that is our ideal set up.. the shared folders can be determined by rules such as group membership (students within class or even, and the environment to spawn can be similarly chosen. This means we can use one hub for every student across every class with total ease. No containers stick around. At all. They just get appropriately mounted to volumes when they are created. the decision to make one hub per class is purely an aesthetic one. the hub can spin up dozens of different configurations depending on what the user needs.
I&amp;rsquo;m going to package this all nice so that I can deploy to a powerful server that I can rent for like &amp;hellip;. a couple hours for testing. Throw a whole bunch of simultaneous use-cases at it.
​
[9:08 PM] Pilosov, Michael
we can even use the admin panel to start/stop servers instead of logging in simultaneously. if each single-user server has a heavy python script to run on startup, we can simulate heavy loads. I played around a little already and saw the containers being created (not restarted, created!) when I &amp;ldquo;started&amp;rdquo; the single-user server and then thrown away when I clicked &amp;ldquo;stop&amp;rdquo; which keeps our physical memory literally AT THE LOWEST possible limit at any given time since stopped containers dont have to sit around.&lt;/p&gt;

&lt;p&gt;So, how?&lt;/p&gt;

&lt;p&gt;I cloned the jupyterhub-deploy-docker repo. (again), and made my fixes&amp;hellip;&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know why the Makefile doesn&amp;rsquo;t handle this, but
&lt;code&gt;echo &amp;quot;POSTGRES_PASSWORD=$( openssl rand -hex 32)&amp;quot; &amp;gt;&amp;gt; secrets/postgres.env&lt;/code&gt; will create a necessary file for &lt;code&gt;make build&lt;/code&gt; to work. And after that works, run &lt;code&gt;make notebook_image&lt;/code&gt; to create the necessary image to be spawned based on the  &lt;code&gt;.env&lt;/code&gt; file in the root directory.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note from 1/8/2019:&lt;/em&gt; Just run &lt;code&gt;make secrets/postgres.env&lt;/code&gt; or whatever other file it needs, and it will create and set permissions. If it doesn&amp;rsquo;t create the file, then simply add it with &lt;code&gt;touch&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I commented out lines 40-49 in the &lt;code&gt;Makefile&lt;/code&gt; since I want to handle certification on my own through the reverse proxy.&lt;/p&gt;

&lt;p&gt;Would be nice to get this working with nginx as well. But all that stuff can be handled from the bash script.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;jupyterhub_config.py&lt;/code&gt; file, I removed references to SSL and set up shared volumes.
It would be great to learn how to sub-class the spawner now and create rules for mounting volumes. A simple restart lets students gain new files.&lt;/p&gt;

&lt;p&gt;I also removed SSL references from &lt;code&gt;Dockerfile.jupyerhub&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/compose/compose-file/&#34; target=&#34;_blank&#34;&gt;Docker-compose guidelines&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Just tested the containerized solution and love it (even though i built small containers). I can log in, add nbextensions as root, and the changes are reflected &lt;em&gt;without touching docker&lt;/em&gt;. No restarting required.&lt;/p&gt;

&lt;p&gt;Can add user accounts as admin through the cPanel. If they don&amp;rsquo;t exist, a home directory or volume is created on their behalf.
I wouldn&amp;rsquo;t suggest sharing directories automatically for the containerized solutions. &lt;em&gt;That part&lt;/em&gt; should be part of a custom spawner (and require hub restart, which can also be done through cpanel since it runs on another port!).&lt;/p&gt;

&lt;p&gt;Admin is powerful! You can start/stop servers at your whim and launch them to poke around on your own. Very cool.&lt;/p&gt;

&lt;p&gt;For a smaller class, auto-mounting some shared directory is a great idea.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jan-5-2019&#34;&gt;Jan 5, 2019&lt;/h1&gt;

&lt;p&gt;To get a bash script for the set-up, you need to package the reverse-proxy with docker-compose. Let&amp;rsquo;s figure out how to use Traefik. Between these two sources, you should be able to figure it out:
&lt;a href=&#34;https://github.com/defeo/jupyterhub-docker/blob/master/docker-compose.yml&#34; target=&#34;_blank&#34;&gt;https://github.com/defeo/jupyterhub-docker/blob/master/docker-compose.yml&lt;/a&gt;
&lt;a href=&#34;https://github.com/containous/traefik/blob/master/examples/quickstart/docker-compose.yml&#34; target=&#34;_blank&#34;&gt;https://github.com/containous/traefik/blob/master/examples/quickstart/docker-compose.yml&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:admin&#34;&gt;Fun note, it may be possible to accidentally revoke admin privileges from everyone. &lt;em&gt;Test this&lt;/em&gt;. But editing the config file in the container as root should be able to make it work again.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:admin&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Remote Connection</title>
      <link>https://www.michaelpilosov.com/openscience/remote/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/remote/</guid>
      <description>

&lt;p&gt;As previously mentioned, the Jupyter Notebook runs in the client (browser) and connects to a server (either running locally or remotely) to perform necessary calculations in a given language.&lt;/p&gt;

&lt;p&gt;The kernels provide the means for establishing this communication, and are effectively what &lt;code&gt;jupyter&lt;/code&gt; (the program) is set up to manage.&lt;/p&gt;

&lt;p&gt;Here, we demonstrate why this approach is so valuable.&lt;/p&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;Assuming you followed the instructions in &lt;a href=&#34;https://www.michaelpilosov.com/openscience/anaconda&#34;&gt;Installing Anaconda&lt;/a&gt; on your local machine, you&amp;rsquo;ll notice that you establish a connection to the server (running in your Terminal session, likely outputting information with green-highlighted time-stamps) through the &amp;ldquo;address&amp;rdquo; &lt;code&gt;localhost&lt;/code&gt;, which references the fact that you are running this server locally.&lt;/p&gt;

&lt;p&gt;However, this means that you can follow those instructions on any server, and with some additional commands (which we will review here), have the ability to connect to your Jupyter session from anywhere!&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:remote&#34;&gt;&lt;a href=&#34;#fn:remote&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;There are a few situations you might find yourself in, and we attempt to address several common ones here.
If there is a scenario that is not covered here that you would like us to write about, please &lt;a href=&#34;https://www.michaelpilosov.com/#contact&#34;&gt;contact us&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;server-on-campus&#34;&gt;Server on Campus&lt;/h1&gt;

&lt;h1 id=&#34;rented-server&#34;&gt;Rented Server&lt;/h1&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:remote&#34;&gt;Provided the machine running Jupyter is one that is publicly accessible. More on that later.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:remote&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Demonstration with Jupyter Lab</title>
      <link>https://www.michaelpilosov.com/openscience/demo/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/demo/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s first get a feel for the possibilities, and &lt;strong&gt;see&lt;/strong&gt; what is possible by checking out some existing websites, organizations, and repositories.
The idea of removing installation complexities, platform dependencies, etc. from your end-users is beautifully demonstrated by some of the recent advancements made over at &lt;a href=&#34;https://jupyter.org&#34; target=&#34;_blank&#34;&gt;Project Jupyter&lt;/a&gt;, all visible on &lt;a href=&#34;https://github.com/jupyter/&#34; target=&#34;_blank&#34;&gt;their Github repository&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My favorite example that demonstrates how slick this new approach to setting up programming environmnents is the repository demonstration with &lt;a href=&#34;https://github.com/binder-examples/jupyterlab&#34; target=&#34;_blank&#34;&gt;JupyterLab + Binder&lt;/a&gt; from the &lt;code&gt;binder-examples&lt;/code&gt; repository collection.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It even has an interactive map!!!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Head on over there, click on the little badge that reads &amp;ldquo;launch | binder,&amp;rdquo; and it will automatically open up a notebook for you.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:timeout&#34;&gt;&lt;a href=&#34;#fn:timeout&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
Have a look around, run code, do whatever you like.&lt;/p&gt;

&lt;p&gt;To then see how easy adding functionality is, run the following in a new code-cell in the notebook that opens:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!jupyter labextension install @jupyter-widgets/jupyterlab-manager 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The exclamation point tells the notebook to run the command using &lt;code&gt;bash.&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:bash&#34;&gt;&lt;a href=&#34;#fn:bash&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
Since widgets are already pre-packaged, all we have to do to enable them is to tell JupyterLab to get the necessary Javascript resources to show them to you in your client (web-browser).
A bunch of dialogue should show up, and then once it finishes, replace the code you just ran with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import ipywidgets as wd
wd.FloatSlider()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and you should see a slider pop up.&lt;/p&gt;

&lt;p&gt;To avoid this step and ensure that the widget functionality is ready-to-go, one can fork the &lt;a href=&#34;https://github.com/binder-examples/jupyterlab&#34; target=&#34;_blank&#34;&gt;repository&lt;/a&gt;, and edit the file &lt;code&gt;binder/postBuild&lt;/code&gt;, which runs after the initial repository is built (using &lt;a href=&#34;https://github.com/jupyter/repo2docker&#34; target=&#34;_blank&#34;&gt;repo2docker&lt;/a&gt; on the backend) but before the client displays the interface.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:timeout&#34;&gt;&lt;em&gt;Be warned&lt;/em&gt;: After a few minutes of inactivity, the &lt;a href=&#34;https://mybinder.org&#34; target=&#34;_blank&#34;&gt;mybinder.org&lt;/a&gt; service that is hosting the docker container which serves this web application will time-out. This means that it will assume you are done with it and clean up the resources it created for you. Say goodbye to whatever you were working on.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:timeout&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:bash&#34;&gt;Alternatively, you could open a new Terminal instance in JupyterLab and run the same code (without the exclamation mark).
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:bash&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Examples of Existing Projects</title>
      <link>https://www.michaelpilosov.com/openscience/example/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/example/</guid>
      <description>&lt;p&gt;There are a number of organizations with deployments you can experiment with.&lt;/p&gt;

&lt;p&gt;We list some of them here, along with useful links for more information (some of these may be turned into future pages).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Installing Anaconda</title>
      <link>https://www.michaelpilosov.com/openscience/anaconda/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/anaconda/</guid>
      <description>

&lt;p&gt;These instructions originally appeared on the &lt;a href=&#34;https://www.mathematicalmichael.com&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Resources&amp;rdquo; page of my website&lt;/a&gt;, where I link to my &lt;a href=&#34;https://gist.github.com/mpilosov/233ccfae58d182d43f690be209b58ba5&#34; target=&#34;_blank&#34;&gt;Github Gist&lt;/a&gt;.
As of &lt;em&gt;Dec 21, 2018&lt;/em&gt;, I am abandoning the aforementioned gist and will keep this webpage updated as my primary source of information for installing Anaconda&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:note&#34;&gt;&lt;a href=&#34;#fn:note&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h1 id=&#34;anaconda-basics&#34;&gt;Anaconda Basics&lt;/h1&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;It is a package manager.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;WRITE MORE ABOUT WHAT A PACKAGE MANAGER IS/DOES AND WHY IT SHOULD BE USED&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;download&#34;&gt;Download&lt;/h2&gt;

&lt;p&gt;Go download it from
&lt;a href=&#34;https://www.anaconda.com/download/&#34; target=&#34;_blank&#34;&gt;https://www.anaconda.com/download/&lt;/a&gt;
for your Linux/Windows/OSX&lt;/p&gt;

&lt;p&gt;I like to use&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget http://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;or if I want to keep things lightweight (may lead to more manual installations later on):&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;install&#34;&gt;Install&lt;/h2&gt;

&lt;p&gt;It will likely be saved in the Downloads folder, so you will install it with something like&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bash ~/Downloads/Anaconda3-5.0.1-Linux-x86_64.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Use all the defaults, agree to everything, and at the end, hit &lt;code&gt;ENTER&lt;/code&gt; to prepend it to your &lt;code&gt;PATH&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;environments&#34;&gt;Environments&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s create an environment for python3:&lt;br /&gt;
&lt;code&gt;conda create -n py3 python=3.6&lt;/code&gt; where &lt;code&gt;py3&lt;/code&gt; is just my personal preferred shorthand for python 3. Feel free to use your own.&lt;/p&gt;

&lt;p&gt;And one for python2:&lt;br /&gt;
&lt;code&gt;conda create -n py2 python=2.7&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To remove:&lt;br /&gt;
&lt;code&gt;conda remove --name py2 --all&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We can now switch between versions of python with commands like&lt;br /&gt;
&lt;code&gt;source activate py3&lt;/code&gt; and &lt;code&gt;source activate py2&lt;/code&gt; and then &lt;code&gt;source deactivate&lt;/code&gt; when you&amp;rsquo;re ready to be done.&lt;/p&gt;

&lt;h1 id=&#34;diving-deeper&#34;&gt;Diving Deeper&lt;/h1&gt;

&lt;h2 id=&#34;widgets&#34;&gt;Widgets&lt;/h2&gt;

&lt;p&gt;Overview:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pip install ipywidgets&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;jupyter nbextension install --py --user widgetsnbextension&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;jupyter nbextension enable --py widgetsnbextension&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;More information about widgets &lt;a href=&#34;https://ipywidgets.readthedocs.io/en/stable/user_install.html&#34; target=&#34;_blank&#34;&gt;can be found here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Alternatively, in each of these environments, run&lt;br /&gt;
&lt;code&gt;conda install -c conda-forge ipywidgets&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;which will install all sorts of dependencies, including Jupyter notebooks&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:notebooks&#34;&gt;&lt;a href=&#34;#fn:notebooks&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. It supposedly enables the widgets too but you can run&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jupyter nbextension enable --py widgetsnbextension&lt;/code&gt; to make sure.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;python -m ipykernel install --name py3 --user&lt;/code&gt; will then link the kernel to jupyter.&lt;/p&gt;

&lt;p&gt;Then &lt;code&gt;--name py3&lt;/code&gt; flag is optional and just assigns a name of your choosing to that kernel.
The version of python used for the kernel is whatever is returned when you ask bash &lt;code&gt;which python&lt;/code&gt; (so if you used source &lt;code&gt;activate&lt;/code&gt; earlier, it will be the version associated with the kernel whose name is in parentheses in your Terminal session).
&lt;strong&gt;The &lt;code&gt;--user&lt;/code&gt; flag is necessary.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;ipyparallel&#34;&gt;iPyParallel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ipython/ipyparallel&#34; target=&#34;_blank&#34;&gt;https://github.com/ipython/ipyparallel&lt;/a&gt;&lt;br /&gt;
&lt;code&gt;pip install ipyparallel&lt;/code&gt; to install.&lt;br /&gt;
&lt;code&gt;ipcluster nbextension enable&lt;/code&gt; (add the &lt;code&gt;--user&lt;/code&gt; flag as well if you encounter an error).
This one also seems to be necessary to get the clusters to show up:&lt;br /&gt;
&lt;code&gt;jupyter serverextension enable --sys-prefix --py ipyparallel&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To install for all users (as root):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jupyter nbextension install --sys-prefix --py ipyparallel
jupyter nbextension enable --sys-prefix --py ipyparallel
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;kernels&#34;&gt;Kernels&lt;/h1&gt;

&lt;h2 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;TODO: WRITE MORE ABOUT MULTI-KERNEL SUPPORT, provide an example.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;To see all the kernels jupyter is aware of:
&lt;code&gt;jupyter kernelspec list&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;management&#34;&gt;Management&lt;/h2&gt;

&lt;p&gt;To remove kernels, use &lt;code&gt;jupyter kernelspec remove&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jupyterhub&#34;&gt;JupyterHub&lt;/h1&gt;

&lt;h2 id=&#34;introduction-2&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;More information here about installation would be helpful, but we&amp;rsquo;ll be going through this in more detail at another time since JupyterHub will form the basis for the solutions we will use for our classroom environments.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;(for personal use)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyterhub.readthedocs.io/en/stable/getting-started/&#34; target=&#34;_blank&#34;&gt;Getting Started&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyter-notebook.readthedocs.io/en/latest/public_server.html&#34; target=&#34;_blank&#34;&gt;Running a notebook server&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jupyterlab&#34;&gt;JupyterLab&lt;/h1&gt;

&lt;h2 id=&#34;introduction-3&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;I love this environment but it is a little tricky to set up properly and get everything working as expected. Though once you do, I doubt you will want to use anything else.&lt;/p&gt;

&lt;h2 id=&#34;install-1&#34;&gt;Install&lt;/h2&gt;

&lt;p&gt;Once Jupyter Lab is installed, go ahead and run it the same way you would a notebook:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jupyter lab (--no-browser)&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;widget-extensions&#34;&gt;Widget Extensions&lt;/h2&gt;

&lt;p&gt;By default (as of Dec 2018), it will be accessible through &lt;code&gt;localhost:8888&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Go ahead and launch an instance of Python and see if widgets work.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import ipywidgets as wd
wd.FloatSlider()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the output of the following is text instead of a widget, try running the following in the command-line (shutdown the server with &lt;code&gt;Ctrl-C&lt;/code&gt; twice, then&lt;/p&gt;

&lt;p&gt;&lt;code&gt;jupyter labextension install @jupyter-widgets/jupyterlab-manager&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And relaunch JupyterLab (if you didn&amp;rsquo;t close your browswer window, a simple refresh will work to re-establish the connection and pick up where you left off), and try the example above again.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Something that came up once&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I saw my server output spitting out &lt;code&gt;TypeError: __init__() got an unexpected keyword argument &#39;io_loop&#39;&lt;/code&gt; over and over again when any kernel was started. Something was going on with the WebSocket I/O communication (whatever that means), but the following downgrade of the Python Web Framework worked to &lt;a href=&#34;https://stackoverflow.com/questions/48090119/jupyter-notebook-typeerror-init-got-an-unexpected-keyword-argument-io-l&#34; target=&#34;_blank&#34;&gt;fix it&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pip install tornado==4.5.3&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;sharing&#34;&gt;Sharing&lt;/h1&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;TODO&lt;/code&gt; write about why this is useful&lt;/p&gt;

&lt;h2 id=&#34;exporting&#34;&gt;Exporting&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;conda env export &amp;gt; environment.yml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Which you then load up with
&lt;code&gt;conda env create -f environment.yml&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;cloning&#34;&gt;Cloning&lt;/h2&gt;

&lt;p&gt;You can make an exact copy of an environment by creating a clone of it:&lt;br /&gt;
&lt;code&gt;conda create --name myclone --clone myenv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To verify that the copy was made:&lt;br /&gt;
&lt;code&gt;conda info --envs&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:note&#34;&gt;Github Gists are actually surprisingly difficult to sort through, and navigating to this webpage will be much easier, anyway.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:note&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:notebooks&#34;&gt;It does appear though that &lt;code&gt;notebooks&lt;/code&gt; is pre-packaged now with Anaconda, so it will likely already be installed.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:notebooks&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Relevant Projects</title>
      <link>https://www.michaelpilosov.com/openscience/getting-started/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/openscience/getting-started/</guid>
      <description>

&lt;h1 id=&#34;basics&#34;&gt;Basics&lt;/h1&gt;

&lt;p&gt;In this documentation, we will research and likely leverage (most if not all of) the following open-source projects.
We will eventually address each in depth within this documentation and will update this section with relevant links as necessary.
For now, we provide a brief overview and summary of what we are looking into.&lt;/p&gt;

&lt;h2 id=&#34;widgets&#34;&gt;Widgets&lt;/h2&gt;

&lt;p&gt;If you have ever tried developing a graphical user interface (GUI) for your code, you&amp;rsquo;ll know how cumbersome it can be.
Thankfully, the &lt;a href=&#34;http://jupyter.org/widgets&#34; target=&#34;_blank&#34;&gt;Widgets&lt;/a&gt; package from Project Jupyter greatly simplifies linking your code to a large library of existing &amp;ldquo;widgets,&amp;rdquo; which do everything from giving you sliders to fully-interactive maps.&lt;/p&gt;

&lt;p&gt;I highly encourage you to see what is possible to embed in your notebooks (and webpages) by scrolling through their &lt;a href=&#34;http://jupyter.org/widgets&#34; target=&#34;_blank&#34;&gt;examples&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;jupyter-nbviewer&#34;&gt;Jupyter nbviewer&lt;/h2&gt;

&lt;p&gt;Paste a link to a notebook into &lt;a href=&#34;https://nbviewer.jupyter.org/&#34; target=&#34;_blank&#34;&gt;this form&lt;/a&gt; and this website will render the notebook for your reading pleasure.&lt;/p&gt;

&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;

&lt;h2 id=&#34;github&#34;&gt;Github&lt;/h2&gt;

&lt;h2 id=&#34;anaconda&#34;&gt;Anaconda&lt;/h2&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;binderhub&#34;&gt;BinderHub&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jupyterhub/binderhub&#34; target=&#34;_blank&#34;&gt;BinderHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;taken from the repository description&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;BinderHub allows you to &lt;code&gt;BUILD&lt;/code&gt; and &lt;code&gt;REGISTER&lt;/code&gt; a Docker image using a GitHub repository, then CONNECT with JupyterHub, allowing you to create a public IP address that allows users to interact with the code and environment within a live JupyterHub instance. You can select a specific branch name, commit, or tag to serve.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;repo2docker&#34;&gt;Repo2Docker&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jupyter/repo2docker&#34; target=&#34;_blank&#34;&gt;repo2docker&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As the title suggest, this package turns a github repository into a docker image that can be built.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;taken from the repository description&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;repo2docker fetches a git repository and builds a container image based on the configuration files found in the repository.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Binder leverages this to then serve the contents of the image in conjuction with JupyterHub.&lt;/p&gt;

&lt;h2 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;

&lt;p&gt;Google is a provider. Links/info should go here to a couple other platforms, some basic information.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;jupyterhub&#34;&gt;JupyterHub&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/jupyterhub/jupyterhub&#34; target=&#34;_blank&#34;&gt;JupyterHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;taken from the repository description&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;With &lt;a href=&#34;https://jupyterhub.readthedocs.io&#34; target=&#34;_blank&#34;&gt;JupyterHub&lt;/a&gt; you can create a
&lt;strong&gt;multi-user Hub&lt;/strong&gt; which spawns, manages, and proxies multiple instances of the
single-user &lt;a href=&#34;https://jupyter-notebook.readthedocs.io&#34; target=&#34;_blank&#34;&gt;Jupyter notebook&lt;/a&gt;
server.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://jupyter.org&#34; target=&#34;_blank&#34;&gt;Project Jupyter&lt;/a&gt; created JupyterHub to support many
users. The Hub can offer notebook servers to a class of students, a corporate
data science workgroup, a scientific research project, or a high performance
computing group.&lt;/p&gt;

&lt;h2 id=&#34;technical-overview&#34;&gt;Technical overview&lt;/h2&gt;

&lt;p&gt;Three main actors make up JupyterHub:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;multi-user &lt;strong&gt;Hub&lt;/strong&gt; (tornado process)&lt;/li&gt;
&lt;li&gt;configurable http &lt;strong&gt;proxy&lt;/strong&gt; (node-http-proxy)&lt;/li&gt;
&lt;li&gt;multiple &lt;strong&gt;single-user Jupyter notebook servers&lt;/strong&gt; (Python/Jupyter/tornado)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Basic principles for operation are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hub launches a proxy.&lt;/li&gt;
&lt;li&gt;Proxy forwards all requests to Hub by default.&lt;/li&gt;
&lt;li&gt;Hub handles login, and spawns single-user servers on demand.&lt;/li&gt;
&lt;li&gt;Hub configures proxy to forward url prefixes to the single-user notebook
servers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JupyterHub also provides a
&lt;a href=&#34;http://petstore.swagger.io/?url=https://raw.githubusercontent.com/jupyter/jupyterhub/master/docs/rest-api.yml#/default&#34; target=&#34;_blank&#34;&gt;REST API&lt;/a&gt;
for administration of the Hub and its users.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I personally run Jupyterhub on a remote server so that I always have access to a secure and familiar environment if I ever need to test out some code and find myself without my laptop.
By default, it accepts the login information of just the user who is running it, but we will see later how it can be configured for its intended use as a multi-user authentication hub.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Day 2</title>
      <link>https://www.michaelpilosov.com/devlog/widgets/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/widgets/</guid>
      <description>

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;I spent the day working with the widget library and understanding how interpolating polynomials are handled by &lt;code&gt;scipy&lt;/code&gt;.
Most of today&amp;rsquo;s developments were concerned with my random art and animation libraries, and I completed some of the most important components of the interface: setting time-dependent functions (independent of frames), and creating a widget that properly reads/writes data to a dictionary.&lt;/p&gt;

&lt;p&gt;I still need to link the interfaces for the existing GUIs that write the properties.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Allow removal feature?&lt;/li&gt;
&lt;li&gt;scrape the widgets and write to dictionary.&lt;/li&gt;
&lt;li&gt;New GUI for stacking effects, connecting each effect to the needed time-series based on available entries in aforementioned dictionary.&lt;/li&gt;
&lt;li&gt;All effects get applied with their time series, passed to animation function to be written to file.&lt;/li&gt;
&lt;li&gt;Maybe use the Play button to preview? (Have a GUI focused on the &lt;code&gt;num_frames&lt;/code&gt; perspective). It is linked to the index.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; As of 01/01/19, dictionary writing is working. Preview button is segmented out. Play button implemented. No removal, bare-bones working time-series manipulation. Need to add in hyperbolic tangent functions (should also write blog about these).&lt;/p&gt;

&lt;h1 id=&#34;notes&#34;&gt;Notes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Still having trouble with the mybinder.org connections with my &lt;code&gt;giftplanning&lt;/code&gt; library that tests out my deployment solutions for interactive blogs.
&lt;em&gt;Update:&lt;/em&gt; As of 01/01/19, devs and I have been in touch on &lt;a href=&#34;https://gitter.im/nbinteract/Lobby&#34; target=&#34;_blank&#34;&gt;gitter&lt;/a&gt;. Sam pushed a fix to unpkg.com and my site started to work again.
TO DO: Go make a publicly accessible redundant copy of JS script, query it. Ask Elliott how to only trigger it if the first one fails.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;After conversing with Elliott last night (12/19/19), I think that writing a simple WebSocket atop Flask with his help may be a good solution. A JSON file gets passed back and forth, manipulations happen on a server. Still would prefer to just learn how to make the widgets do this part.
&lt;em&gt;Update:&lt;/em&gt; As of 01/01/19, I have found numerous other solutions and there is a &lt;a href=&#34;https://github.com/SamLau95/nbinteract/issues/101&#34; target=&#34;_blank&#34;&gt;feature request&lt;/a&gt; submitted for the nbinteract library that would enable me to run the nbserver that mybinder.org is providing on a machine that I own instead, which would greatly reduce latency. Would docker be able to automatically re-start it? Load balance? Etc. (probably, but that&amp;rsquo;s for later. For now, mybinder.org is fine, but steps should be taken to ensure the visualizations work in posterity). Should also attempt to get their plotting to work again (maybe one of their updates have fixed this?)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Website Upgrading Logs</title>
      <link>https://www.michaelpilosov.com/devlog/academicupgrades/</link>
      <pubDate>Wed, 19 Dec 2018 18:16:07 -0700</pubDate>
      
      <guid>https://www.michaelpilosov.com/devlog/academicupgrades/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;This documents the changes made to the academic theme to make this website work when upgrading from Hugo ver=0.47 and Academic Theme ver=2.4.&lt;/p&gt;

&lt;p&gt;The upgrade for this website was performed on 12-19-2018.&lt;/p&gt;

&lt;p&gt;All in all, it took the better part of an entire day to get familiar with all the nooks and crannies of the new updates and plan out the migration of the more complicated website&amp;hellip; &lt;a href=&#34;https://www.mathematicalmichael.com&#34; target=&#34;_blank&#34;&gt;Mathematical Michael&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;changes-made-to-theme&#34;&gt;Changes Made to Theme&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Removed Weibo sharing icon in &lt;code&gt;/layouts/partials/share&lt;/code&gt; in the theme directory.&lt;/li&gt;
&lt;li&gt;Changed footer in &lt;code&gt;layouts/partials/footer_section.html&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Re-did &lt;code&gt;config.toml&lt;/code&gt; line-by-line, disabled night/day mode.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Created slides and docs based on the &lt;code&gt;exampleSite&lt;/code&gt; folder, including creating the directory &lt;code&gt;/assets/css/reveal_custom.css&lt;/code&gt; for the Reveal.js slideshows.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;added &lt;code&gt;boards.jpg&lt;/code&gt; to &lt;code&gt;/static/img/&lt;/code&gt; to test headers and embeds in the example slideshow.&lt;/li&gt;
&lt;li&gt;created &lt;code&gt;slides.md&lt;/code&gt; in &lt;code&gt;/content/&lt;/code&gt; to link to &lt;code&gt;/content/slides/&lt;/code&gt; folder since using an index file does not work to list the available slideshows in that folder.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;created &lt;code&gt;/wid/&lt;/code&gt; and &lt;code&gt;/dockerhub/&lt;/code&gt; to experiment with new &lt;code&gt;docs&lt;/code&gt; template.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;copied over dummy project files, still need to migrate own projects to new formatting, remove dummy projects.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Changed &lt;code&gt;work&lt;/code&gt; hyperlink and &lt;code&gt;resume&lt;/code&gt; to reflect new migration to the &lt;code&gt;docs&lt;/code&gt; template.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;resume widget changed to hyperlink to resume doc.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;to-do&#34;&gt;To-Do&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;header/feature images for post, check how fb/twitter scrapes them.

&lt;ul&gt;
&lt;li&gt;optional feature image without becoming header will be useful for posts that are galleries.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;migrate any posts/projects to new formatting.&lt;/li&gt;
&lt;li&gt;think about how to migrate MathematicalMichael.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Things I&amp;rsquo;m Considering&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;No need to re-make publication type.

&lt;ul&gt;
&lt;li&gt;Since posts can be linked to projects, and filters can be applied within widgets, we should have all the flexibility we need.&lt;/li&gt;
&lt;li&gt;Taken with the new folder structure of pages, the overall directory structure remains quite clean.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Use widgets pagetype to construct/mimick the &lt;code&gt;/artwork&lt;/code&gt; page.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Have carousels and project widgets linking to galleries and slideshows.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Can additionally link out to a &lt;code&gt;docs&lt;/code&gt; page that describes the art in more depth, also linked to from the projects page of &lt;code&gt;Probably Art&lt;/code&gt; to tell the &amp;ldquo;story&amp;rdquo; of this project over time and in its phases.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Phase 1: Directed Study&lt;/li&gt;
&lt;li&gt;Phase 2: Pickup with Pocket CHIP, restart coding in Python&lt;/li&gt;
&lt;li&gt;Phase 3: After some time, picked it up again and added a whole bunch of functionality, attempted to get random art automated in Squarespace&lt;/li&gt;
&lt;li&gt;Phase 4: Pick up again when I get into GCode. Adds functionality.&lt;/li&gt;
&lt;li&gt;Phase 5: Lapse again. Then finally tackle creating a framework that will work long-term. Talk about requirements. How is has to be in Python, based on stable packages, recreatable and deterministic. GCode scalable. Talk about some to-do&amp;rsquo;s (bumpers, bash scripts that wrap around to position plotter better). Show images of getting plotter back up again.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Phase 6: Merge with Animation code/projects. Talk about goals, current progress. Random animations on non-random images&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Have another to tell the story of &lt;code&gt;Moving Pictures&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;upgrading-to-hugo-v0-52&#34;&gt;Upgrading to Hugo v0.52&lt;/h1&gt;

&lt;p&gt;Date: 12/21/18&lt;/p&gt;

&lt;p&gt;Today I began to structure and fill in the basic information for the &lt;a href=&#34;https://www.michaelpilosov.com/openscience&#34;&gt;Open Science&lt;/a&gt; Documentation.
It involved some research and collection of resources from disparated places and things I&amp;rsquo;ve done before.&lt;/p&gt;

&lt;p&gt;I also sat down and in a couple minutes managed to figure out the &amp;ldquo;breaking changes&amp;rdquo; to my MathematicalMichael website under Hugo v0.52.
The only file that needed to be changed (before updating the theme, that is) was the &lt;code&gt;$i,&lt;/code&gt; reference in a file I made myself:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim themes/academic/layouts/partials/artwork_links.html 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next step was to copy the theme from &lt;code&gt;michaelpilosov/&lt;/code&gt; (which pulled from the github repo only a few days prior, and to which some minor changes were made) into &lt;code&gt;mathematicalmichael/themes/&lt;/code&gt; along with a copy of the config file.&lt;/p&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Once the reference to the new theme is made, I expect a number of things to break.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Here I will attempt to document one-by-one the changes I had to make to port my theme over, which I will attempt to do by leveraging the &amp;ldquo;lookup structure&amp;rdquo; of Hugo (something I read online).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The idea is that rather than make changes to a theme that result in deviations that make merging new changes difficult, one makes changes by copying files into directories that are checked first, before &lt;code&gt;themes/&lt;/code&gt; is searched for &lt;code&gt;layouts&lt;/code&gt; or &lt;code&gt;partials&lt;/code&gt; files.
My hope is that this will aid in future upgrades, since less differences will exist between my version of the theme and the master branch.
A really useful command (for comparing files), that I used to see what needed to change in the master configuration file for my theme (compared to the updated one from this website) was:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;diff -y file1.md file2.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which will print out two files side-by-side directly into the UNIX Terminal. Excellent.&lt;/p&gt;

&lt;h2 id=&#34;academic-theme-v0-3-32&#34;&gt;Academic Theme v0.3.32&lt;/h2&gt;

&lt;p&gt;After making the appropriate changes to the &lt;code&gt;config.toml&lt;/code&gt; file (which were all straightforward), I ensured that the site built with the new Hugo &lt;em&gt;and&lt;/em&gt; the new configuration file but &lt;em&gt;without&lt;/em&gt; the new theme. It did. All was well.&lt;/p&gt;

&lt;p&gt;Then I changed the theme to point to the updated one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;theme = &amp;quot;hugo-academic&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which yielded the following error (kind of expected to be honest):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Error: 
Error building site: 
failed to render pages: 
render of &amp;quot;home&amp;quot; failed: 
execute of template failed: 
template: index.html:4:3: 
executing &amp;quot;index.html&amp;quot; at &amp;lt;partial widget_page...&amp;gt;: 
error calling partial: 
&amp;quot;/media/mathematicalmichael/HANK/repos/mathematicalmichael/themes/hugo-academic/layouts/partials/widget_page.html:23:9&amp;quot;: 
execute of template failed: 
template: partials/widget_page.html:23:9: 
executing &amp;quot;partials/widget_page.html&amp;quot; at &amp;lt;partial $widget $par...&amp;gt;: 
error calling partial: 
Partial &amp;quot;widgets/artworks.html&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So why did this happen?&lt;/p&gt;

&lt;p&gt;Well, I had defined my own template page called &lt;code&gt;artworks&lt;/code&gt; that was modeled on the &lt;code&gt;publications&lt;/code&gt; style of page.
I used this to publish a webpage for each piece of art, complete with a rich tagging-system automated through Python.
I made random art and had written code that created pages for that art to live on.
Any changes made to the front-matter could be easily applied later.&lt;/p&gt;

&lt;p&gt;I believe that simply moving some files to directories that exist &lt;em&gt;above&lt;/em&gt; &lt;code&gt;themes&lt;/code&gt; will resolve my problems.&lt;/p&gt;

&lt;h2 id=&#34;image-galleries&#34;&gt;Image Galleries&lt;/h2&gt;

&lt;p&gt;However, I know there will be an opportunity to switch to page-bundles and leverage the &lt;code&gt;image-gallery&lt;/code&gt; feature in &lt;code&gt;v3.0&lt;/code&gt; of &lt;code&gt;Hugo-Academic&lt;/code&gt;. My thinking is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Instead of daily pages, make weekly ones as galleries.&lt;/li&gt;
&lt;li&gt;Alternatively, keep daily postings as-is, and add galleries additionally. See if you can link images to the main folder, so all art can continue to live in one folder without duplicates.&lt;/li&gt;
&lt;li&gt;You can make galleries using page-bundles as a separate way to interact with the art.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Definitely need to integrate a widget page that hosts all the art. I don&amp;rsquo;t want to clutter the home page with everything.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I think that clicking from the main menu to &lt;code&gt;art/&lt;/code&gt; should suffice.&lt;/li&gt;
&lt;li&gt;Curate the experience, minimize contact with &lt;code&gt;/artwork/&lt;/code&gt; page (i.e. make slideshows link to other content rather than the search they perform now, which can be a bit slow.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Since slideshows are just a markdown file, we should have no trouble linking to images in another folder!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;will take some playing around to figure out exactly the right directory structure.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;** Main Goal ** for the time being is to make sure the site builds with the new theme. We can add features and functionality later on.&lt;/p&gt;

&lt;p&gt;Today&amp;rsquo;s agenda is simply to allow migration to Hugo v0.52 on my Macbook by ensuring the site builds with the new version.
Having the new theme work would be an added bonus.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I suspect all that needs to happen is a little migration of &lt;code&gt;partials&lt;/code&gt; and &lt;code&gt;shortcodes&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp themes/academic/layouts/partials/artwork_* layouts/partials/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Did not change the error.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir layouts/partials/widgets/
cp themes/academic/layouts/partials/widgets/artworks* layouts/partials/widgets/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resolved that but sprang a new error:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Error: 
Error building site: 
failed to render pages: 
render of &amp;quot;home&amp;quot; failed: 
execute of template failed: 
template: 
index.html:4:3: 
executing &amp;quot;index.html&amp;quot; at &amp;lt;partial widget_page...&amp;gt;: 
error calling partial: 
&amp;quot;/media/mathematicalmichael/HANK/repos/mathematicalmichael/themes/hugo-academic/layouts/partials/widget_page.html:23:9&amp;quot;: 
execute of template failed: 
template: 
partials/widget_page.html:23:9: 
executing &amp;quot;partials/widget_page.html&amp;quot; at &amp;lt;partial $widget $par...&amp;gt;: 
error calling partial: 
Partial &amp;quot;widgets/search.html&amp;quot; not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Okay, so let&amp;rsquo;s move &lt;code&gt;widgets/search.html&lt;/code&gt; over?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp themes/academic/layouts/partials/widgets/search.html layouts/partials/widgets/
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo server --disableFastRender
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that did it! Wow, relatively painless. Now let&amp;rsquo;s see how it looks.&lt;/p&gt;

&lt;p&gt;The layout is dark for some reason&amp;hellip; Enabling light/dark mode shows me the white I want to see but with inverted header.
&lt;code&gt;:mailto&lt;/code&gt; icon is broken. Change to &amp;ldquo;fas&amp;rdquo; instead of &amp;ldquo;fab&amp;rdquo; in &lt;code&gt;config.toml&lt;/code&gt;, line 293.&lt;/p&gt;

&lt;p&gt;Back to the theme.. let&amp;rsquo;s grab a file and move it to the root directory and figure out where to put it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp themes/hugo-academic/data/themes/dark.toml .
mkdir data
mkdir data/themes
mv dark.toml data/themes/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I then proceeded to change some things to get the right colors. Still not sure if this is correct. I also changed the theme to &lt;code&gt;self.toml&lt;/code&gt; and referenced that in the &lt;code&gt;config.toml&lt;/code&gt; file.&lt;/p&gt;

&lt;h2 id=&#34;dark-mode&#34;&gt;Dark Mode&lt;/h2&gt;

&lt;p&gt;Next test: Day/Night mode (re-enable, see what happens).&lt;/p&gt;

&lt;p&gt;Day Mode is fine.
Night mode makes my logos look weird (though I do like the look overall). Top bar is also white instead of black for some reason.&lt;/p&gt;

&lt;p&gt;Editing &lt;code&gt;data/themes/self.toml&lt;/code&gt; to rename the theme (mistake to not have done that before), and toggle &lt;code&gt;light = true&lt;/code&gt;, since I did make it into a light theme.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Theme metadata
name = &amp;quot;Self&amp;quot;

# Is theme light or dark?
light = true

# Primary
primary = &amp;quot;hsl(339, 90%, 68%)&amp;quot;
primary_light = &amp;quot;hsl(339, 90%, 78%)&amp;quot;
primary_dark = &amp;quot;hsl(339, 90%, 58%)&amp;quot;

# Menu
menu_primary = &amp;quot;#fff&amp;quot;
menu_text = &amp;quot;rgba(0,0,0,0.6)&amp;quot;
menu_text_active = &amp;quot;hsl(339, 90%, 68%)&amp;quot;
menu_title = &amp;quot;#2b2b2b&amp;quot;

# Home sections
home_section_odd = &amp;quot;rgb(255, 255, 255)&amp;quot;
home_section_even = &amp;quot;rgb(247, 247, 247)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: Also broken is the search widget. Sad.&lt;/p&gt;

&lt;p&gt;Disable search widget&amp;hellip; Should not have moved it in the first place!
&lt;em&gt;There is a new search feature&lt;/em&gt; that renders this one useless. I will now remove the &lt;code&gt;search.html&lt;/code&gt; widget (and &lt;code&gt;search.md&lt;/code&gt; from &lt;code&gt;content/home/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Contact form&amp;hellip;
Had to paste in the new format. I was using a custom partial code (note to self&amp;hellip; &lt;em&gt;delete that&lt;/em&gt;) to make a formspree link. Now I don&amp;rsquo;t have to!&lt;/p&gt;

&lt;p&gt;Also, remove &lt;code&gt;Search&lt;/code&gt; from menu in &lt;code&gt;config.toml&lt;/code&gt;.
After deleting &lt;code&gt;layouts/shortcodes/contactme.html&lt;/code&gt; (my custom formspree link), in favor of using the one the upgraded theme provided, it appears that my website is now settled into the new theme. I did have to remove all references to this deleted shortcode, of course.&lt;/p&gt;

&lt;p&gt;Day/night mode works correctly. (would like to make my logo transparent though).&lt;/p&gt;

&lt;h2 id=&#34;page-bundles&#34;&gt;Page Bundles&lt;/h2&gt;

&lt;p&gt;Okay, well I knew it was too good to be true that things just worked. While pages loaded correctly, before building the final site, I made sure to investigate the directories a bit more and found that a bunch of files prepended with &lt;code&gt;._XXX.md&lt;/code&gt; had populated my website directories.
&lt;em&gt;This must be how they&amp;rsquo;re ensuring backward-compatibility.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Well, I refactored the pages into page bundles with this shell script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/sh

# Helps migrate from v2.4.0 to v3.0.0
#
# Refactor a page named `X.md` to `content/&amp;lt;section&amp;gt;/X/index.md` to use the
# new page bundles and featured image system
#
# - E.g. a post `content/post/X.md` is converted to `content/post/X/index.md`

refactor_pages_to_page_bundles()
{
  if [ ! -d ./content/ ]; then
    echo &amp;quot;Please run script from root of hugo site&amp;quot;
  fi
  local files=&amp;quot;$(find ./content/ -iname &#39;*.md&#39; -not -iname &#39;*index.md&#39; -not -ipath &#39;./content/home/*&#39;)&amp;quot;
  for file in ${files}; do
    local pagedir=&amp;quot;${file%.md}&amp;quot;

    echo &amp;quot;${file} -&amp;gt; ${pagedir}/index.md&amp;quot;
    if [ ! -d &amp;quot;${pagedir}&amp;quot; ]; then
      mkdir &amp;quot;${pagedir}&amp;quot;
    fi

    mv &amp;quot;${file}&amp;quot; &amp;quot;${pagedir}/index.md&amp;quot;
  done
}

# Bash Strict Mode
set -eu

# set -x
refactor_pages_to_page_bundles &amp;quot;$@&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sourcethemes/academic-scripts/blob/master/refactor-pages-to-page-bundles.sh&#34; target=&#34;_blank&#34;&gt;Source&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After poking around, it looks like the pages obey the proper structure now (for the most part)&amp;hellip; There are a few stray &lt;code&gt;.md&lt;/code&gt; files around.&lt;/p&gt;

&lt;p&gt;I will push the changes live but later on go through both websites to ensure that bundles are everywhere and no stray pages are left.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;search-filter&#34;&gt;Search/Filter&lt;/h2&gt;

&lt;p&gt;Notably, I will need to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;update my python script that writes project pages and art pages.&lt;/li&gt;
&lt;li&gt;ensure featured images (optional) are properly handled&lt;/li&gt;
&lt;li&gt;find out how galleries can work with the &lt;code&gt;artwork/images&lt;/code&gt; directory, which so far doesn&amp;rsquo;t seem to be conflicting with the page-bundle format.&lt;/li&gt;
&lt;li&gt;Make sure the artwork search works. Seems to be broken, though &lt;code&gt;publications&lt;/code&gt; search still works.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Oh, I think all that needs to happen is to move
&lt;code&gt;/themes/academic/layouts/artwork&lt;/code&gt; into the &lt;code&gt;layouts&lt;/code&gt; folder I have in my root directory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mv themes/academic/layouts/artwork/ layouts/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But that led to an error regarding &lt;code&gt;partial header_image.html&lt;/code&gt;. Thus, it seems like I will need to copy the new publication template over and edit it again. At least this time I will document it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp themes/hugo-academic/layouts/publication/single.html  layouts/artwork/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then I replaced all instances of &lt;code&gt;publication&lt;/code&gt; with &lt;code&gt;artwork&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;But that still didn&amp;rsquo;t lead to the filter-ability that I wanted.&lt;/p&gt;

&lt;p&gt;The default behavior was to paginate and list all of the art, which doesn&amp;rsquo;t have image previews but honestly is just fine, especially since it loads quickly.&lt;/p&gt;

&lt;p&gt;The widget on the homepage that links to the search of artwork though is now broken as a consequence. I can fall back on searching by tags, or disable the widget temporarily until I set up galleries for the artworks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If I write a python script that scrapes the &lt;code&gt;artwork/images&lt;/code&gt; folder and creates galleries linked to that, well that would be just perfect.&lt;/li&gt;
&lt;li&gt;This widget can be linked to those galleries, or slideshows.&lt;/li&gt;
&lt;li&gt;Disable it for now.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Okay, later at night I had to come across this as well, but I wanted the listing of artworks in their projects, so I copied the new &lt;code&gt;layouts/partials/project/single.html&lt;/code&gt; into the &lt;code&gt;layouts/partials/projects/&lt;/code&gt; directory I created and pasted the following relevant chunk of code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;&amp;lt;br&amp;gt;
      &amp;lt;h4&amp;gt; Archive &amp;lt;/h4&amp;gt;
      {{ $items := where (where .Site.RegularPages &amp;quot;Type&amp;quot; &amp;quot;artwork&amp;quot;) &amp;quot;.Params.projects&amp;quot; &amp;quot;intersect&amp;quot; (slice $project) }}
      {{ $items := $items | union (where (where .Site.RegularPages &amp;quot;Type&amp;quot; &amp;quot;artwork&amp;quot;) &amp;quot;.Params.url_project&amp;quot; $project_path) }}
      {{ $arts_len := len $items }}
      {{ if ge $arts_len 1 }}
        &amp;lt;h4&amp;gt;{{ (i18n &amp;quot;artworks&amp;quot;) }}&amp;lt;/h4&amp;gt;
        {{ range $items }}
          {{ if eq $page.Site.Params.projects.artwork_format 1 }}
            {{ partial &amp;quot;artwork_li_detailed&amp;quot; . }}
          {{ else }}
            {{ partial &amp;quot;artwork_li_simple&amp;quot; . }}
          {{ end }}
        {{ end }}
      {{ end }}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And I got my desired lists!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.mathematicalmichael.com/project/rnr&#34; target=&#34;_blank&#34;&gt;See here for example&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;p&gt;I also realized I needed to edit the table of contents with some custom CSS.&lt;/p&gt;

&lt;p&gt;Create a custom file in &lt;code&gt;/static/css&lt;/code&gt; and link it to line &lt;code&gt;custom_css = []&lt;/code&gt; in &lt;code&gt;config.toml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#TableOfContents{
    padding-left: 10px
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
